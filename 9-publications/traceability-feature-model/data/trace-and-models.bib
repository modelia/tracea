% Encoding: UTF-8

@InProceedings{lohar2013,
  author    = {Lohar, Sugandha and Amornborvornwong, Sorawit and Zisman, Andrea and Cleland-Huang, Jane},
  booktitle = {Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering},
  title     = {Improving Trace Accuracy through Data-Driven Configuration and Composition of Tracing Features},
  year      = {2013},
  address   = {New York, NY, USA},
  pages     = {378--388},
  publisher = {Association for Computing Machinery},
  series    = {ESEC/FSE 2013},
  abstract  = {Software traceability is a sought-after, yet often elusive quality in large software-intensive systems primarily because the cost and effort of tracing can be overwhelming. State-of-the art solutions address this problem through utilizing trace retrieval techniques to automate the process of creating and maintaining trace links. However, there is no simple one- size-fits all solution to trace retrieval. As this paper will show, finding the right combination of tracing techniques can lead to significant improvements in the quality of generated links. We present a novel approach to trace retrieval in which the underlying infrastructure is configured at runtime to optimize trace quality. We utilize a machine-learning approach to search for the best configuration given an initial training set of validated trace links, a set of available tracing techniques specified in a feature model, and an architecture capable of instantiating all valid configurations of features. We evaluate our approach through a series of experiments using project data from the transportation, healthcare, and space exploration domains, and discuss its implementation in an industrial environment. Finally, we show how our approach can create a robust baseline against which new tracing techniques can be evaluated.},
  doi       = {10.1145/2491411.2491432},
  groups    = {NLP use, identification},
  isbn      = {9781450322379},
  keywords  = {trace configuration, Trace retrieval, configuration},
  location  = {Saint Petersburg, Russia},
  numpages  = {11},
}

@Article{hayes2006,
  author   = {J. H. {Hayes} and A. {Dekhtyar} and S. K. {Sundaram}},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Advancing candidate link generation for requirements tracing: the study of methods},
  year     = {2006},
  number   = {1},
  pages    = {4-19},
  volume   = {32},
  abstract = {This paper addresses the issues related to improving the overall quality of the dynamic candidate link generation for the requirements tracing process for verification and validation and independent verification and validation analysts. The contribution of the paper is four-fold: we define goals for a tracing tool based on analyst responsibilities in the tracing process, we introduce several new measures for validating that the goals have been satisfied, we implement analyst feedback in the tracing process, and we present a prototype tool that we built, RETRO (REquirements TRacing On-target), to address these goals. We also present the results of a study used to assess RETRO's support of goals and goal elements that can be measured objectively.},
  url      = {https://doi.org/10.1109/TSE.2006.3},
}

@InBook{Gotel2012,
  author     = {Gotel, Orlena and Cleland-Huang, Jane and Hayes, Jane Huffman and Zisman, Andrea and Egyed, Alexander and Gr{\"u}nbacher, Paul and Dekhtyar, Alex and Antoniol, Giuliano and Maletic, Jonathan and M{\"a}der, Patrick},
  editor     = {Cleland-Huang, Jane and Gotel, Orlena and Zisman, Andrea},
  pages      = {3--22},
  publisher  = {Springer London},
  title      = {Traceability Fundamentals},
  year       = {2012},
  address    = {London},
  isbn       = {978-1-4471-2239-5},
  abstract   = {This chapter seeks to provide a reference resource on traceability fundamentals. It defines the essential traceability terminology of trace, trace artifact, trace link, traceability and tracing, and is supplemented by an extensive glossary that has been developed and endorsed by members of the traceability community. This chapter also offers a model of a generic traceability process and describes the essential activities involved in the life cycle of a trace. This model has been used as a frame of reference for articulating the grand challenge of traceability, as reported in the chapter by Gotel et al. of this book. The chapter also describes the basic types of traceability and explains a number of key associated concepts.},
  booktitle  = {Software and Systems Traceability},
  doi        = {10.1007/978-1-4471-2239-5_1},
  groups     = {meta, Metastudies},
  keywords   = {read},
  readstatus = {read},
  url        = {https://doi.org/10.1007/978-1-4471-2239-5_1},
}

@InProceedings{li2013ontologybasedTraceRetrieval,
  author    = {Y. {Li} and J. {Cleland-Huang}},
  booktitle = {2013 7th International Workshop on Traceability in Emerging Forms of Software Engineering (TEFSE)},
  title     = {Ontology-based trace retrieval},
  year      = {2013},
  pages     = {30-36},
  abstract  = {In automated requirements trace retrieval, an ontology can be used as an intermediary artifact to identify relationships that would not be recognized by standard information retrieval techniques. However, ontologies must be carefully constructed to fit the needs of the project. In this paper we present a technique for incorporating information from general and domain-specific ontologies into the tracing process. Our approach applies the domain ontology at the phrase level and then uses a general ontology to augment simple term matching in order to deduce relationships between individual terms weighted according to the relative importance of the phrase in which they occur. The combined weights are used to compute the overall similarity between a source and target artifact in order to establish a candidate trace link. We experimentally evaluated our approach against the standard Vector Space Model (VSM) and show that a domain ontology combined with generalized ontology returned greatest improvements in trace accuracy.},
  groups    = {NLP use, identification},
}

@Article{clelandhuang2007bestPracticeForAutomatedTraceability,
  author   = {J. {Cleland-Huang} and B. {Berenbach} and S. {Clark} and R. {Settimi} and E. {Romanova}},
  journal  = {Computer},
  title    = {Best Practices for Automated Traceability},
  year     = {2007},
  number   = {6},
  pages    = {27-35},
  volume   = {40},
  abstract = {Automated traceability applies information-retrieval techniques to generate candidate links, sharply reducing the effort of manual approaches to build and maintain a requirements trace matrix as well as providing after-the-fact traceability in legacy documents.The authors describe nine best practices for implementing effective automated traceability.},
  file     = {:clelandhuang2007_Best practice for automated traceability.pdf:PDF},
  groups   = {meta, Metastudies, identification},
}

@InProceedings{guo2013expertSystemInTraceabilityDSL,
  author     = {J. {Guo} and J. {Cleland-Huang} and B. {Berenbach}},
  booktitle  = {2013 21st IEEE International Requirements Engineering Conference (RE)},
  title      = {Foundations for an expert system in domain-specific traceability},
  year       = {2013},
  pages      = {42-51},
  abstract   = {Attempts to utilize information retrieval techniques to fully automate the creation of traceability links have been hindered by terminology mismatches between source and target artifacts. Therefore, current trace retrieval algorithms tend to produce imprecise and incomplete results. In this paper we address this mismatch by proposing an expert system which integrates a knowledge base of domain concepts and their relationships, a set of logic rules for defining relationships between artifacts based on these rules, and a process for mapping artifacts into a structure against which the rules can be applied. This paper lays down the core foundations needed to integrate an expert system into the automated tracing process. We construct a knowledge base and inference rules for part of a large industrial project in the transportation domain and empirically show that our approach significantly improves precision and recall of the generated trace links.},
  groups     = {Metamodels, identification},
  keywords   = {read},
  readstatus = {read},
}

@InProceedings{tekinerdogan2007-metamodel-for-tracing-concers-accross-life-cycle,
  author     = {Tekinerdo{\u{g}}an, Bedir and Hofmann, Christian and Ak{\c{s}}it, Mehmet and Bakker, Jethro},
  booktitle  = {Early Aspects: Current Challenges and Future Directions},
  title      = {Metamodel for Tracing Concerns Across the Life Cycle},
  year       = {2007},
  address    = {Berlin, Heidelberg},
  editor     = {Moreira, Ana and Grundy, John},
  pages      = {175--194},
  publisher  = {Springer Berlin Heidelberg},
  abstract   = {Several aspect-oriented approaches have been proposed to specify aspects at different phases in the software life cycle. Aspects can appear within a phase, be refined or mapped to other aspects in later phases, or even disappear. Tracing aspects is necessary to support understandability and maintainability of software systems. Although several approaches have been introduced to address traceability of aspects, two important limitations can be observed. First, tracing is not yet tackled for the entire life cycle. Second, the traceability model that is applied usually refers to elements of specific aspect languages, thereby limiting the reusability of the adopted traceability model. We propose the concern traceability metamodel (CTM) that enables traceability of concerns throughout the life cycle, and which is independent from the aspect languages that are used. CTM can be enhanced to provide additional properties for tracing, and be instantiated to define customized traceability models with respect to the required aspect languages. We have implemented CTM in the tool M-Trace, that uses XML-based representations of the models and XQuery queries to represent tracing information. CTM and M-Trace are illustrated for a Concurrent Versioning System to trace aspects from the requirements level to architecture design level and the implementation.},
  groups     = {Metamodels},
  isbn       = {978-3-540-76811-1},
  keywords   = {read},
  readstatus = {read},
}

@Article{poshyvanyk2007,
  author   = {D. {Poshyvanyk} and Y. {Gueheneuc} and A. {Marcus} and G. {Antoniol} and V. {Rajlich}},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Feature Location Using Probabilistic Ranking of Methods Based on Execution Scenarios and Information Retrieval},
  year     = {2007},
  number   = {6},
  pages    = {420-432},
  volume   = {33},
  abstract = {This paper recasts the problem of feature location in source code as a decision-making problem in the presence of uncertainty. The solution to the problem is formulated as a combination of the opinions of different experts. The experts in this work are two existing techniques for feature location: a scenario-based probabilistic ranking of events and an information-retrieval-based technique that uses latent semantic indexing. The combination of these two experts is empirically evaluated through several case studies, which use the source code of the Mozilla Web browser and the Eclipse integrated development environment. The results show that the combination of experts significantly improves the effectiveness of feature location as compared to each of the experts used independently},
  groups   = {Concrete applications, NLP use, identification},
}

@InProceedings{keenan2012-workbench-for-traceability,
  author    = {E. {Keenan} and A. {Czauderna} and G. {Leach} and J. {Cleland-Huang} and Y. {Shin} and E. {Moritz} and M. {Gethers} and D. {Poshyvanyk} and J. {Maletic} and J. H. {Hayes} and A. {Dekhtyar} and D. {Manukian} and S. {Hossein} and D. {Hearn}},
  booktitle = {2012 34th International Conference on Software Engineering (ICSE)},
  title     = {TraceLab: An experimental workbench for equipping researchers to innovate, synthesize, and comparatively evaluate traceability solutions},
  year      = {2012},
  month     = {June},
  pages     = {1375-1378},
  abstract  = {TraceLab is designed to empower future traceability research, through facilitating innovation and creativity, increasing collaboration between researchers, decreasing the startup costs and effort of new traceability research projects, and fostering technology transfer. To this end, it provides an experimental environment in which researchers can design and execute experiments in TraceLab's visual modeling environment using a library of reusable and user-defined components. TraceLab fosters research competitions by allowing researchers or industrial sponsors to launch research contests intended to focus attention on compelling traceability challenges. Contests are centered around specific traceability tasks, performed on publicly available datasets, and are evaluated using standard metrics incorporated into reusable TraceLab components. TraceLab has been released in beta-test mode to researchers at seven universities, and will be publicly released via CoEST.org in the summer of 2012. Furthermore, by late 2012 TraceLab's source code will be released as open source software, licensed under GPL. TraceLab currently runs on Windows but is designed with cross platforming issues in mind to allow easy ports to Unix and Mac environments.},
  doi       = {10.1109/ICSE.2012.6227244},
  groups    = {Trace analysis},
  issn      = {1558-1225},
  keywords  = {computerised instrumentation;innovation management;technology transfer;Unix;TraceLab;technology transfer;traceability research projects;visual modeling environment;open source software;GPL;Unix environment;Mac environment;Measurement;Software engineering;Principal component analysis;Software;Benchmark testing;Libraries;Java;Traceability;Instrumentation;TraceLab;Benchmarks;Experiments;eXtreme Software Engineering Lab},
}

@InProceedings{florez2019-finegrained-req2code,
  author    = {J. M. {Florez}},
  booktitle = {2019 IEEE/ACM 41st International Conference on Software Engineering: Companion Proceedings (ICSE-Companion)},
  title     = {Automated Fine-Grained Requirements-to-Code Traceability Link Recovery},
  year      = {2019},
  month     = {May},
  pages     = {222-225},
  abstract  = {Problem: Existing approaches for requirements-to-code traceability link recovery rely on text retrieval to trace requirements to coarse-grained code documents (e.g., methods, files, classes, etc.), while suffering from low accuracy problems. Hypotheses: The salient information in most requirements is expressed as functional constraints, which can be automatically identified and categorized. Moreover, people use recognizable discourse patterns when describing them and developers use well-defined patterns for implementing them. Contributions: Recasting the requirements-to-code traceability link problem as an accurate matching between functional constraints and their implementation.},
  doi       = {10.1109/ICSE-Companion.2019.00087},
  groups    = {NLP use, identification},
  issn      = {2574-1934},
  keywords  = {information retrieval;text analysis;functional constraints;requirements-to-code traceability link problem;text retrieval;coarse-grained code documents;automated fine-grained requirements-to-code traceability link recovery;traceability;static analysis;discourse analysis;qualitative analysis},
}

@InProceedings{rempl2014-conformance-of-traceability-to-guidelines,
  author    = {Rempel, Patrick and M\"{a}der, Patrick and Kuschke, Tobias and Cleland-Huang, Jane},
  booktitle = {Proceedings of the 36th International Conference on Software Engineering},
  title     = {Mind the Gap: Assessing the Conformance of Software Traceability to Relevant Guidelines},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {943–954},
  publisher = {Association for Computing Machinery},
  series    = {ICSE 2014},
  abstract  = {Many guidelines for safety-critical industries such as aeronautics, medical devices, and railway communications, specify that traceability must be used to demonstrate that a rigorous process has been followed and to provide evidence that the system is safe for use. In practice, there is a gap between what is prescribed by guidelines and what is implemented in practice, making it difficult for organizations and certifiers to fully evaluate the safety of the software system. In this paper we present an approach, which parses a guideline to extract a Traceability Model depicting software artifact types and their prescribed traces. It then analyzes the traceability data within a project to identify areas of traceability failure. Missing traceability paths, redundant and/or inconsistent data, and other problems are highlighted. We used our approach to evaluate the traceability of seven safety-critical software systems and found that none of the evaluated projects contained traceability that fully conformed to its relevant guidelines.},
  doi       = {10.1145/2568225.2568290},
  groups    = {Metamodels, Trace analysis, Trace integrity, certification, identification},
  isbn      = {9781450327565},
  keywords  = {software and system safety, compliance, guideline, inspection, Software traceability, conformance, certification, failure patterns, safety critical, safety, assessment},
  location  = {Hyderabad, India},
  numpages  = {12},
  url       = {https://doi.org/10.1145/2568225.2568290},
}

@InProceedings{rath2018-guo-augmenting-incomplete-traces,
  author    = {Rath, Michael and Rendall, Jacob and Guo, Jin L. C. and Cleland-Huang, Jane and M\"{a}der, Patrick},
  booktitle = {Proceedings of the 40th International Conference on Software Engineering},
  title     = {Traceability in the Wild: Automatically Augmenting Incomplete Trace Links},
  year      = {2018},
  address   = {New York, NY, USA},
  pages     = {834–845},
  publisher = {Association for Computing Machinery},
  series    = {ICSE ’18},
  abstract  = {Software and systems traceability is widely accepted as an essential element for supporting many software development tasks. Today's version control systems provide inbuilt features that allow developers to tag each commit with one or more issue ID, thereby providing the building blocks from which project-wide traceability can be established between feature requests, bug fixes, commits, source code, and specific developers. However, our analysis of six open source projects showed that on average only 60% of the commits were linked to specific issues. Without these fundamental links the entire set of project-wide links will be incomplete, and therefore not trustworthy. In this paper we address the fundamental problem of missing links between commits and issues. Our approach leverages a combination of process and text-related features characterizing issues and code changes to train a classifier to identify missing issue tags in commit messages, thereby generating the missing links. We conducted a series of experiments to evaluate our approach against six open source projects and showed that it was able to effectively recommend links for tagging issues at an average of 96% recall and 33% precision. In a related task for augmenting a set of existing trace links, the classifier returned precision at levels greater than 89% in all projects and recall of 50%.},
  doi       = {10.1145/3180155.3180207},
  groups    = {NLP use, identification},
  isbn      = {9781450356381},
  keywords  = {link recovery, traceability, open source, machine learning},
  location  = {Gothenburg, Sweden},
  numpages  = {12},
  url       = {https://doi.org/10.1145/3180155.3180207},
}

@InBook{bonde2006-different-levels-of-abstraction,
  author    = {Bond{\'e}, Lossan and Boulet, Pierre and Dekeyser, Jean-Luc},
  editor    = {Vachoux, A.},
  pages     = {263--276},
  publisher = {Springer Netherlands},
  title     = {Traceability and Interoperability at Different Levels of Abstraction in Model-Driven Engineering},
  year      = {2006},
  address   = {Dordrecht},
  isbn      = {978-1-4020-4998-9},
  abstract  = {Model-driven engineering (MDE) is an emerging approach of software design where the whole process of design and implementation is worked out around models. With MDE, a system is built by designing a set of models at different levels of abstraction. At the first level, only the main functionalities of the system are  modeled. This first model is called according to the model-driven architecture  (MDA) terminology as the platform-independent model (PIM). This PIM can be projected into one or more other models by transformations. These latter models are at lower levels of abstraction. When a model at a given level of abstraction integrates some platform (technology) information, it is called a platform-specific model (PSM). Model transformation is therefore a key issue of the MDE approach. However, many questions arise about transformations. Among these questions is: When a model is transformed into different other models on different platforms, how to ensure the interoperability between these models?
This chapter aims to provide an answer to the above question. Our approach is based on a traceability model. This model not only keeps links between the source and target model elements but also records the different operations that where performed in the transformation. We present a methodology for the automatic generation of the traceability model and the exploitation of this model to ensure interoperability. An example based on open core protocol (OCP) is provided to illustrate our proposal.},
  booktitle = {Applications of Specification and Design Languages for SoCs: Selected papers from FDL 2005},
  doi       = {10.1007/978-1-4020-4998-9_15},
  groups    = {MT, Metamodels, mde},
  url       = {https://doi.org/10.1007/978-1-4020-4998-9_15},
}

@InProceedings{tinnes2019-improving-art-reuse-with-traceability,
  author    = {C. {Tinnes} and A. {Biesdorf} and U. {Hohenstein} and F. {Matthes}},
  booktitle = {2019 IEEE/ACM 10th International Symposium on Software and Systems Traceability (SST)},
  title     = {Ideas on Improving Software Artifact Reuse via Traceability and Self-Awareness},
  year      = {2019},
  month     = {May},
  pages     = {13-16},
  abstract  = {We describe our vision towards automatic software and system development and argue that reusing knowledge from existing projects as well as traceability between corresponding artifacts are important steps towards this vision. We furthermore list barriers that are currently experienced with software artifact reuse and traceability in industry and suggest some ideas to overcome these barriers.},
  doi       = {10.1109/SST.2019.00013},
  file      = {:tinnes2019-improving-art-reuse-with-traceability.pdf:PDF},
  groups    = {Metastudies},
  issn      = {2157-2194},
  keywords  = {software maintenance;software quality;software reusability;traceability;self-awareness;automatic software;system development;reusing knowledge;corresponding artifacts;software artifact reuse;Software;Tools;Task analysis;Computational modeling;Engines;Self-aware;Natural languages;Software Reuse;Traceability;Self Aware Systems;Natural Language Processing;Architecture Knowledge Management},
}

@InProceedings{seiler2019-comparing-trac-through-IR-Commits-Logs,
  author    = {M. {Seiler} and P. {Hübner} and B. {Paech}},
  booktitle = {2019 IEEE/ACM 10th International Symposium on Software and Systems Traceability (SST)},
  title     = {Comparing Traceability through Information Retrieval, Commits, Interaction Logs, and Tags},
  year      = {2019},
  month     = {May},
  pages     = {21-28},
  abstract  = {Context and motivation: Traceability is used to follow and understand the relationships between various software engineering artifacts such as requirements and source code. Comprehensive traceability of software engineering artifacts is important to ensure that a software can be further developed or maintained. Traceability links are often created manually by using commit ids or retrospectively by using information retrieval (IR). Question/Problem: However, creating traceability links manually is costly and it is error-prone in retrospect. As part of our ongoing research on feature management where traceability is also of interest, we use a lightweight tagging approach to relate artifacts. We want to investigate how such a tag-based approach compares to approaches using commit ids, interaction logs (IL), and IR for creating traceability links. Principal ideas/results: We conducted a case study in which students applied the tag-based, the IL-based, and the commit-based approach. We transformed the tags to traceability links and compared them with the commit-based and IL-based approach as well as with IR-based approaches, using a gold standard. We applied different improvements. Contribution: This is the first study comparing four completely different traceability approaches in one project. The combination of IL and commit ids shows the best precision and recall but is intrusive. The other approaches differ less in precision and recall and both need improvement for practical application. We discuss the benefits and drawbacks of the different approaches and state implications for research and practice.},
  doi       = {10.1109/SST.2019.00015},
  groups    = {Metastudies, identification},
  issn      = {2157-2194},
  keywords  = {information retrieval;program diagnostics;software maintenance;information retrieval;interaction tags;IR-based approaches;commit-based IL-based approach;tag-based approach;commit ids;traceability links;software engineering artifacts;interaction logs;Large scale integration;Software engineering;Tagging;Software;Distance measurement;Gold;traceability;tagging;interaction logs;information retrieval},
}

@InProceedings{farrar2019-comparing-stemming-technics,
  author    = {D. {Farrar} and J. {Huffman Hayes}},
  booktitle = {2019 IEEE/ACM 10th International Symposium on Software and Systems Traceability (SST)},
  title     = {A Comparison of Stemming Techniques in Tracing},
  year      = {2019},
  month     = {May},
  pages     = {37-44},
  abstract  = {We examine the effects of stemming on the tracing of software engineering artifacts. We compare two common stemming algorithms to each other as well as to a baseline of no stemming. We evaluate the algorithms on eight tracing datasets. We run the experiment using the TraceLab experimental framework to allow for ease of repeatability and knowledge sharing among the tracing community. We compare the algorithms on precision at recall levels of [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0], as well as on mean average precision values. The experiment indicated that neither the Porter stemmer nor the Krovetz stemmer outperformed the other on all datasets tested.},
  doi       = {10.1109/SST.2019.00017},
  groups    = {NLP use, Metastudies, identification},
  issn      = {2157-2194},
  keywords  = {document handling;information retrieval;stemming techniques;software engineering artifacts;tracing datasets;knowledge sharing;tracing community;mean average precision values;tracelab experimental framework;Krovetz stemmer;Measurement;Tools;Software;Dictionaries;Software engineering;Standards;traceability, stemming, empirical research},
}

@InProceedings{ghaisas2019-traceability-for-a-knowledge-driven-SW,
  author    = {S. {Ghaisas}},
  booktitle = {2019 IEEE/ACM 10th International Symposium on Software and Systems Traceability (SST)},
  title     = {Traceability for a Knowledge-Driven Software Engineering},
  year      = {2019},
  month     = {May},
  pages     = {1-1},
  abstract  = {Software Engineering (SE) industry views traceability as a means to obtain a comprehensive view of relevant knowledge. For a successful execution and delivery of large projects, the core Software Engineering process and artifacts need to be synchronized with processes and artifacts associated with the business domain, project management, and compliance.},
  doi       = {10.1109/SST.2019.00008},
  issn      = {2157-2194},
  keywords  = {project management;software engineering;software engineering process;knowledge-driven software engineering;business domain;project management;Software engineering;Project management;Software;Industries;Knowledge engineering;Synchronization;traceability, domain knowledge, compliance, project management},
}

@InProceedings{rahimi2019-Evolving-trace-req2source,
  author    = {M. {Rahimi} and J. {Cleland-Huang}},
  booktitle = {2019 IEEE/ACM 10th International Symposium on Software and Systems Traceability (SST)},
  title     = {Evolving Software Trace Links between Requirements and Source Code},
  year      = {2019},
  month     = {May},
  pages     = {12-12},
  abstract  = {Maintaining trace links in response to continuous changes occurring in software systems is arduous. In this paper, we present a Trace Link Evolver (TLE) to automatically evolve source-to-requirement trace links according to underlying changes in the system. TLE depends on a set of heuristics coupled with refactoring detection tools and information retrieval algorithms to detect predefined change scenarios that occur across contiguous versions of a software system. Our evaluations show that considering both structural and semantic changes leads to more accurate trace link evolution.},
  doi       = {10.1109/SST.2019.00012},
  groups    = {Trace analysis, Trace integrity, NLP use, identification, Coevolution},
  issn      = {2157-2194},
  keywords  = {information retrieval;software maintenance;source code;software system;TLE;source-to-requirement trace links;information retrieval algorithms;structural changes;semantic changes;evolving software trace links;trace link evolver;refactoring detection tools;trace link evolution;Computer science;Software systems;Hazards;Information retrieval;Tools;Heuristic algorithms;Traceability;Evolution;Maintenance},
}

@InProceedings{lian2019-Traceability-reveals-quality-in-source,
  author    = {X. {Lian} and A. {Fakhry} and L. {Zhang} and J. {Cleland-Huang}},
  booktitle = {2015 IEEE/ACM 8th International Symposium on Software and Systems Traceability},
  title     = {Leveraging Traceability to Reveal the Tapestry of Quality Concerns in Source Code},
  year      = {2015},
  month     = {May},
  pages     = {50-56},
  abstract  = {Software quality concerns, related to attributes such as reliability, security, and performance, are realized through a series of architectural decisions impacting the choice of frameworks, styles, tactics, and even high-level design patterns. These decisions are often undocumented and, as a result, developers maybe unaware of the relationship between various sections of the code and quality concerns. In this paper we utilize an existing classifier to detect architectural tactics in code, and then present three different visualization techniques for visualizing the impact of quality concerns on code. We demonstrate our approach against the Cassandra database system and show that our visualizations offer potentially useful perspectives on the tapestry of quality concerns woven throughout the code.},
  doi       = {10.1109/SST.2015.15},
  groups    = {Visualization},
  issn      = {2157-2194},
  keywords  = {program diagnostics;program visualisation;software architecture;software quality;software reliability;source code (software);traceability;source code;software quality concerns;reliability;security;architectural decisions;classifier;architectural tactics;visualization techniques;Cassandra database system;Peer-to-peer computing;Visualization;Monitoring;Scalability;Heart beat;Biomedical monitoring;Security;Traceability;visualization;architecture;quality concerns},
}

@InProceedings{shin2015-guidelines-benchmark-auto-traceability,
  author    = {Y. {Shin} and J. H. {Hayes} and J. {Cleland-Huang}},
  booktitle = {2015 IEEE/ACM 8th International Symposium on Software and Systems Traceability},
  title     = {Guidelines for Benchmarking Automated Software Traceability Techniques},
  year      = {2015},
  month     = {May},
  pages     = {61-67},
  abstract  = {To comparatively evaluate automated trace ability solutions, we need to develop standardized benchmarks. However there is currently no consensus on how a benchmark should be constructed and used to evaluate competing techniques. In this paper we discuss recurring problems in evaluating trace ability techniques, identify essential properties that evaluation methods should possess, and provide guidelines for benchmarking software trace ability techniques. We illustrate the properties and guidelines using empirical evaluation of three software trace ability techniques on nine data sets.},
  doi       = {10.1109/SST.2015.13},
  groups    = {Metastudies, identification},
  issn      = {2157-2194},
  keywords  = {benchmark testing;program diagnostics;software engineering;automated software traceability technique;benchmarking;evaluation method;Measurement;Accuracy;Benchmark testing;Software;Guidelines;Software engineering;Communities;Traceability;measurement;evaluation metrics;benchmarks},
}

@InProceedings{li2013-trace-matrix-analyzer,
  author    = {W. {Li} and J. H. {Hayes} and F. {Yang} and K. {Imai} and J. {Yannelli} and C. {Carnes} and M. {Doyle}},
  booktitle = {2013 7th International Workshop on Traceability in Emerging Forms of Software Engineering (TEFSE)},
  title     = {Trace Matrix Analyzer (TMA)},
  year      = {2013},
  month     = {May},
  pages     = {44-50},
  abstract  = {A Trace Matrix (TM) represents the relationship between software engineering artifacts and is foundational for many software assurance techniques such as criticality analysis. In a large project, a TM might represent the relationships between thousands of elements of dozens of artifacts (for example, between design elements and code elements, between requirements and test cases). In mission- and safety-critical systems, a third party agent may be given the job to assess a TM prepared by the developer. Due to the size and complexity of the task, automated techniques are needed. We have developed a technique for analyzing a TM, called Trace Matrix Analyzer (TMA), so that third party agents can perform their work faster and more effectively. To validate, we applied TMA to two TMs with known problems and golden answersets: MoonLander and MODIS. We also asked an experienced software engineer to manually review the TM. We found that TMA properly identified TM issues and was much faster than manual review, but also falsely identified issues for one dataset. This work addresses the Trusted Grand Challenge, research projects 3, 5, and 6.},
  doi       = {10.1109/TEFSE.2013.6620153},
  groups    = {Trace analysis, identification},
  issn      = {2157-2194},
  keywords  = {formal specification;multi-agent systems;program diagnostics;safety-critical software;trace matrix analyzer;TMA;software engineering artifacts;software assurance techniques;code elements;mission-critical systems;safety-critical systems;third party agent;task complexity;automated techniques;MoonLander;MODIS;trusted grand challenge;research projects;Manuals;MODIS;Vectors;Software engineering;Noise measurement;Radio access networks;Educational institutions;Formal Specification;Temporal Requirements;Translation;Requirement Comprehension;Trusted Grand Challenge;Research Projects 3, 5, and 6},
}

@Article{nejat2012-traceability-sysml-safety-certification,
  author   = {Shiva Nejati and Mehrdad Sabetzadeh and Davide Falessi and Lionel Briand and Thierry Coq},
  journal  = {Information and Software Technology},
  title    = {A SysML-based approach to traceability management and design slicing in support of safety certification: Framework, tool support, and case studies},
  year     = {2012},
  issn     = {0950-5849},
  note     = {Special Section: Engineering Complex Software Systems through Multi-Agent Systems and Simulation},
  number   = {6},
  pages    = {569 - 590},
  volume   = {54},
  abstract = {Context
Traceability is one of the basic tenets of all safety standards and a key prerequisite for software safety certification. In the current state of practice, there is often a significant traceability gap between safety requirements and software design. Poor traceability, in addition to being a non-compliance issue on its own, makes it difficult to determine whether the design fulfills the safety requirements, mainly because the design aspects related to safety cannot be clearly identified.
Objective
The goal of this article is to develop a framework for specifying and automatically extracting design aspects relevant to safety requirements. This goal is realized through the combination of two components: (1) A methodology for establishing traceability between safety requirements and design, and (2) an algorithm that can extract for any given safety requirement a minimized fragment (slice) of the design that is sound, and yet easy to understand and inspect.
Method
We ground our framework on System Modeling Language (SysML). The framework includes a traceability information model, a methodology to establish traceability, and mechanisms for model slicing based on the recorded traceability information. The framework is implemented in a tool, named SafeSlice.
Results
We prove that our slicing algorithm is sound for temporal safety properties, and argue about the completeness of slices based on our practical experience. We report on the lessons learned from applying our approach to two case studies, one benchmark and one industrial case. Both studies indicate that our approach substantially reduces the amount of information that needs to be inspected for ensuring that a given (behavioral) safety requirement is met by the design.},
  doi      = {https://doi.org/10.1016/j.infsof.2012.01.005},
  groups   = {Metamodels, identification},
  keywords = {Safety certification, SysML, Traceability, Model slicing},
  url      = {http://www.sciencedirect.com/science/article/pii/S095058491200016X},
}

@InProceedings{gannous2019-Certification-into-Model-based-Testing-for-Safety-Critical-Systems,
  author    = {A. {Gannous} and A. {Andrews}},
  booktitle = {2019 IEEE 30th International Symposium on Software Reliability Engineering (ISSRE)},
  title     = {Integrating Safety Certification Into Model-Based Testing of Safety-Critical Systems},
  year      = {2019},
  month     = {Oct},
  pages     = {250-260},
  abstract  = {Testing plays an important role in assuring the safety of safety-critical systems (SCS). Testing SCSs should include tasks to test how the system operates in the presence of failures. With the increase of autonomous, sensing-based functionality in safety-critical systems, efficient and cost-effective testing that maximizes safety evidences has become increasingly challenging. A previously proposed framework for testing safety-critical systems called Model-Combinatorial based testing (MCbt) has the potential for addressing these challenges. MCbt is a framework that proposes an integration of model-based testing, fault analysis, and combinatorial testing to produce the maximum number of evidences for an efficient safety certification process but was never actually used to derive a specific testing approach. In this paper, we present a concrete application of MCbt with an application to a case study. The validation showed that MCbt is more efficient and produces more safety evidences compared to state-of-the-art testing approaches.},
  doi       = {10.1109/ISSRE.2019.00033},
  groups    = {mde},
  issn      = {2332-6549},
  keywords  = {certification;program diagnostics;program testing;safety-critical software;software fault tolerance;fault analysis;model-combinatorial based testing;cost-effective testing;sensing-based functionality;SCS testing;safety certification;safety evidences;MCbt;safety-critical systems;Model based Testing, Combinatorial Testing, Fault Modelling, Safety Analysis, Fault Tree Analysis, Finite State Machines, EFSM, CEFSM, Testing Safety-critical Systems},
}

@Conference{azevedo2019-traceability-metamodel-and-reference-model,
  author       = {Bruno Azevedo. and Mario Jino.},
  booktitle    = {Proceedings of the 14th International Conference on Evaluation of Novel Approaches to Software Engineering - Volume 1: ENASE,},
  title        = {Modeling Traceability in Software Development: A Metamodel and a Reference Model for Traceability},
  year         = {2019},
  organization = {INSTICC},
  pages        = {322-329},
  publisher    = {SciTePress},
  abstract     = {Many traceability models lack well-defined traceability link types, provide incomplete coverage of situations, do not provide mechanisms to ensure consistency of traceability, and consider only requirements traceability ignoring other activities of development. We propose a set of basic concepts for traceability, a reference model, and a comprehensive metamodel for traceability created using this reference model. The reference model defines: basic elements for traceability, basic actions to be done on artifacts, basic properties that sets of link types and artifact types should have, basic categories that should be realized regarding these sets, and basic set of processes for traceability. The metamodel is composed of a visual model defining how its elements interact, the definition and semantic description of link types and artifact types which realize the categories of the reference model, and a set of detailed processes describing the steps to maintain traceability and system consistency. Our proposal aims to reduce the problems identified; the reference model provides directions to help the creation, or evaluation, of a traceability model; the metamodel provides semantically described traceability link types, coverage of the most common situations, mechanisms to ensure consistency of traceability, and covers the most common activities in software development.},
  doi          = {10.5220/0007715103220329},
  file         = {:azevedo2019-traceability-metamodel-and-reference-model.pdf:PDF},
  groups       = {Metamodels, identification},
  isbn         = {978-989-758-375-9},
  keywords     = {read, prio1, rank4},
  priority     = {prio1},
  ranking      = {rank4},
  readstatus   = {read},
}

@Article{tran2011-vbTrace-view-based-MDD-processdriven-SOAs-traceability,
  author   = {Tran, Huy and Zdun, Uwe and Dustdar, Schahram},
  journal  = {Software \& Systems Modeling},
  title    = {VbTrace: using view-based and model-driven development to support traceability in process-driven SOAs},
  year     = {2011},
  issn     = {1619-1374},
  number   = {1},
  pages    = {5--29},
  volume   = {10},
  abstract = {In process-driven, service-oriented architectures, there are a number of important factors that hinder the traceability between design and implementation artifacts. First of all, there are no explicit links between process design and implementation languages not only due to the differences of syntax and semantics but also the differences of granularity. The second factor is the complexity caused by tangled process concerns that multiplies the difficulty of analyzing and understanding the trace dependencies. Finally, there is a lack of adequate tool support for establishing and maintaining the trace dependencies between process designs and implementations. We present in this article a view-based, model-driven traceability approach that tackles these challenges. Our approach supports (semi-)automatically eliciting and (semi-)formalizing trace dependencies among process development artifacts at different levels of granularity and abstraction. A proof-of-concept tool support has been realized, and its functionality is illustrated via an industrial case study.},
  groups   = {Visualization},
  refid    = {Tran2011},
  url      = {https://doi.org/10.1007/s10270-009-0137-0},
}

@Article{goknil2014-change-impact-analysis-for-requirement-metamodel,
  author   = {Arda Goknil and Ivan Kurtev and Klaas [van den Berg] and Wietze Spijkerman},
  journal  = {Information and Software Technology},
  title    = {Change impact analysis for requirements: A metamodeling approach},
  year     = {2014},
  issn     = {0950-5849},
  number   = {8},
  pages    = {950 - 972},
  volume   = {56},
  abstract = {Context
Following the evolution of the business needs, the requirements of software systems change continuously and new requirements emerge frequently. Requirements documents are often textual artifacts with structure not explicitly given. When a change in a requirements document is introduced, the requirements engineer may have to manually analyze all the requirements for a single change. This may result in neglecting the actual impact of a change. Consequently, the cost of implementing a change may become several times higher than expected.
Objective
In this paper, we aim at improving change impact analysis in requirements by using formal semantics of requirements relations and requirements change types.
Method
In our previous work we present a requirements metamodel with commonly used requirements relation types and their semantics formalized in first-order logic. In this paper the classification of requirements changes based on structure of a textual requirement is provided with formal semantics. The formalization of requirements relations and changes is used for propagating proposed changes and consistency checking of proposed changes in requirements models. The tool support for change impact analysis in requirements models is an extension of our Tool for Requirements Inferencing and Consistency Checking (TRIC).
Results
The described approach for change impact analysis helps in the elimination of some false positive impacts in change propagation, and enables consistency checking of changes.
Conclusion
We illustrate our approach in an example which shows that the formal semantics of requirements relations and change classification enables change alternatives to be proposed semi-automatically, the reduction of some false positive impacts and contradicting changes in requirements to be determined.},
  doi      = {https://doi.org/10.1016/j.infsof.2014.03.002},
  groups   = {Metamodels},
  keywords = {Requirements metamodel, Change impact analysis, Proposing and propagating changes},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584914000615},
}

@InProceedings{fittkau2013-explorviz-Trace-Visualization,
  author    = {F. {Fittkau} and J. {Waller} and C. {Wulf} and W. {Hasselbring}},
  booktitle = {2013 First IEEE Working Conference on Software Visualization (VISSOFT)},
  title     = {Live trace visualization for comprehending large software landscapes: The ExplorViz approach},
  year      = {2013},
  month     = {Sep.},
  pages     = {1-4},
  abstract  = {The increasing code complexity in modern enterprise software systems exceeds the capabilities of most software engineers to understand the system's behavior by just looking at its program code. Large software landscapes, e.g., applications in a cloud infrastructure, further increase this complexity. A solution to these problems is visualizing the applications of the software landscape to ease program comprehension and to understand the respective communication. An established visualization concept is the 3D city metaphor. It utilizes the familiarity with navigating a city to improve program comprehension. Dynamic analysis, e.g., monitoring, can provide the required program traces of the communication. In this paper, we present our live visualization approach of monitoring traces for large software landscapes. It combines a landscape and a system level perspective. The landscape level perspective provides an overview of the software landscape utilizing the viewer's familiarity with UML. The system level perspective provides a visualization utilizing the city metaphor for each software system.},
  doi       = {10.1109/VISSOFT.2013.6650536},
  groups    = {Visualization},
  keywords  = {cloud computing;data visualisation;software maintenance;Unified Modeling Language;software system;UML;landscape level perspective;program traces;dynamic analysis;program comprehension;3D city metaphor;cloud infrastructure;ExplorViz approach;software landscapes;live trace visualization;Visualization;Three-dimensional displays;Cities and towns;Unified modeling language;Software systems;Monitoring},
}

@Article{borg2014-SmS-IR-for-traceability,
  author   = {Borg, Markus and Runeson, Per and Ardö, Anders},
  journal  = {Empirical Software Engineering},
  title    = {Recovering from a decade: a systematic mapping of information retrieval approaches to software traceability},
  year     = {2014},
  issn     = {1573-7616},
  number   = {6},
  pages    = {1565--1616},
  volume   = {19},
  abstract = {Engineers in large-scale software development have to manage large amounts of information, spread across many artifacts. Several researchers have proposed expressing retrieval of trace links among artifacts, i.e. trace recovery, as an Information Retrieval (IR) problem. The objective of this study is to produce a map of work on IR-based trace recovery, with a particular focus on previous evaluations and strength of evidence. We conducted a systematic mapping of IR-based trace recovery. Of the 79 publications classified, a majority applied algebraic IR models. While a set of studies on students indicate that IR-based trace recovery tools support certain work tasks, most previous studies do not go beyond reporting precision and recall of candidate trace links from evaluations using datasets containing less than 500 artifacts. Our review identified a need of industrial case studies. Furthermore, we conclude that the overall quality of reporting should be improved regarding both context and tool details, measures reported, and use of IR terminology. Finally, based on our empirical findings, we present suggestions on how to advance research on IR-based  trace recovery.},
  file     = {:borg2014-SmS-IR-for-traceability.pdf:PDF},
  groups   = {meta, NLP use, identification},
  refid    = {Borg2014},
  url      = {https://doi.org/10.1007/s10664-013-9255-y},
}

@InProceedings{post2009-link-functional-req-to-verification,
  author    = {H. {Post} and C. {Sinz} and F. {Merz} and T. {Gorges} and T. {Kropf}},
  booktitle = {2009 17th IEEE International Requirements Engineering Conference},
  title     = {Linking Functional Requirements and Software Verification},
  year      = {2009},
  month     = {Aug},
  pages     = {295-302},
  abstract  = {Synchronization between component requirements and implementation centric tests remains a challenge that is usually addressed by requirements reviews with testers and traceability policies. The claim of this work is that linking requirements, their scenario-based formalizations, and software verification provides a promising extension to this approach. Formalized scenarios, for example in the form of low-level assume/assert statements in C, are easier to trace to requirements than traditional test sets. For a verification engineer, they offer an opportunity to better participate in requirements changes. Changes in requirements can be more easily propagated because adapting formalized scenarios is often easier than deriving and updating a large set of test cases. The proposed idea is evaluated in a case study encompassing over 50 functional requirements of an automotive software developed at Robert Bosch GmbH. Results indicate that requirement formalization together with formal verification leads to the discovery of implementation problems missed in a traditional testing process.},
  doi       = {10.1109/RE.2009.43},
  issn      = {2332-6441},
  keywords  = {formal specification;object-oriented programming;program diagnostics;program testing;program verification;software maintenance;systems analysis;functional requirement review;software verification;component requirement change;software testing;software traceability policy;scenario-based formalization;C statement;Joining processes;Software testing;System testing;Automotive engineering;Programming;Computer industry;Safety;Computer science;Control systems;Formal verification;functional requirements;verification;bounded model checking},
}

@InProceedings{guo2017-semantically-enhanced-tracebility-deep-learning,
  author    = {Guo, Jin and Cheng, Jinghui and Cleland-Huang, Jane},
  booktitle = {Proceedings of the 39th International Conference on Software Engineering},
  title     = {Semantically Enhanced Software Traceability Using Deep Learning Techniques},
  year      = {2017},
  pages     = {3–14},
  publisher = {IEEE Press},
  series    = {ICSE ’17},
  abstract  = {In most safety-critical domains the need for traceability is prescribed by certifying bodies. Trace links are generally created among requirements, design, source code, test cases and other artifacts, however, creating such links manually is time consuming and error prone. Automated solutions use information retrieval and machine learning techniques to generate trace links, however, current techniques fail to understand semantics of the software artifacts or to integrate domain knowledge into the tracing process and therefore tend to deliver imprecise and inaccurate results. In this paper, we present a solution that uses deep learning to incorporate requirements artifact semantics and domain knowledge into the tracing solution. We propose a tracing network architecture that utilizes Word Embedding and Recurrent Neural Network (RNN) models to generate trace links. Word embedding learns word vectors that represent knowledge of the domain corpus and RNN uses these word vectors to learn the sentence semantics of requirements artifacts. We trained 360 different configurations of the tracing network using existing trace links in the Positive Train Control domain and identified the Bidirectional Gated Recurrent Unit (BI-GRU) as the best model for the tracing task. BI-GRU significantly out-performed state-of-the-art tracing methods including the Vector Space Model and Latent Semantic Indexing.},
  doi       = {10.1109/ICSE.2017.9},
  groups    = {NLP use, identification},
  isbn      = {9781538638682},
  keywords  = {traceability, recurrent neural network, semantic representation, deep learning},
  location  = {Buenos Aires, Argentina},
  numpages  = {12},
  url       = {https://doi.org/10.1109/ICSE.2017.9},
}

@Article{rutle2018-MT-coevolution-with-traceability-and-graph-transfo,
  author    = {A Rutle and L Iovino and H König and Z Diskin},
  journal   = {Modelling Foundations and Applications},
  title     = {Automatic Transformation Co-evolution Using Traceability Models and Graph Transformation},
  year      = {2018},
  volume    = {10890},
  abstract  = {In rule-based approaches, a model transformation definition tells how an instance of a source model should be transformed to an instance of a target model. As these models undergo changes, model transformations defined over these models may get out of sync. Restoring conformance between model transformations and the models is a complex and error prone task. In this paper, we propose a formal approach to automatically co-evolve model transformations according to the evolution of the models. The approach is based on encoding the model transformation definition as a traceability model and the evolution of the models as applications of graph transformation rules. These rules are used to obtain an evolved traceability model from the original traceability model. We will identify the criteria which need to be fulfilled in order to make this automatic co-evolution possible. We provide a tool support for this procedure, in which the evolved model transformation definition is derived from the evolved traceability model.},
  address   = {Cham},
  editor    = {Pierantonio A., Trujillo S.},
  groups    = {MT, Coevolution, mde, identification},
  publisher = {Springer},
}

@Article{amar2013-model-coevolution-uding-traceability,
  author    = {B Amar and H Leblanc and B Coulette and P Dhaussy},
  journal   = {Communications in Computer and Information Science},
  title     = {Automatic Co-evolution of Models Using Traceability},
  year      = {2013},
  volume    = {170},
  abstract  = {Model Driven Engineering allows models to be considered as data and then used as first class entities in dedicated transformations languages. As a result, recurring problems linked to software production are emerging in this new development context. One such problem is to maintain an inter-model consistency during execution of a process based on models and model transformations. When some related models must co-evolve, what appends when different transformations are applied separately on each of these models? To prevent this, we assume that one of these models is the master model and we propose an automatic co-evolution of the other models based on the traceability of the main transformation. So the contribution of this paper is a conceptual framework where the necessary transformations of repercussion can be easily deployed.},
  address   = {Berlin, Heidelberg},
  editor    = {Cordeiro J., Virvou M., Shishkov B.},
  groups    = {Coevolution, mde},
  publisher = {Springer},
}

@InProceedings{wenzel2007-Tracing-model-elements,
  author    = {S. {Wenzel} and H. {Hutter} and U. {Kelter}},
  booktitle = {2007 IEEE International Conference on Software Maintenance},
  title     = {Tracing Model Elements},
  year      = {2007},
  month     = {Oct},
  pages     = {104-113},
  abstract  = {In model-driven engineering developers work mainly or only with models, which exist in many versions. This paper presents an approach to trace single model elements or groups of elements within a version history of a model. It also offers analysis capabilities such as detection of logical coupling between model elements. The approach uses a differencing algorithm blown as SiDiff to identify similar elements in different versions of a model. SiDiff is highly configurable and thus our tracing approach can be adapted to all diagram types of the UML and to a large set of domain specific languages. The approach has been implemented as an Eclipse plug-in that visualizes all relevant information about the traces and it allows developers to interactively explore details. It has been evaluated by several groups of test persons; they considered most of the functions of the tool to be very useful.},
  doi       = {10.1109/ICSM.2007.4362623},
  groups    = {mde, identification},
  issn      = {1063-6773},
  keywords  = {program diagnostics;software engineering;Unified Modeling Language;model-driven engineering developer;model element tracing;SiDiff;UML;domain specific language;differencing algorithm;tracing approach;Eclipse plug-in;information visualization;Object oriented modeling;Mathematical model;Power system modeling;Unified modeling language;Model driven engineering;Software engineering;History;Domain specific languages;Collaborative software;Project management},
}

@InProceedings{santiago2013traceability-in-MDE,
  author    = {Santiago, Iv{\'a}n and Vara, Juan Manuel and de Castro, Mar{\'i}a Valeria and Marcos, Esperanza},
  booktitle = {Conceptual Modeling},
  title     = {Towards the Effective Use of Traceability in Model-Driven Engineering Projects},
  year      = {2013},
  address   = {Berlin, Heidelberg},
  editor    = {Ng, Wilfred and Storey, Veda C. and Trujillo, Juan C.},
  pages     = {429--437},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The key role of models in any Model-Driven Engineering (MDE) process provides a new landscape for dealing with traceability. In the context of MDE traces are merely links between the elements of the different models handled along the software development cycle. Traces can be consequently stored in models that can be processed by means of model-based techniques. To take advantage of this scenario, this paper introduces iTrace, a framework for the management and analysis of traceability information in MDE projects. We present the methodological proposal bundled in the framework as well as the tooling that supports it. Finally, a case study is used to introduce some of the functionalities offered by the framework.},
  groups    = {Metamodels, mde, Trace analysis},
  isbn      = {978-3-642-41924-9},
}

@InProceedings{aranega2011-trace-for-mutation-analysis-in-model-transformation,
  author    = {Aranega, Vincent and Mottu, Jean-Marie and Etien, Anne and Dekeyser, Jean-Luc},
  booktitle = {Models in Software Engineering},
  title     = {Traceability for Mutation Analysis in Model Transformation},
  year      = {2011},
  address   = {Berlin, Heidelberg},
  editor    = {Dingel, Juergen and Solberg, Arnor},
  pages     = {259--273},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {Model transformation can't be directly tested using program techniques. Those have to be adapted to model characteristics. In this paper we focus on one test technique: mutation analysis. This technique aims to qualify a test data set by analyzing the execution results of intentionally faulty program versions. If the degree of qualification is not satisfactory, the test data set has to be improved. In the context of model, this step is currently relatively fastidious and manually performed.},
  groups    = {MT, mde},
  isbn      = {978-3-642-21210-9},
}

@Article{seibel2010-dynamic-hierarchical-models-comprehensive-traceability,
  author   = {Seibel, Andreas and Neumann, Stefan and Giese, Holger},
  journal  = {Software \& Systems Modeling},
  title    = {Dynamic hierarchical mega models: comprehensive traceability and its efficient maintenance},
  year     = {2010},
  issn     = {1619-1374},
  number   = {4},
  pages    = {493--528},
  volume   = {9},
  abstract = {In the world of model-driven engineering (MDE) support for traceability and maintenance of traceability information is essential. On the one hand, classical traceability approaches for MDE address this need by supporting automated creation of traceability information on the model element level. On the other hand, global model management approaches manually capture traceability information on the model level. However, there is currently no approach that supports comprehensive traceability, comprising traceability information on both levels, and efficient maintenance of traceability information, which requires a high-degree of automation and scalability. In this article, we present a comprehensive traceability approach that combines classical traceability approaches for MDE and global model management in form of dynamic hierarchical mega models. We further integrate efficient maintenance of traceability information based on top of dynamic hierarchical mega models. The proposed approach is further outlined by using an industrial case study and by presenting an implementation of the concepts in form of a prototype.},
  groups   = {Metamodels, mde, Trace integrity},
  refid    = {Seibel2010},
  url      = {https://doi.org/10.1007/s10270-009-0146-z},
}

@Article{schwarz2010-graph-based-traceability,
  author   = {Schwarz, Hannes and Ebert, Jürgen and Winter, Andreas},
  journal  = {Software \& Systems Modeling},
  title    = {Graph-based traceability: a comprehensive approach},
  year     = {2010},
  issn     = {1619-1374},
  number   = {4},
  pages    = {473--492},
  volume   = {9},
  abstract = {In recent years, traceability has been globally accepted as being a key success factor of software development projects. However, the multitude of different, poorly integrated taxonomies, approaches and technologies impedes the application of traceability techniques in practice. This paper presents a comprehensive view on traceability, pertaining to the whole software development process. Based on the state of the art, the field is structured according to six specific activities related to traceability as follows: definition, recording, identification, maintenance, retrieval, and utilization. Using graph technology, a comprehensive and seamless approach for supporting these activities is derived, combining them in one single conceptual framework. This approach supports the definition of metamodels for traceability information, recording of traceability information in graph-based repositories, identification and maintenance of traceability relationships using transformations, as well as retrieval and utilization of traceability information using a graph query language. The approach presented here is applied in the context of the ReDSeeDS project (Requirements Driven Software Development System) that aims at requirements-based software reuse. ReDSeeDS makes use of traceability information to determine potentially reusable architectures, design, or code artifacts based on a given set of reusable requirements. The project provides case studies from different domains for the validation of the approach.},
  file     = {:schwarz2010-graph-based-traceability.pdf:PDF},
  groups   = {Metamodels, identification},
  refid    = {Schwarz2010},
  url      = {https://doi.org/10.1007/s10270-009-0141-4},
}

@Article{winkler2010-survey-traceability-and-MDE,
  author   = {Winkler, Stefan and von Pilgrim, Jens},
  journal  = {Software and Systems Modeling},
  title    = {A survey of traceability in requirements engineering and model-driven development},
  year     = {2010},
  issn     = {1619-1374},
  number   = {4},
  pages    = {529--565},
  volume   = {9},
  abstract = {Traceability--the ability to follow the life of software artifacts--is a topic of great interest to software developers in general, and to requirements engineers and model-driven developers in particular. This article aims to bring those stakeholders together by providing an overview of the current state of traceability research and practice in both areas. As part of an extensive literature survey, we identify commonalities and differences in these areas and uncover several unresolved challenges which affect both domains. A good common foundation for further advances regarding these challenges appears to be a combination of the formal basis and the automated recording opportunities of MDD on the one hand, and the more holistic view of traceability in the requirements engineering domain on the other hand.},
  groups   = {meta, mde, Metastudies, identification},
  refid    = {Winkler2010},
  url      = {https://doi.org/10.1007/s10270-009-0145-0},
}

@Article{paige2010-MDE-Traceability-classifications,
  author   = {Paige, Richard and Olsen, Gøran and Kolovos, Dimitrios and Zschaler, Steffen and Power, Christopher},
  title    = {Building Model-Driven Engineering Traceability Classifications},
  year     = {2010},
  month    = {01},
  abstract = {Model-Driven Engineering involves the application of many differ- ent model management operations, some automated, some manual. For devel- opers to stay in control of their models and codebase, trace information must be maintained by all model management operations. This leads to a large number of trace links, which themselves need to be managed, queried, and evaluated. Classifications of traceability and trace links are an essential capability required for understanding and managing trace links. We present a process for building traceability classifications for a variety of widely used and accepted operations (both automated and manual) and show the results of applying the process to a rich traceability context.},
  file     = {:paige2010-MDE-Traceability-classifications.pdf:PDF},
  groups   = {mde, Metastudies},
}

@InProceedings{helming2009-traceability-change-awareness,
  author   = {Helming, Jonas and Koegel, Maximilian and Naughton, Helmut and David, Jörn and Shterev, Aleksandar},
  title    = {Traceability-Based Change Awareness},
  year     = {2009},
  month    = {10},
  pages    = {372-376},
  volume   = {5795},
  abstract = {Many tools in software engineering projects support the visualization and collaborative modification of custom sets of artifacts. This includes tools for requirements engineering, UML tools for design, project management tools, developer tools and many more. A key factor for success in software engineering projects is the collective understanding of changes applied to these artifacts. To support this, there are several strategies to automatically notify project participants about relevant changes. Known strategies are limited to a fixed set of artifacts and/or make no use of traceability information to supply change notifications. This paper proposes a change notification approach based on traceability in a unified model and building upon operation-based change tracking. The unified model explicitly combines system specification models and project management models into one fully traceable model. To show the benefit of our approach we compare it to related approaches in a case study.},
  doi      = {10.1007/978-3-642-04425-0_28},
}

@InProceedings{grammel2010-facet-based-traceability-data-extraction-in-MDE,
  author    = {Grammel, Birgit and Kastenholz, Stefan},
  booktitle = {Proceedings of the 6th ECMFA Traceability Workshop},
  title     = {A Generic Traceability Framework for Facet-Based Traceability Data Extraction in Model-Driven Software Development},
  year      = {2010},
  address   = {New York, NY, USA},
  pages     = {7–14},
  publisher = {Association for Computing Machinery},
  series    = {ECMFA-TW ’10},
  abstract  = {Traceability of artefacts induces the means of understanding the complexity of logical relations existing among artefacts, that are created during software development. In turn, this provides the necessary knowledge for reasoning about the quality of software. With the inception of Model-Driven Software Engineering, the advantage of generating traceability information automatically, eases the problem of creating and maintaining trace links, which is a labor intensive task, when done manually. Yet, there is still a wide range of open challenges in existing traceability solutions and a need to consolidate traceability domain knowledge. This paper proposes a generic traceability framework for augmenting arbitrary model transformation approaches with a traceability mechanism. Essentially, this augmentation is based on a domain-specific language for traceability, accounting for facet-based data extraction.},
  doi       = {10.1145/1814392.1814394},
  groups    = {mde, MT, Metamodels},
  isbn      = {9781605589930},
  location  = {Paris, France},
  numpages  = {8},
  url       = {https://doi.org/10.1145/1814392.1814394},
}

@Article{santiago2012-MDE-as-a-new-landscape-for-traceability-SLR,
  author   = {Iván Santiago and Álvaro Jiménez and Juan Manuel Vara and Valeria [De Castro] and Verónica A. Bollati and Esperanza Marcos},
  journal  = {Information and Software Technology},
  title    = {Model-Driven Engineering as a new landscape for traceability management: A systematic literature review},
  year     = {2012},
  issn     = {0950-5849},
  note     = {Special Section on Software Reliability and Security},
  number   = {12},
  pages    = {1340 - 1356},
  volume   = {54},
  abstract = {Context
Model-Driven Engineering provides a new landscape for dealing with traceability in software development.
Objective
Our goal is to analyze the current state of the art in traceability management in the context of Model-Driven Engineering.
Method
We use the systematic literature review based on the guidelines proposed by Kitchenham. We propose five research questions and six quality assessments.
Results
Of the 157 relevant studies identified, 29 have been considered primary studies. These studies have resulted in 17 proposals.
Conclusion
The evaluation shows that the most addressed operations are storage, CRUD and visualization, while the most immature operations are exchange and analysis traceability information.},
  doi      = {https://doi.org/10.1016/j.infsof.2012.07.008},
  groups   = {Featuring, meta, mde, Metastudies, identification},
  keywords = {Traceability, Model-Driven Engineering, Systematic literature review},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584912001346},
}

@Article{vara2014-traceability-in-MDD-MTransfo,
  author    = {Juan Manuel Vara and Ver{\'{o}}nica Andrea Bollati and {\'{A}}lvaro Jim{\'{e}}nez and Esperanza Marcos},
  journal   = {{IEEE} Trans. Software Eng.},
  title     = {Dealing with Traceability in the MDDof Model Transformations},
  year      = {2014},
  number    = {6},
  pages     = {555--583},
  volume    = {40},
  abstract  = {Traceability has always been acknowledged as a relevant topic in Software Engineering. However, keeping track of the relationships between the different assets involved in a development process is a complex and tedious task. The fact that the main assets handled in any model-driven engineering project are models and model transformations eases the task. In order to take advantage of this scenario, which has not been appropriately capitalized on by the most widely adopted model transformation languages before, this work presents MeTAGeM-Trace, a methodological and technical proposal with which to support the model-driven development of model transformations that include trace generation. The underlying idea is to start from a high-level specification of the transformation which is subsequently refined into lower-level transformation models in terms of a set of DSLs until the source code that implements the transformation can be generated. Running this transformation produces not only the corresponding target models, but also a trace model between the elements of the source and target models. As part of the proposal, an EMF-based toolkit has been developed to support the development of ATL and ETL model transformations. This toolkit has been empirically validated by conducting a set of case studies following a systematic research methodology.},
  doi       = {10.1109/TSE.2014.2316132},
  file      = {:mde/vara2014-traceability-in-MDD-MTransfo.pdf:PDF},
  groups    = {MT, mde},
  timestamp = {Thu, 15 Jun 2017 21:30:50 +0200},
  url       = {https://doi.org/10.1109/TSE.2014.2316132},
}

@Article{marcen2020-req2model-with-EA-ranking-train-system,
  author    = {Ana Cristina Marc{\'{e}}n and Ra{\'{u}}l Lape{\~{n}}a and Oscar Pastor and Carlos Cetina},
  journal   = {J. Syst. Softw.},
  title     = {Traceability Link Recovery between Requirements and Models using an Evolutionary Algorithm Guided by a Learning to Rank Algorithm: Train control and management case},
  year      = {2020},
  pages     = {110519},
  volume    = {163},
  abstract  = {Traceability Link Recovery (TLR) has been a topic of interest for many years within the software engineering community. In recent years, TLR has been attracting more attention, becoming the subject of both fundamental and applied research. However, there still exists a large gap between the actual needs of industry on one hand and the solutions published through academic research on the other.

In this work, we propose a novel approach, named Evolutionary Learning to Rank for Traceability Link Recovery (TLR-ELtoR). TLR-ELtoR recovers traceability links between a requirement and a model through the combination of evolutionary computation and machine learning techniques, generating as a result a ranking of model fragments that can realize the requirement.

TLR-ELtoR was evaluated in a real-world case study in the railway domain, comparing its outcomes with five TLR approaches (Information Retrieval, Linguistic Rule-based, Feedforward Neural Network, Recurrent Neural Network, and Learning to Rank). The results show that TLR-ELtoR achieved the best results for most performance indicators, providing a mean precision value of 59.91%, a recall value of 78.95%, a combined F-measure of 62.50%, and a MCC value of 0.64. The statistical analysis of the results assesses the magnitude of the improvement, and the discussion presents why TLR-ELtoR achieves better results than the baselines.},
  doi       = {10.1016/j.jss.2020.110519},
  groups    = {NLP use, identification},
  timestamp = {Thu, 19 Mar 2020 10:23:20 +0100},
  url       = {https://doi.org/10.1016/j.jss.2020.110519},
}

@Book{ruiz18-traceME-conceptual-model-evolution,
  author    = {Marcela Ruiz},
  publisher = {Springer},
  title     = {TraceME: {A} Traceability-Based Method for Conceptual Model Evolution - Model-Driven Techniques, Tools, Guidelines, and Open Challenges in Conceptual Model Evolution},
  year      = {2018},
  isbn      = {978-3-319-89715-8},
  series    = {Lecture Notes in Business Information Processing},
  volume    = {312},
  abstract  = {This book presents TraceME, a traceability-based method for conceptual model evolution whose general purpose is to support the evolution of information systems. By providing a set of four TraceME chunks, TraceME is situational-oriented. In this way, it can be adapted to support different evolution projects by just assembling the TraceME chunks. To facilitate its industrial adoption, open source tools were developed and described which support the implementation of the TraceME chunks.

The work presented highlights various research endeavors for the development of methods and techniques to automate the evolution of software systems. It explores the requirements engineering field as a steppingstone to a successful software development processes. In 2017, the underlying PhD dissertation won the “CAiSE PhD award”, granted to outstanding PhD theses in the field of Information Systems Engineering.},
  doi       = {10.1007/978-3-319-89716-5},
  groups    = {mde, Coevolution},
  timestamp = {Wed, 16 May 2018 14:25:04 +0200},
  url       = {https://doi.org/10.1007/978-3-319-89716-5},
}

@InProceedings{aboussoror2012-Seeing-errors-trace-visualisation,
  author    = {El Arbi Aboussoror and Ileana Ober and Iulian Ober},
  booktitle = {Model Driven Engineering Languages and Systems - 15th International Conference, {MODELS} 2012, Innsbruck, Austria, September 30-October 5, 2012. Proceedings},
  title     = {Seeing Errors: Model Driven Simulation Trace Visualization},
  year      = {2012},
  editor    = {Robert B. France and J{\"{u}}rgen Kazmeier and Ruth Breu and Colin Atkinson},
  pages     = {480--496},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {7590},
  abstract  = {Powerful theoretical frameworks exist for model validation and verification, yet their use in concrete projects is limited. This is partially due to the fact that the results of model verification and simulation are difficult to exploit. This paper reports on a model driven approach that supports the user during the error diagnosis phases, by allowing customizable simulation trace visualization. Our thesis is that we can use models to significantly improve the information visualization during the diagnosis phase. This thesis is supported by Metaviz - a model-driven framework for simulation trace visualization. Metaviz uses the IFx-OMEGA model validation platform and a state-of-the-art information visualization reference model together with a well-defined development process guiding the user into building custom visualizations,essentially by defining model transformations. This approach has the potential to improve the practical usage of modeling techniques and to increase the usability and attractiveness of model validation tools.},
  doi       = {10.1007/978-3-642-33666-9\_31},
  file      = {:aboussoror2012-Seeing-errors-trace-visualisation.pdf:PDF},
  groups    = {Metamodels, mde},
  timestamp = {Tue, 14 May 2019 10:00:45 +0200},
  url       = {https://doi.org/10.1007/978-3-642-33666-9\_31},
}

@InProceedings{grammel2012-model-matching-for-traceability-in-MDE,
  author    = {Birgit Grammel and Stefan Kastenholz and Konrad Voigt},
  booktitle = {Model Driven Engineering Languages and Systems - 15th International Conference, {MODELS} 2012, Innsbruck, Austria, September 30-October 5, 2012. Proceedings},
  title     = {Model Matching for Trace Link Generation in Model-Driven Software Development},
  year      = {2012},
  editor    = {Robert B. France and J{\"{u}}rgen Kazmeier and Ruth Breu and Colin Atkinson},
  pages     = {609--625},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {7590},
  abstract  = {With the advent of Model-driven Software Engineering, the advantage of generating trace links between source and target model elements automatically, eases the problem of creating and maintaining traceability data. Yet, an existing transformation engine as in the above case is not always given in model-based development, (i.e. when transformations are implemented manually) and can not be leveraged for the sake of trace link generation through the transformation mapping. We tackle this problem by using model matching techniques to generate trace links for arbitrary source and target models. Thereby, our approach is based on a novel, language-agnostic concept defining three similarity measures for matching. To achieve this, we exploit metamodel matching techniques for graph-based model matching. Furthermore, we evaluate our approach according to large-scale SAP business transformations and the ATL Zoo.},
  doi       = {10.1007/978-3-642-33666-9\_39},
  groups    = {Metamodels, mde},
  timestamp = {Tue, 14 May 2019 10:00:45 +0200},
  url       = {https://doi.org/10.1007/978-3-642-33666-9\_39},
}

@InProceedings{mader2010-visual-tracability-modeling-language,
  author    = {Patrick M{\"{a}}der and Jane Cleland{-}Huang},
  booktitle = {Model Driven Engineering Languages and Systems - 13th International Conference, {MODELS} 2010, Oslo, Norway, October 3-8, 2010, Proceedings, Part {I}},
  title     = {A Visual Traceability Modeling Language},
  year      = {2010},
  editor    = {Dorina C. Petriu and Nicolas Rouquette and {\O}ystein Haugen},
  pages     = {226--240},
  publisher = {Springer},
  series    = {Lecture Notes in Computer Science},
  volume    = {6394},
  abstract  = {Software traceability is effort intensive and must be applied strategically in order to maximize its benefits and justify its costs. Unfortunately, development tools provide only limited support for traceability, and as a result users often construct trace queries using generic query languages which require intensive knowledge of the data-structures in which artifacts are stored. In this paper, we propose a usage-centered traceability process that utilizes UML class diagrams to define traceability strategies for a project and then visually represents trace queries as constraints upon subsets of the model. The Visual Trace Modeling Language (VTML) allows users to model queries while hiding the underlying technical details and data structures. The approach has been demonstrated through a prototype system and and evaluated through a preliminary experiment to evaluate the expressiveness and readability of VTML in comparison to generic SQL queries.},
  doi       = {10.1007/978-3-642-16145-2\_16},
  groups    = {mde, Visualization},
  timestamp = {Tue, 14 May 2019 10:00:45 +0200},
  url       = {https://doi.org/10.1007/978-3-642-16145-2\_16},
}

@InProceedings{ziegenhagen2020-tracing-life-cycles,
  author    = {Dennis Ziegenhagen and Elke Pulverm{\"{u}}ller and Andreas Speck},
  booktitle = {Proceedings of the 15th International Conference on Evaluation of Novel Approaches to Software Engineering, {ENASE} 2020, Prague, Czech Republic, May 5-6, 2020},
  title     = {Capturing Tracing Data Life Cycles for Supporting Traceability},
  year      = {2020},
  editor    = {Raian Ali and Hermann Kaindl and Leszek A. Maciaszek},
  pages     = {564--571},
  publisher = {{SCITEPRESS}},
  abstract  = {Activities for achieving traceability in software development projects include planning, implementing, using and maintaining a suitable strategy. Current research aims at supporting these activities by automating the involved tasks, processes and applications. In this paper, we present a concept for developing a flexible framework which enables the integration of respective functional modules, e.g. artifact data extractors and trace link generators, to form traceability environments according to the project’s demands. By automating the execution of the framework’s components and monitoring artifact-related interactions between developers and their tools, the tracing data’s life cycle is captured and provided for further usages. This paper presents an exemplified framework setup which is used to demonstrate the path and enrichment of tracing data along these components. Furthermore, we discuss observations and findings which we made during defining and realizing the example. We aim at using this information to further improve the framework in order to support the implementation of traceability environments.},
  doi       = {10.5220/0009581805640571},
  timestamp = {Thu, 04 Jun 2020 17:11:38 +0200},
  url       = {https://doi.org/10.5220/0009581805640571},
}

@InProceedings{heisig2019-generic-traceability-metamodel-end-to-end-capra,
  author    = {Heisig, Philipp and Stegh\"{o}fer, Jan-Philipp and Brink, Christopher and Sachweh, Sabine},
  booktitle = {Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing},
  title     = {A Generic Traceability Metamodel for Enabling Unified End-to-End Traceability in Software Product Lines},
  year      = {2019},
  address   = {New York, NY, USA},
  pages     = {2344–2353},
  publisher = {Association for Computing Machinery},
  series    = {SAC ’19},
  abstract  = {Mature development methodologies like software product line engineering or model-driven engineering are more and more adopted in software development. Accordingly, the resulting development processes combine artifacts from different disciplines and on different abstraction levels. It is crucial that the relationship between these artifacts is explicitly maintained to be able to track the development process and the reasons for design decisions. This problem becomes exacerbated if variability is considered since it is a cross-cutting concern that impacts all disciplines and artifacts. Traceability links support the linking of artifacts across model boundaries in an end-to-end manner. However, existing traceability solutions are either limited to specific development processes, tools, and artifact types, lack in uniformity, or do not consider variability. Thus, this paper introduces a MOF-based generic traceability metamodel for establishing uniform traceability-enabled workflows in a variability-aware and model-based environment. Necessary steps for instantiating the metamodel to specific artifact types of certain development processes are described. We evaluate the proposed solution with an exemplar of a car headlight and demonstrate the benefits of a consistent traceability concept.},
  doi       = {10.1145/3297280.3297510},
  file      = {:heisig2019-generic-traceability-metamodel-end-to-end-capra.pdf:PDF},
  groups    = {Metamodels},
  isbn      = {9781450359337},
  keywords  = {requirement, software product line, component model, traceability, feature model, workflow, model-driven engineering},
  location  = {Limassol, Cyprus},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3297280.3297510},
}

@InProceedings{mader2008-rule-based-maintenance-post-requirements-traceability,
  author    = {P. {Mäder} and O. {Gotel} and I. {Philippow}},
  booktitle = {2008 16th IEEE International Requirements Engineering Conference},
  title     = {Rule-Based Maintenance of Post-Requirements Traceability Relations},
  year      = {2008},
  month     = {Sep.},
  pages     = {23-32},
  abstract  = {An accurate set of traceability relations between software development artifacts is desirable to support evolutionary development. However, even where an initial set of traceability relations has been established, their maintenance during subsequent development activities is time consuming and error prone, which results in traceability decay. This paper focuses solely on the problem of maintaining a set of traceability relations in the face of evolutionary change, irrespective of whether generated manually or via automated techniques, and it limits its scope to UML-driven development activities post-requirements specification. The paper proposes an approach for the automated update of existing traceability relations after changes have been made to UML analysis and design models. The update is based upon predefined rules that recognize elementary change events as constituent steps of broader development activities. A prototype traceMaintainer has been developed to demonstrate the approach. Currently, traceMaintainer can be used with two commercial software development tools to maintain their traceability relations. The prototype has been used in two experiments. The results are discussed and our ongoing work is summarized.},
  doi       = {10.1109/RE.2008.24},
  groups    = {Coevolution, Trace integrity, identification},
  issn      = {2332-6441},
  keywords  = {program diagnostics;software maintenance;Unified Modeling Language;rule-based maintenance;post-requirements traceability relation;traceability relations;software development artifacts;evolutionary development;traceability decay;evolutionary change;UML-driven development activities;post-requirements specification;UML analysis model;UML design model;predefined rules;Software systems;Unified modeling language;Prototypes;Programming;Software prototyping;Information retrieval;Computer science;USA Councils;Computer errors;Testing;Change;Post-requirements traceability;Rule-based traceability;Traceability maintenance},
}

@Article{antoniol2017-traceability-grand-challenges,
  author        = {Giuliano Antoniol and Jane Cleland{-}Huang and Jane Huffman Hayes and Michael Vierhauser},
  journal       = {CoRR},
  title         = {Grand Challenges of Traceability: The Next Ten Years},
  year          = {2017},
  volume        = {abs/1710.03129},
  abstract      = {n 2007, the software and systems traceability community met at the first Natural Bridge symposium on the Grand Challenges of Traceability to establish and address research goals for achieving effective, trustworthy, and ubiquitous traceability. Ten years later, in 2017, the community came together to evaluate a decade of progress towards achieving these goals. These proceedings document some of that progress. They include a series of short position papers, representing current work in the community organized across four process axes of traceability practice. The sessions covered topics from Trace Strategizing, Trace Link Creation and Evolution, Trace Link Usage, real-world applications of Traceability, and Traceability Datasets and benchmarks. Two breakout groups focused on the importance of creating and sharing traceability datasets within the research community, and discussed challenges related to the adoption of tracing techniques in industrial practice. Members of the research community are engaged in many active, ongoing, and impactful research projects. Our hope is that ten years from now we will be able to look back at a productive decade of research and claim that we have achieved the overarching Grand Challenge of Traceability, which seeks for traceability to be always present, built into the engineering process, and for it to have "effectively disappeared without a trace". We hope that others will see the potential that traceability has for empowering software and systems engineers to develop higher-quality products at increasing levels of complexity and scale, and that they will join the active community of Software and Systems traceability researchers as we move forward into the next decade of research.},
  archiveprefix = {arXiv},
  bibsource     = {dblp computer science bibliography, https://dblp.org},
  biburl        = {https://dblp.org/rec/journals/corr/abs-1710-03129.bib},
  eprint        = {1710.03129},
  file          = {:antoniol2017-traceability-grand-challenges.pdf:PDF},
  groups        = {meta, Metastudies},
  timestamp     = {Mon, 13 Aug 2018 16:48:11 +0200},
  url           = {http://arxiv.org/abs/1710.03129},
}

@InProceedings{borg2012-tracea-taxonomy-for-IR-tools,
  author    = {M. {Borg} and P. {Runeson} and L. {Brodén}},
  booktitle = {16th International Conference on Evaluation Assessment in Software Engineering (EASE 2012)},
  title     = {Evaluation of traceability recovery in context: A taxonomy for information retrieval tools},
  year      = {2012},
  month     = {May},
  pages     = {111-120},
  abstract  = {Background: Development of complex, software intensive systems generates large amounts of information. Several researchers have developed tools implementing information retrieval (IR) approaches to suggest traceability links among artifacts. Aim: We explore the consequences of the fact that a majority of the evaluations of such tools have been focused on benchmarking of mere tool output. Method: To illustrate this issue, we have adapted a framework of general IR evaluations to a context taxonomy specifically for IR-based traceability recovery. Furthermore, we evaluate a previously proposed experimental framework by conducting a study using two publicly available tools on two datasets originating from development of embedded software systems. Results: Our study shows that even though both datasets contain software artifacts from embedded development, the characteristics of the two datasets differ considerably, and consequently the traceability outcomes. Conclusions: To enable replications and secondary studies, we suggest that datasets should be thoroughly characterized in future studies on traceability recovery, especially when they can not be disclosed. Also, while we conclude that the experimental framework provides useful support, we argue that our proposed context taxonomy is a useful complement. Finally, we discuss how empirical evidence of the feasibility of IR-based traceability recovery can be strengthened in future research.},
  doi       = {10.1049/ic.2012.0014},
  groups    = {meta, Metastudies, NLP use, identification},
  keywords  = {embedded systems;information retrieval;program diagnostics;software engineering;system recovery;traceability recovery evaluation;information retrieval tool taxonomy;software intensive system development;traceability link;benchmarking;context taxonomy;embedded software system development;software artifact},
}

@InProceedings{borillo1992-linguistic-engineering-to-spacial-SE,
  author    = {Borillo, Mario and Borillo, Andr\'{e}e and Castell, N\'{u}ria and Latour, Dominique and Toussaint, Yannick and Verdejo, M. Felisa},
  booktitle = {Proceedings of the 10th European Conference on Artificial Intelligence},
  title     = {Applying Linguistic Engineering to Spatial Software Engineering: The Traceability Problem},
  year      = {1992},
  address   = {USA},
  pages     = {593–595},
  publisher = {John Wiley \& Sons, Inc.},
  series    = {ECAI ’92},
  groups    = {NLP use},
  isbn      = {0471936081},
  location  = {Vienna, Austria},
  numpages  = {3},
}

@Article{antoniol2002-tracing-code-documentation-links,
  author   = {G. {Antoniol} and G. {Canfora} and G. {Casazza} and A. {De Lucia} and E. {Merlo}},
  journal  = {IEEE Transactions on Software Engineering},
  title    = {Recovering traceability links between code and documentation},
  year     = {2002},
  issn     = {1939-3520},
  month    = {Oct},
  number   = {10},
  pages    = {970-983},
  volume   = {28},
  abstract = {Software system documentation is almost always expressed informally in natural language and free text. Examples include requirement specifications, design documents, manual pages, system development journals, error logs, and related maintenance reports. We propose a method based on information retrieval to recover traceability links between source code and free text documents. A premise of our work is that programmers use meaningful names for program items, such as functions, variables, types, classes, and methods. We believe that the application-domain knowledge that programmers process when writing the code is often captured by the mnemonics for identifiers; therefore, the analysis of these mnemonics can help to associate high-level concepts with program concepts and vice-versa. We apply both a probabilistic and a vector space information retrieval model in two case studies to trace C++ source code onto manual pages and Java code to functional requirements. We compare the results of applying the two models, discuss the benefits and limitations, and describe directions for improvements.},
  doi      = {10.1109/TSE.2002.1041053},
  groups   = {NLP use, identification},
  keywords = {system documentation;information retrieval;object-oriented programming;natural languages;probability;software system documentation;information retrieval;object orientation;traceability;program comprehension;traceability link recovery;source code;free text documents;vector space;Documentation;Programming profession;Information retrieval;Natural languages;Context modeling;Information resources;Writing;Java;Inspection;Mathematics},
}

@InProceedings{marcus2003-latent-semantic-indexing-for-traceability-LSI,
  author    = {A. {Marcus} and J. I. {Maletic}},
  booktitle = {25th International Conference on Software Engineering, 2003. Proceedings.},
  title     = {Recovering documentation-to-source-code traceability links using latent semantic indexing},
  year      = {2003},
  month     = {May},
  pages     = {125-135},
  abstract  = {An information retrieval technique, latent semantic indexing, is used to automatically identify traceability links from system documentation to program source code. The results of two experiments to identify links in existing software systems (i.e., the LEDA library, and Albergate) are presented. These results are compared with other similar type experimental results of traceability link identification using different types of information retrieval techniques. The method presented proves to give good results by comparison and additionally it is a low cost, highly flexible method to apply with regards to preprocessing and/or parsing of the source code and documentation.},
  doi       = {10.1109/ICSE.2003.1201194},
  groups    = {NLP use, identification},
  issn      = {0270-5257},
  keywords  = {information retrieval;system documentation;computer aided software engineering;indexing;information retrieval technique;latent semantic indexing;system documentation;program source code;traceability link identification;Indexing;Documentation;Information retrieval;Software systems;Information analysis;Costs;Software engineering;Natural languages;Computer science;Software libraries},
}

@InProceedings{mcmillan2009-combining-text-and-structural-analysis-for-traceability,
  author    = {C. {McMillan} and D. {Poshyvanyk} and M. {Revelle}},
  booktitle = {2009 ICSE Workshop on Traceability in Emerging Forms of Software Engineering},
  title     = {Combining textual and structural analysis of software artifacts for traceability link recovery},
  year      = {2009},
  month     = {May},
  pages     = {41-48},
  abstract  = {Existing methods for recovering traceability links among software documentation artifacts analyze textual similarities among these artifacts. It may be the case, however, that related documentation elements share little terminology or phrasing. This paper presents a technique for indirectly recovering these traceability links in requirements documentation by combining textual with structural information as we conjecture that related requirements share related source code elements. A preliminary case study indicates that our combined approach improves the precision and recall of recovering relevant links among documents as compared to stand-alone methods based solely on analyzing textual similarities.},
  doi       = {10.1109/TEFSE.2009.5069582},
  groups    = {NLP use, identification},
  issn      = {2157-2194},
  keywords  = {information retrieval;software engineering;system documentation;textual analysis;structural analysis;software documentation artifacts;traceability link recovery;requirements documentation;source code elements;Documentation;Large scale integration;Matrix decomposition;Terminology;Information analysis;Computer science;Educational institutions;Information retrieval;Software tools;Indexing},
}

@Article{delucia2012-information-retrieval-for-traceability,
  author    = {De Lucia, Andrea and Marcus, Andrian and Oliveto, Rocco and Poshyvanyk, Denys},
  journal   = {Software and Systems Traceability},
  title     = {Information Retrieval Methods for Automated Traceability Recovery},
  year      = {2012},
  pages     = {71--98},
  abstract  = {The potential benefits of traceability are well known and documented, as well as the impracticability of recovering and maintaining traceability links manually. Indeed, the manual management of traceability information is an error prone and time consuming task. Consequently, despite the advantages that can be gained, explicit traceability is rarely established unless there is a regulatory reason for doing so. Extensive efforts have been brought forth to improve the explicit connection of software artifacts in the software engineering community (both research and commercial). Promising results have been achieved using Information Retrieval (IR) techniques for traceability recovery. IR-based traceability recovery methods propose a list of candidate traceability links based on the similarity between the text contained in the software artifacts. Software artifacts have different structures and the common element among many of them is the textual data, which most often captures the informal semantics of artifacts. For example, source code includes large volume of textual data in the form of comments and identifiers. In consequence, IR-based approaches are very well suited to address the traceability recovery problem. The conjecture is that artifacts with high textual similarity are good candidates to be traced to each other since they share several concepts. In this chapter we overview a general process of using IR-based methods for traceability link recovery and overview some of them in a greater detail: probabilistic, vector space, and Latent Semantic Indexing models. Finally, we discuss common approaches to measuring the performance of IR-based traceability recovery methods and the latest advances in techniques for the analysis of candidate links.},
  address   = {London},
  booktitle = {Software and Systems Traceability},
  doi       = {10.1007/978-1-4471-2239-5_4},
  editor    = {Cleland-Huang, Jane and Gotel, Orlena and Zisman, Andrea},
  file      = {:delucia2012-information-retrieval-for-traceability.pdf:PDF},
  groups    = {AI, meta, NLP use, Metastudies, identification},
  isbn      = {978-1-4471-2239-5},
  publisher = {Springer London},
  url       = {https://doi.org/10.1007/978-1-4471-2239-5_4},
}

@InProceedings{badreddin2014-req-traceability-model-based-approach,
  author    = {O. {Badreddin} and A. {Sturm} and T. C. {Lethbridge}},
  booktitle = {2014 IEEE 4th International Model-Driven Requirements Engineering Workshop (MoDRE)},
  title     = {Requirement traceability: A model-based approach},
  year      = {2014},
  month     = {Aug},
  pages     = {87-91},
  abstract  = {Requirements tractability remains challenging, particularly in the prevalence of code centric approaches. Similarly, within the emerging model centric paradigm, requirements traceability is addressed only to a limited extent. To facilitate such traceability, we call for representing requirements as first class entities in the emerging paradigm of model-oriented programming. This has the objective of enabling software developers, modelers, and business analysts to manipulate requirements entities as textual model and code elements. To illustrate the feasibility of such an approach, we propose a Requirement-Oriented Modeling and Programming Language (ROMPL) that demonstrates how modeling abstractions can be utilized to manage the behavior and relationships of key requirements entities.},
  doi       = {10.1109/MoDRE.2014.6890829},
  groups    = {Metamodels},
  keywords  = {formal verification;object-oriented programming;requirement traceability;model-oriented programming;code centric approach;textual model;code element;requirement-oriented modeling;programming language;ROMPL;Unified modeling language;Object oriented modeling;Business;Software;Computational modeling;Syntactics;Requirements;Modeling;Action languages;Domain Specific Language;MDA},
}

@InProceedings{panichella2013-using-structural-information-to-improve-IR-traceability,
  author    = {A. {Panichella} and C. {McMillan} and E. {Moritz} and D. {Palmieri} and R. {Oliveto} and D. {Poshyvanyk} and A. {De Lucia}},
  booktitle = {2013 17th European Conference on Software Maintenance and Reengineering},
  title     = {When and How Using Structural Information to Improve IR-Based Traceability Recovery},
  year      = {2013},
  month     = {March},
  pages     = {199-208},
  abstract  = {Information Retrieval (IR) has been widely accepted as a method for automated traceability recovery based on the textual similarity among the software artifacts. However, a notorious difficulty for IR-based methods is that artifacts may be related even if they are not textually similar. A growing body of work addresses this challenge by combining IR-based methods with structural information from source code. Unfortunately, the accuracy of such methods is highly dependent on the IR methods. If the IR methods perform poorly, the combined approaches may perform even worse. In this paper, we propose to use the feedback provided by the software engineer when classifying candidate links to regulate the effect of using structural information. Specifically, our approach only considers structural information when the traceability links from the IR methods are verified by the software engineer and classified as correct links. An empirical evaluation conducted on three systems suggests that our approach outperforms both a pure IR-based method and a simple approach for combining textual and structural information.},
  doi       = {10.1109/CSMR.2013.29},
  groups    = {NLP use, Metastudies, identification},
  issn      = {1534-5351},
  keywords  = {information retrieval;pattern classification;program diagnostics;structural information;information retrieval-based traceability recovery;automated traceability recovery;textual similarity;software artifact;source code;candidate link classification;Software;Vectors;Accuracy;Medical services;Context;Indexes;Educational institutions;Traceability Link Recovery;Empirical studies},
}

@Article{laghouaouta2017-model-composition-tracaebility,
  author   = {Youness Laghouaouta and Adil Anwar and Mahmoud Nassar and Bernard Coulette},
  journal  = {Information and Software Technology},
  title    = {A dedicated approach for model composition traceability},
  year     = {2017},
  issn     = {0950-5849},
  pages    = {142 - 159},
  volume   = {91},
  abstract = {Context: Software systems are often too complex to be expressed by a single model. Recognizing this, the Model Driven Engineering (MDE) proposes multi-modeling approaches to allow developers to describe a system from different perspectives. In this context, model composition has become important since the combination of those partial representations is inevitable. Nevertheless, no approach has been defined for keeping track of the composition effects, and this operation has been overshadowed by model transformations.
Objective
This paper presents a traceability approach dedicated to the composition of models. Two aspects of quality are considered: producing relevant traces; and dealing with scalability.
Method
The composition of softgoal trees has been selected to motivate the need for tracing the composition of models and to illustrate our approach. The base principle is to augment the specification of the composition with the behavior needed to generate the expected composed model accompanied with a trace model. This latter includes traces of the execution details. For that, traceability is considered as a crosscutting concern and encapsulated in an aspect. As part of the proposal, an Eclipse plug-in has been implemented as a tool support. Besides, a comparative experiment has been conducted to assess the traces relevance. We also used the regression method to validate the scalability of the tool support.
Results
Our experiments show that the proposed approach allows generating relevant traces. In addition, the obtained results reveal that tracing a growing number of elements causes an acceptable increase of response time.
Conclusion
This paper presents a traceability approach dedicated to the composition of models and its application to softgoal trees. The experiment results reveal that our proposal considers the composition specificities for producing valuable traceability information while supporting scalability.},
  doi      = {https://doi.org/10.1016/j.infsof.2017.07.002},
  groups   = {mde},
  keywords = {Model traceability, Model composition, Aspect-oriented modeling, Graph transformations, NFR framework},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584917304494},
}

@InProceedings{dosimont2014-eficient-analysis-methodology-for-huge-application-traces,
  author    = {D. {Dosimont} and G. {Pagano} and G. {Huard} and V. M. {Huard} and J. {Vincent}},
  booktitle = {2014 International Conference on High Performance Computing Simulation (HPCS)},
  title     = {Efficient analysis methodology for huge application traces},
  year      = {2014},
  month     = {July},
  pages     = {951-958},
  abstract  = {The growing complexity of computer system hardware and software makes their behavior analysis a challenging task. In this context, tracing appears to be a promising solution as it provides relevant information about the system execution. However, trace analysis techniques and tools lack in providing the analyst the way to perform an efficient analysis flow because of several issues. First, traces contain a huge volume of data difficult to store, load in memory and work with. Then, the analysis flow is hindered by various result formats, provided by different analysis techniques, often incompatible. Last, analysis frameworks lack an entry point to understand the traced application general behavior. Indeed, traditional visualization techniques suffer from time and space scalability issues due to screen size, and are not able to represent the full trace. In this article, we present how to do an efficient analysis by using the Shneiderman's mantra: “Overview first, zoom and filter, then details on demand”. Our methodology is based on FrameSoC, a trace management infrastructure that provides solutions for trace storage, data access, and analysis flow, managing analysis results and tool. Ocelotl, a visualization tool, takes advantage of FrameSoC and shows a synthetic representation of a trace by using a time aggregation. This visualization solves scalability issues and provides an entry point for the analysis by showing phases and behavior disruptions, with the objective of getting more details by focusing on the interesting trace parts.},
  doi       = {10.1109/HPCSim.2014.6903791},
  groups    = {Trace analysis},
  keywords  = {data visualisation;program debugging;program diagnostics;huge application traces;computer system hardware;computer system software;trace analysis techniques;visualization techniques;time scalability;space scalability;FrameSoC infrastructure;trace management infrastructure;storage flow;data access flow;analysis flow;Ocelotl visualization tool;time aggregation;Measurement;Complexity theory;Indexing;Data visualization;Arrays;Vectors;Application analysis;trace management;analysis tools;visualization tools;debugging;performance analysis},
}

@InProceedings{borg2013-IR-in-traceability-birds-view,
  author    = {M. {Borg} and P. {Runeson}},
  booktitle = {2013 ACM / IEEE International Symposium on Empirical Software Engineering and Measurement},
  title     = {IR in Software Traceability: From a Bird's Eye View},
  year      = {2013},
  month     = {Oct},
  pages     = {243-246},
  abstract  = {Background. Several researchers have proposed creating after-the-fact structure among software artifacts using trace recovery based on Information Retrieval (IR). Due to significant variation points in previous studies, results are not easily aggregated. Aim. We aim at an overview picture of the outcome of previous evaluations. Method. Based on a systematic mapping study, we perform a synthesis of published research. Results. Our synthesis shows that there are no empirical evidence that any IR model outperforms another model consistently. We also display a strong dependency between the Precision and Recall (P-R) values and the input datasets. Finally, our mapping of P-R values on the possible output space highlights the difficulty of recovering accurate trace links using naïve cut-off strategies. Conclusion. Based on our findings, we stress the need for empirical evaluations beyond the basic P-R 'race'.},
  comment   = {All IR technic give comparable P-R results},
  doi       = {10.1109/ESEM.2013.39},
  groups    = {meta, NLP use, Metastudies, identification},
  issn      = {1949-3789},
  keywords  = {information retrieval;software engineering;software traceability;software artifacts;trace recovery;information retrieval;IR model;precision and recall value;software engineering;Software;Information retrieval;Software engineering;Standards;Accuracy;Large scale integration;Systematics;empirical software engineering;software traceability;information retrieval;secondary study},
}

@Article{anquetil2010-model-driven-tracea-for-SPL,
  author   = {Anquetil, Nicolas and Kulesza, Uirá and Mitschke, Ralf and Moreira, Ana and Royer, Jean-Claude and Rummler, Andreas and Sousa, André},
  journal  = {Software and Systems Modeling},
  title    = {A model-driven traceability framework for software product lines},
  year     = {2010},
  issn     = {1619-1374},
  number   = {4},
  pages    = {427--451},
  volume   = {9},
  abstract = {Software product line (SPL) engineering is a recent approach to software development where a set of software products are derived for a well defined target application domain, from a common set of core assets using analogous means of production (for instance, through Model Driven Engineering). Therefore, such family of products are built from reuse, instead of developed individually from scratch. SPL promise to lower the costs of development, increase the quality of software, give clients more flexibility and reduce time to market. These benefits come with a set of new problems and turn some older problems possibly more complex. One of these problems is traceability management. In the European AMPLE project we are creating a common traceability framework across the various activities of the SPL development. We identified four orthogonal traceability dimensions in SPL development, one of which is an extension of what is often considered as “traceability of variability”. This constitutes one of the two contributions of this paper. The second contribution is the specification of a metamodel for a repository of traceability links in the context of SPL and the implementation of a respective traceability framework. This framework enables fundamental traceability management operations, such as trace import and export, modification, query and visualization. The power of our framework is highlighted with an example scenario.},
  file     = {:anquetil2010-model-driven-tracea-for-SPL.pdf:PDF},
  groups   = {Metamodels, identification},
  refid    = {Anquetil2010},
  url      = {https://doi.org/10.1007/s10270-009-0120-9},
}

@Article{diaz2015-tracing-variability-from-features-to-product-line-SPL,
  author   = {Díaz, Jessica and Pérez, Jennifer and Garbajosa, Juan},
  journal  = {Requirements Engineering},
  title    = {A model for tracing variability from features to product-line architectures: a case study in smart grids},
  year     = {2015},
  issn     = {1432-010X},
  number   = {3},
  pages    = {323--343},
  volume   = {20},
  abstract = {In current software systems with highly volatile requirements, traceability plays a key role to maintain the consistency between requirements and code. Traceability between artifacts involved in the development of software product line (SPL) is still more critical because it is necessary to guarantee that the selection of variants that realize the different SPL products meet the requirements. Current SPL traceability mechanisms trace from variability in features to variations in the configuration of product-line architecture (PLA) in terms of adding and removing components. However, it is not always possible to materialize the variable features of a SPL through adding or removing components, since sometimes they are materialized inside components, i.e., in part of their functionality: a class, a service, and/or an interface. Additionally, variations that happen inside components may crosscut several components of architecture. These kinds of variations are still challenging and their traceability is not currently well supported. Therefore, it is not possible to guarantee that those SPL products with these kinds of variations meet the requirements. This paper presents a solution for tracing variability from features to PLA by taking these kinds of variations into account. This solution is based on models and traceability between models in order to automate SPL configuration by selecting the variants and realizing the product application. The FPLA modeling framework supports this solution which has been deployed in a software factory. Validation has consisted in putting the solution into practice to develop a product line of power metering management applications for smart grids.},
  groups   = {SPL},
  refid    = {Díaz2015},
  url      = {https://doi.org/10.1007/s00766-014-0203-1},
}

@Article{paige2011-traces-in-moel-driven-engineering,
  author   = {Paige, Richard F. and Drivalos, Nikolaos and Kolovos, Dimitrios S. and Fernandes, Kiran J. and Power, Christopher and Olsen, Goran K. and Zschaler, Steffen},
  journal  = {Software \& Systems Modeling},
  title    = {Rigorous identification and encoding of trace-links in model-driven engineering},
  year     = {2011},
  issn     = {1619-1374},
  number   = {4},
  pages    = {469--487},
  volume   = {10},
  abstract = {Model-driven engineering (MDE) involves the construction and manipulation of many models of different kinds in an engineering process. In principle, models can be used in the product engineering lifecycle in an end-to-end manner for representing requirements, designs and implementations, and assisting in deployment and maintenance. The manipulations applied to models may be manual, but they can also be automated--for example, using model transformations, code generation, and validation. To enhance automated analysis, consistency and coherence of models used in an MDE process, it is useful to identify, establish and maintain trace-links between models. However, the breadth and scope of trace-links that can be used in MDE is substantial, and managing trace-link information can be very complex. In this paper, we contribute to managing the complexity of traceability information in MDE in two ways: firstly, we demonstrate how to identify the different kinds of trace-links that may appear in an end-to-end MDE process; secondly, we describe a rigorous approach to defining semantically rich trace-links between models, where the models themselves may be constructed using diverse modelling languages. The definition of rich trace-links allows us to use tools to maintain and analyse traceability relationships.},
  groups   = {mde, Trace analysis, Trace integrity, identification},
  refid    = {Paige2011},
  url      = {https://doi.org/10.1007/s10270-010-0158-8},
}

@InProceedings{drivalos2009-engineering-DSL-for-traceability,
  author    = {Drivalos, Nikolaos and Kolovos, Dimitrios S. and Paige, Richard F. and Fernandes, Kiran J.},
  booktitle = {Software Language Engineering},
  title     = {Engineering a DSL for Software Traceability},
  year      = {2009},
  address   = {Berlin, Heidelberg},
  editor    = {Ga{\v{s}}evi{\'{c}}, Dragan and L{\"a}mmel, Ralf and Van Wyk, Eric},
  pages     = {151--167},
  publisher = {Springer Berlin Heidelberg},
  abstract  = {The software artefacts at different levels of abstraction and at different stages of the development process are closely inter-related. For developers to stay in control of the development process, traceability information must be maintained. In this paper, we present the engineering of the Traceability Metamodelling Language (TML), a metamodelling language dedicated to defining traceability metamodels. We present the abstract syntax of the language and its semantics, which are defined using a translational approach. Finally, we provide a case study that demonstrates the construction of a traceability metamodel that captures traceability information between two metamodels using TML.},
  file      = {:drivalos2009-engineering-DSL-for-traceability.pdf:PDF},
  groups    = {Metamodels},
  isbn      = {978-3-642-00434-6},
}

@Article{vale2017-SPL-traceability-a-SMS,
  author   = {Tassio Vale and Eduardo Santana [de Almeida] and Vander Alves and Uirá Kulesza and Nan Niu and Ricardo [de Lima]},
  journal  = {Information and Software Technology},
  title    = {Software product lines traceability: A systematic mapping study},
  year     = {2017},
  issn     = {0950-5849},
  pages    = {1 - 18},
  volume   = {84},
  abstract = {Context: Traceability in Software Product Lines (SPL) is the ability to interrelate software engineering artifacts through required links to answer specific questions related to the families of products and underlying development processes. Despite the existence of studies to map out available evidence on traceability for single systems development, there is a lack of understanding on common strategies, activities, artifacts, and research gaps for SPL traceability. Objective: This paper analyzes 62 studies dating from 2001 to 2015 and discusses seven aspects of SPL traceability: main goals, strategies, application domains, research intensity, research challenges, rigor, and industrial relevance. In addition to the analysis, this paper also synthesizes the available evidence, identifies open issues and points out areas calling for further research. Method: To gather evidence, we defined a mapping study process adapted from existing guidelines. Driven by a set of research questions, this process comprises three major phases: planning, conducting, and documenting the review. Results: This work provides a structured understanding of SPL traceability, indicating areas for further research. The lack of evidence regarding the application of research methods indicates the need for more rigorous SPL traceability studies with better description of context, study design, and limitations. For practitioners, although most identified studies have low industrial relevance, a few of them have high relevance and thus could provide some decision making support for application of SPL traceability in practice. Conclusions: This work concludes that SPL traceability is maturing and pinpoints areas where further investigation should be performed. As future work, we intend to improve the comparison between traceability proposals for SPL and single-system development.},
  doi      = {https://doi.org/10.1016/j.infsof.2016.12.004},
  groups   = {meta, Metastudies, identification},
  keywords = {Systematic mapping study, Software product lines, Software and systems traceability, Software reuse},
  url      = {http://www.sciencedirect.com/science/article/pii/S0950584916304463},
}

@InProceedings{clelandhuang2014-traceability-trends-and-futurte-direction,
  author    = {Cleland-Huang, Jane and Gotel, Orlena C. Z. and Huffman Hayes, Jane and M\"{a}der, Patrick and Zisman, Andrea},
  booktitle = {Future of Software Engineering Proceedings},
  title     = {Software Traceability: Trends and Future Directions},
  year      = {2014},
  address   = {New York, NY, USA},
  pages     = {55–69},
  publisher = {Association for Computing Machinery},
  series    = {FOSE 2014},
  abstract  = {Software traceability is a sought-after, yet often elusive quality in software-intensive systems. Required in safety-critical systems by many certifying bodies, such as the USA Federal Aviation Authority, software traceability is an essential element of the software development process. In practice, traceability is often conducted in an ad-hoc, after-the-fact manner and, therefore, its benefits are not always fully realized. Over the past decade, researchers have focused on specific areas of the traceability problem, developing more sophisticated tooling, promoting strategic planning, applying information retrieval techniques capable of semi-automating the trace creation and maintenance process, developing new trace query languages and visualization techniques that use trace links, and applying traceability in specific domains such as Model Driven Development, product line systems, and agile project environments. In this paper, we build upon a prior body of work to highlight the state-of-the-art in software traceability, and to present compelling areas of research that need to be addressed.},
  doi       = {10.1145/2593882.2593891},
  file      = {:clelandhuang2014-traceability-trends-and-futurte-direction.pdf:PDF},
  groups    = {meta, Metastudies, identification},
  isbn      = {9781450328654},
  keywords  = {Software Traceability, Roadmap},
  location  = {Hyderabad, India},
  numpages  = {15},
  url       = {https://doi.org/10.1145/2593882.2593891},
}

@InProceedings{gallina2014-model-driven-certification-method-for-process-compliance,
  author    = {B. {Gallina}},
  booktitle = {2014 IEEE International Symposium on Software Reliability Engineering Workshops},
  title     = {A Model-Driven Safety Certification Method for Process Compliance},
  year      = {2014},
  month     = {Nov},
  pages     = {204-209},
  abstract  = {A safety case is a contextualized structured argument constituted of process and product-based sub-arguments to show that a system is acceptably safe. The creation of a safety case is an extremely time-consuming and costly activity needed for certification purposes. To reduce time and cost, reuse as well as automatic generation possibilities represent urgent research directions. In this paper, we focus on safety processes mandated by prescriptive standards and we identify process-related structures from which process-based arguments (those aimed at showing that a required development process has been applied according to the standard) can be generated and more easily reused. Then, we propose a model-driven safety certification method to derive those arguments as goal structures given in Goal Structuring Notation from process models given in compliance with Software Process Engineering Meta-model 2.0. The method is illustrated by generating process-based arguments in the context of ISO 26262.},
  doi       = {10.1109/ISSREW.2014.30},
  groups    = {Metamodels, certification, identification},
  keywords  = {certification;safety-critical software;software engineering;software standards;model-driven safety certification method;process compliance;safety case;contextualized structured argument;process subargument;safety process;process-related structure;process-based argument;goal structures;goal structuring notation;Software Process Engineering Meta-model 2.0;ISO 26262;Hazards;Software;Context;ISO standards;Automotive engineering;Safety processes;safety cases;process-based arguments;safety standards;model driven engineering;Software Process Engineering Meta-model (SPEM) 2.0;Structured Assurance Case Metamodel (SACM);Goal Structuring Notation (GSN)},
}

@InProceedings{asuncion2010-software-traceability-with-topic-modeling,
  author    = {H. U. {Asuncion} and A. U. {Asuncion} and R. N. {Taylor}},
  booktitle = {2010 ACM/IEEE 32nd International Conference on Software Engineering},
  title     = {Software traceability with topic modeling},
  year      = {2010},
  month     = {May},
  pages     = {95-104},
  volume    = {1},
  abstract  = {Software traceability is a fundamentally important task in software engineering. The need for automated traceability increases as projects become more complex and as the number of artifacts increases. We propose an automated technique that combines traceability with a machine learning technique known as topic modeling. Our approach automatically records traceability links during the software development process and learns a probabilistic topic model over artifacts. The learned model allows for the semantic categorization of artifacts and the topical visualization of the software system. To test our approach, we have implemented several tools: an artifact search tool combining keyword-based search and topic modeling, a recording tool that performs prospective traceability, and a visualization tool that allows one to navigate the software architecture and view semantic topics associated with relevant artifacts and architectural components. We apply our approach to several data sets and discuss how topic modeling enhances software traceability, and vice versa.},
  doi       = {10.1145/1806799.1806817},
  groups    = {AI, NLP use},
  issn      = {1558-1225},
  keywords  = {learning (artificial intelligence);probability;software engineering;software traceability;topic modeling;software engineering;automated traceability;machine learning technique;software development process;probabilistic topic model;semantic categorization;topical visualization;software architecture;Semantics;Software;Machine learning;Visualization;Large scale integration;Probabilistic logic;Resource management;latent dirichlet allocation;software architecture;software traceability;topic model},
}

@InCollection{bouillon2013-survey-on-usage-scenario-requirements-traceability-in-practice,
  author    = {Elke Bouillon and Patrick M\"{a}der and Ilka Philippow},
  booktitle = {Requirements Engineering: Foundation for Software Quality},
  publisher = {Springer Berlin Heidelberg},
  title     = {A Survey on Usage Scenarios for Requirements Traceability in Practice},
  year      = {2013},
  pages     = {158--173},
  abstract  = {[Context and motivation] Requirements traceability is known as an important part of development projects. Studies showed that traceability is applied in practice, but insufficient tool- and method-support hinders its practical use. [Question/problem] We conducted a survey to understand which traceability usage scenarios are most relevant for practitioners. Gaining this information is a required step for providing better traceability support to practitioners. [Principal ideas/results] We identified a list of 29 regularly cited usage scenarios and asked practitioners to assess the frequency of use for each in a typical development project. Our analysis is restricted to those 56 participants that were actively using traceability in order to ensure comparable results. Subjects held various roles in the development and reported about diverse projects. [Contribution] This study provides not only an initial catalog of usage scenarios and their relevance, but also provides insights on practitioner’s traceability practices. In result, we found all scenarios to be used by practitioners. Participants use traceability especially for: finding origin and rationale of requirements, documenting a requirement’s history, and tracking requirement or task implementation state. Furthermore, we highlight topics for ongoing evaluation and better method and tool support in the area of requirements traceability.},
  doi       = {10.1007/978-3-642-37422-7_12},
  groups    = {meta, Metastudies, identification},
  url       = {https://doi.org/10.1007/978-3-642-37422-7_12},
}

@InCollection{clelandHuang2012-trace-queries-safety-requirements-assurance,
  author    = {Jane Cleland-Huang and Mats Heimdahl and Jane Huffman Hayes and Robyn Lutz and Patrick Maeder},
  booktitle = {Requirements Engineering: Foundation for Software Quality},
  publisher = {Springer Berlin Heidelberg},
  title     = {Trace Queries for Safety Requirements in High Assurance Systems},
  year      = {2012},
  pages     = {179--193},
  abstract  = {[Context and motivation] Safety critical software systems pervade almost every facet of our lives. We rely on them for safe air and automative travel, healthcare diagnosis and treatment, power generation and distribution, factory robotics, and advanced assistance systems for special-needs consumers. [Question/Problem] Delivering demonstrably safe systems is difficult, so certification and regulatory agencies routinely require full life-cycle traceability to assist in evaluating them. In practice, however, the traceability links provided by software producers are often incomplete, inaccurate, and ineffective for demonstrating software safety. Also, there has been insufficient integration of formal method artifacts into such traceability. [Principal ideas/results] To address these weaknesses we propose a family of reusable traceability queries that serve as a blueprint for traceability in safety critical systems. In particular we present queries that consider formal artifacts, designed to help demonstrate that: 1) identified hazards are addressed in the safety-related requirements, and 2) the safety-related requirements are realized in the implemented system. We model these traceability queries using the Visual Trace Modeling Language, which has been shown to be more intuitive than the defacto SQL standard. [Contribution] Practitioners building safety critical systems can use these trace queries to make their traceability efforts more complete, accurate and effective. This, in turn, can assist in building safer software systems and in demonstrating their adequate handling of hazards.},
  doi       = {10.1007/978-3-642-28714-5_16},
  groups    = {identification},
  url       = {https://doi.org/10.1007/978-3-642-28714-5_16},
}

@InProceedings{dietrich2013-learning-efective-query-transformation-for-enhanced-req-trace-retrieval,
  author    = {T. {Dietrich} and J. {Cleland-Huang} and Y. {Shin}},
  booktitle = {2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE)},
  title     = {Learning effective query transformations for enhanced requirements trace retrieval},
  year      = {2013},
  month     = {Nov},
  pages     = {586-591},
  abstract  = {In automated requirements traceability, significant improvements can be realized through incorporating user feedback into the trace retrieval process. However, existing feedback techniques are designed to improve results for individual queries. In this paper we present a novel technique designed to extend the benefits of user feedback across multiple trace queries. Our approach, named Trace Query Transformation (TQT), utilizes a novel form of Association Rule Mining to learn a set of query transformation rules which are used to improve the efficacy of future trace queries. We evaluate TQT using two different kinds of training sets. The first represents an initial set of queries directly modified by human analysts, while the second represents a set of queries generated by applying a query optimization process based on initial relevance feedback for trace links between a set of source and target documents. Both techniques are evaluated using requirements from theWorldVista Healthcare system, traced against certification requirements for the Commission for Healthcare Information Technology. Results show that the TQT technique returns significant improvements in the quality of generated trace links.},
  doi       = {10.1109/ASE.2013.6693117},
  groups    = {AI, identification},
  keywords  = {data mining;formal verification;health care;learning (artificial intelligence);medical computing;program diagnostics;query processing;relevance feedback;text analysis;effective query transformation learning;requirement trace retrieval enhancement process;automated requirements traceability;user feedback;trace query transformation;association rule mining;training sets;query optimization process;relevance feedback;source documents;target documents;WorldVista Healthcare system;certification requirements;Commission for Healthcare Information Technology;TQT technique;machine learning;text mining;software engineering activities;Training;Association rules;Itemsets;Medical services;Standards;Manuals;Educational institutions;requirements traceability;query replacement;contractual requirements;text mining;machine learning;association rules},
}

@InCollection{li2012-which-visualization-in-this-context,
  author    = {Yang Li and Walid Maalej},
  booktitle = {Requirements Engineering: Foundation for Software Quality},
  publisher = {Springer Berlin Heidelberg},
  title     = {Which Traceability Visualization Is Suitable in This Context? A Comparative Study},
  year      = {2012},
  pages     = {194--210},
  abstract  = {Traceability supports users in describing and tracking the relationships between software artifacts. Techniques such as traceability matrices and graphs visualize these relationships and help users to access and understand them. Researchers agree that different visualization techniques add valuable information in different contexts. However, there is an ambiguity which visualization is suitable for which context. To clarify this we conducted a comparative study of common visualization techniques, including an experiment and interviews with 24 participants.

We found that traceability matrices and graphs are most preferred in management tasks, while hyperlinks are preferred in implementation and testing tasks. Traceability lists seem to be the least attractive technique for most participants. Graphs are preferred to navigate linked artifacts, while matrices are appropriate for overview. Hyperlinks are regarded to fit for fine-grained information. Participants stressed the importance of visualizing semantics of artifacts and links. Our finding also indicates that users are not always able to choose the most suitable visualization.},
  doi       = {10.1007/978-3-642-28714-5_17},
  groups    = {Visualization, Metastudies},
  url       = {https://doi.org/10.1007/978-3-642-28714-5_17},
}

@Article{mader2012-visual-language-for-traceability-queries,
  author    = {Patrick M\"{a}der and Jane Cleland-Huang},
  journal   = {Software {\&} Systems Modeling},
  title     = {A visual language for modeling and executing traceability queries},
  year      = {2012},
  month     = apr,
  number    = {3},
  pages     = {537--553},
  volume    = {12},
  abstract  = {Current software and systems engineering tools provide only basic trace features, and as a result users are often compelled to construct non-trivial traceability queries using generic query languages such as SQL. In this paper, we present an alternative approach which defines traceability strategies for a project using UML class diagrams and then constructs trace queries as constraints upon subsets of the model. The visual trace modeling language (VTML) allows users to model a broad range of trace queries while hiding underlying technical details and data structures. The viability and expressiveness of VTML for use in a real project are demonstrated through modeling a broadly representative set of queries for a web-based health-care system. It is then evaluated through an experiment with human users to assess the readability and writability of VTML queries in comparison to generic SQL queries. We found that users read and constructed traceability queries considerably faster using VTML than using SQL. Furthermore, visually constructed traceability queries were substantially more correct compared to the same queries constructed with SQL.},
  doi       = {10.1007/s10270-012-0237-0},
  groups    = {Visualization},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007/s10270-012-0237-0},
}

@InProceedings{mader2009-motivation-matters-in-traceability-practitioner-survey,
  author    = {P. {Mader} and O. {Gotel} and I. {Philippow}},
  booktitle = {2009 17th IEEE International Requirements Engineering Conference},
  title     = {Motivation Matters in the Traceability Trenches},
  year      = {2009},
  month     = {Aug},
  pages     = {143-148},
  abstract  = {Reports from the field are few and far between when it comes to traceability. As a community, we know little more about the traceability practice in companies today than we did a decade ago. This paper reports on findings from a practitioner survey designed to get a high-level update on traceability practice and problems. What emerges is the importance of the prevailing motivation underlying traceability adoption in an organization and we characterize this in four ways. We use these perspectives to discuss our findings and their implications.},
  doi       = {10.1109/RE.2009.23},
  groups    = {meta, Metastudies},
  issn      = {2332-6441},
  keywords  = {formal specification;formal verification;human factors;software development management;systems analysis;traceability trench adoption;traceability practitioner survey;organizational motivation factor;requirements traceability management;Software systems;Computer science;USA Councils;Data analysis;Programming;Information technology;Documentation;requirements traceability;traceability practice;traceability problem;traceability process},
}

@Article{mader2013-strategic-traceability-for-safety-critical-projects,
  author   = {P. {Mäder} and P. L. {Jones} and Y. {Zhang} and J. {Cleland-Huang}},
  journal  = {IEEE Software},
  title    = {Strategic Traceability for Safety-Critical Projects},
  year     = {2013},
  issn     = {1937-4194},
  month    = {May},
  number   = {3},
  pages    = {58-66},
  volume   = {30},
  abstract = {To support any claim that a product is safe for its intended use, manufacturers must establish traceability within that product's development life cycle. Unfortunately, traceability information submitted to regulators and third parties is often weak, casting doubt rather than confidence in a product's integrity. This article evaluates traceability information for 10 submissions prepared by manufacturers for review at the US Food and Drug Administration. The authors observed nine widespread traceability problems that affected regulators' ability to evaluate the product's safety in a timely manner. To address these problems, the authors present a set of guidelines for implementing strategic traceability in a way that supports safety assessments.},
  doi      = {10.1109/MS.2013.60},
  groups   = {Metastudies, certification},
  keywords = {Safety;Software development;Software reliability;Software architecture;Product safety;requirements traceability;safety critical;assessment;traceability strategies;software and system safety;documentation},
}

@InProceedings{panis2010-req-traceability-deployment-in-commercial-engineering-organisation,
  author    = {M. C. {Panis}},
  booktitle = {2010 18th IEEE International Requirements Engineering Conference},
  title     = {Successful Deployment of Requirements Traceability in a Commercial Engineering Organization...Really},
  year      = {2010},
  month     = {Sep.},
  pages     = {303-307},
  abstract  = {Within the world of requirements engineering, it seems a foregone conclusion that traceability is vital to the product development process. Simultaneously, it appears that any implementation of traceability is doomed to failure. This paper examines a commercial engineering company's use of traceability and the reasons why traceability is providing value despite the many challenges it presents. It describes the solution that was deployed and analyzes what has and has not succeeded, factors which should be common to any organization attempting to use requirements traceability.},
  doi       = {10.1109/RE.2010.43},
  groups    = {Concrete applications},
  issn      = {2332-6441},
  keywords  = {systems analysis;successful deployment;requirements traceability;commercial engineering organization;requirements engineering;foregone conclusion;product development process;Software;Instruments;Book reviews;Accuracy;Hardware;Conferences;Organizations;requirements;traceability},
}

@Article{spanoudakis2004-rule-based-generation-of-req-traceability-relations,
  author   = {George Spanoudakis and Andrea Zisman and Elena Pérez-Miñana and Paul Krause},
  journal  = {Journal of Systems and Software},
  title    = {Rule-based generation of requirements traceability relations},
  year     = {2004},
  issn     = {0164-1212},
  number   = {2},
  pages    = {105 - 127},
  volume   = {72},
  abstract = {The support for traceability between requirement specifications has been recognised as an important task in the development life cycle of software systems. In this paper, we present a rule-based approach to support the automatic generation of traceability relations between documents which specify requirement statements and use cases (expressed in structured forms of natural language), and analysis object models for software systems. The generation of such relations is based on traceability rules of two different types. More specifically, we use requirement-to-object-model rules to trace the requirements and use case specification documents to an analysis object model, and inter-requirements traceability rules to trace requirement and use case specification documents to each other. By deploying such rules, our approach can generate four different types of traceability relations. To implement and demonstrate our approach, we have implemented a traceability prototype system. This system assumes requirement and use case specification documents and analysis object models represented in XML. It also uses traceability rules which are represented in an XML-based rule mark-up language that we have developed for this purpose. This XML-based representation framework makes it easier to deploy our prototype in settings characterised by the use of heterogeneous software engineering and requirements management tools. The developed prototype has been used in a series of experiments that we have conducted to evaluate our approach. The results of these experiments have provided encouraging initial evidence about the plausibility of our approach and are discussed in the paper.},
  doi      = {https://doi.org/10.1016/S0164-1212(03)00242-5},
  groups   = {ws},
  keywords = {Requirement traceability, Natural language processing, Rule-based traceability reasoning},
  url      = {http://www.sciencedirect.com/science/article/pii/S0164121203002425},
}

@InProceedings{vonknethen2002-change-oriented-req-traceability-evolution-of-embedded-systems,
  author    = {A. {von Knethen}},
  booktitle = {International Conference on Software Maintenance, 2002. Proceedings.},
  title     = {Change-oriented requirements traceability. Support for evolution of embedded systems},
  year      = {2002},
  month     = {Oct},
  pages     = {482-485},
  abstract  = {Planning of requirements changes is often inaccurate and implementation of changes is time consuming and error prone. One reason for these problems is imprecise and inefficient approaches to analyze the impact of changes. This thesis proposes a precise and efficient impact analysis approach that focuses on functional system requirements changes of embedded control systems. It consists of three parts: (1) a fine-grained conceptual trace model, (2) process descriptions of how to establish traces and how to analyze the impact of changes, and (3) supporting tools. Empirical investigation shows that the approach has a beneficial effect on the effectiveness and efficiency of impact analyses and that it supports a more consistent implementation of changes.},
  doi       = {10.1109/ICSM.2002.1167808},
  groups    = {Concrete applications},
  issn      = {1063-6773},
  keywords  = {systems analysis;software maintenance;embedded systems;software tools;change-oriented requirements traceability;embedded systems evolution;requirements change planning;time consuming;impact analysis approach;functional system requirements changes;embedded control systems;fine-grained conceptual trace model;process descriptions;software tools;software maintenance;Embedded system;Software engineering;Control systems;Computer science;Computer errors;Software systems;System analysis and design;Costs;Software maintenance},
}

@InProceedings{kuang2012-do-data-dependencies-complement-call-dependencies,
  author    = {H. {Kuang} and P. {Mäder} and H. {Hu} and A. {Ghabi} and L. {Huang} and L. {Jian} and A. {Egyed}},
  booktitle = {2012 28th IEEE International Conference on Software Maintenance (ICSM)},
  title     = {Do data dependencies in source code complement call dependencies for understanding requirements traceability?},
  year      = {2012},
  month     = sep,
  pages     = {181-190},
  abstract  = {It is common practice for requirements traceability research to consider method call dependencies within the source code (e.g., fan-in/fan-out analyses). However, current approaches largely ignore the role of data. The question this paper investigates is whether data dependencies have similar relationships to requirements as do call dependencies. For example, if two methods do not call one another, but do have access to the same data then is this information relevant? We formulated several research questions and validated them on three large software systems, covering about 120 KLOC. Our findings are that data relationships are roughly equally relevant to understanding the relationship to requirements traces than calling dependencies. However, most interestingly, our analyses show that data dependencies complement call dependencies. These findings have strong implications on all forms of code understanding, including trace capture, maintenance, and validation techniques (e.g., information retrieval).},
  doi       = {10.1109/ICSM.2012.6405270},
  groups    = {Trace analysis, identification},
  issn      = {1063-6773},
  keywords  = {formal specification;formal verification;reverse engineering;data dependency;source code;call dependency;requirements traceability;software system;code understanding;trace capture technique;maintenance technique;validation technique;information retrieval;Java;Servers;Software systems;Conferences;Software maintenance;Video on demand;Motion pictures;requirements traceability;feature location;source code dependencies;program analysis;method call dependencies;method data dependencies},
}

@InProceedings{yu2012-maintainging-invariant-traceability,
  author    = {Y. {Yu} and Y. {Lin} and Z. {Hu} and S. {Hidaka} and H. {Kato} and L. {Montrieux}},
  booktitle = {2012 34th International Conference on Software Engineering (ICSE)},
  title     = {Maintaining invariant traceability through bidirectional transformations},
  year      = {2012},
  month     = {June},
  pages     = {540-550},
  abstract  = {Following the “convention over configuration” paradigm, model-driven development (MDD) generates code to implement the “default” behaviour that has been specified by a template separate from the input model, reducing the decision effort of developers. For flexibility, users of MDD are allowed to customise the model and the generated code in parallel. A synchronisation of changed model or code is maintained by reflecting them on the other end of the code generation, as long as the traceability is unchanged. However, such invariant traceability between corresponding model and code elements can be violated either when (a) users of MDD protect custom changes from the generated code, or when (b) developers of MDD change the template for generating the default behaviour. A mismatch between user and template code is inevitable as they evolve for their own purposes. In this paper, we propose a two-layered invariant traceability framework that reduces the number of mismatches through bidirectional transformations. On top of existing vertical (model↔code) synchronisations between a model and the template code, a horizontal (code↔code) synchronisation between user and template code is supported, aligning the changes in both directions. Our blinkit tool is evaluated using the data set available from the CVS repositories of a MDD project: Eclipse MDT/GMF.},
  doi       = {10.1109/ICSE.2012.6227162},
  groups    = {Metamodels, mde},
  issn      = {1558-1225},
  keywords  = {program compilers;program diagnostics;software maintenance;two-layered invariant traceability maintenance framework;bidirectional transformations;convention over configuration paradigm;model-driven development;MDD;code generation;default behaviour generation;code elements;user code;template code;vertical synchronisations;horizontal synchronisation;blinkit tool;CVS repositories;Eclipse MDT-GMF;Synchronization;Java;Computational modeling;Generators;Adaptation models;Educational institutions;Prototypes},
}

@InProceedings{galvao2007-survey-traceability-in-MDE,
  author    = {I. {Galvao} and A. {Goknil}},
  booktitle = {11th IEEE International Enterprise Distributed Object Computing Conference (EDOC 2007)},
  title     = {Survey of Traceability Approaches in Model-Driven Engineering},
  year      = {2007},
  month     = {Oct},
  pages     = {313-313},
  abstract  = {Models have been used in various engineering fields to help managing complexity and represent information in different abstraction levels, according to specific notations and stakeholder's viewpoints. Model-Driven Engineering (MDE) gives the basic principles for the use of models as primary artefacts throughout the software development phases and presents characteristics that simplify the engineering of software in various domains, such as Enterprise Computing Systems. Hence, for its successful application, MDE processes must consider traceability practices. They help the understanding, capturing, tracking and verification of software artefacts and their relationships and dependencies with other artefacts during the software life-cycle. In this survey, we discuss the state-of-the-art in traceability approaches in MDE and assess them with respect to five general comparison criteria: representation, mapping, scalability, change impact analysis and tool support. As a complementary result, we have identified some open issues that can be better explored by traceability in MDE.},
  doi       = {10.1109/EDOC.2007.42},
  file      = {:galvao2007-survey-traceability-in-MDE.pdf:PDF},
  groups    = {meta, mde, Metastudies, identification},
  issn      = {1541-7719},
  keywords  = {computational complexity;software engineering;traceability approaches;model-driven engineering;complexity management;abstraction levels;software development;software engineering;enterprise computing systems;software life-cycle;impact analysis;Model driven engineering;Programming;Engineering management;Scalability;Software engineering;Distributed computing;Computer science;Application software;Reverse engineering;Software systems},
}

@InProceedings{naslavsky2007-traceability-of-MB-Testing-MT,
  author    = {Naslavsky, Leila and Ziv, Hadar and Richardson, Debra J.},
  booktitle = {Proceedings of the 3rd International Workshop on Advances in Model-Based Testing},
  title     = {Towards Traceability of Model-Based Testing Artifacts},
  year      = {2007},
  address   = {New York, NY, USA},
  pages     = {105–114},
  publisher = {Association for Computing Machinery},
  series    = {A-MOST ’07},
  abstract  = {Practitioners regard software testing as the central means for ensuring that a system behaves as expected. Due to the recent widespread adoption of model-driven development (MDD), code is no longer the single source for selecting test cases. Testing against original expectations can be done with model-based testing that adopts high-level models as the basis for test generation. In addition to test generation, challenges to model-based testing include creation and maintenance of traceability information among test-related artifacts. Traceability is required to support activities such as result evaluation, regression testing and coverage analysis. MDD and model transformation solutions address the traceability problem by creating relationships among transformed artifacts throughout the transformation process. This paper proposes an approach that leverages model transformation traceability techniques to create fine-grained relationships among model-based testing artifacts. Relationships are created during the test generation process. Their fine granularity enables the support for result evaluation, coverage analysis and regression testing.},
  doi       = {10.1145/1291535.1291546},
  groups    = {MT, mde},
  isbn      = {9781595938503},
  keywords  = {model-driven development, model-based testing, traceability},
  location  = {London, United Kingdom},
  numpages  = {10},
  url       = {https://doi.org/10.1145/1291535.1291546},
}

@InProceedings{arunthavanathan2016-traceability-with-NLP,
  author    = {A. {Arunthavanathan} and S. {Shanmugathasan} and S. {Ratnavel} and V. {Thiyagarajah} and I. {Perera} and D. {Meedeniya} and D. {Balasubramaniam}},
  booktitle = {2016 Moratuwa Engineering Research Conference (MERCon)},
  title     = {Support for traceability management of software artefacts using Natural Language Processing},
  year      = {2016},
  month     = {April},
  pages     = {18-23},
  abstract  = {One of the major problems in software development process is managing software artefacts. While software evolves, inconsistencies between the artefacts do evolve as well. To resolve the inconsistencies in change management, a tool named “Software Artefacts Traceability Analyzer (SAT-Analyzer)” was introduced as the previous work of this research. Changes in software artefacts in requirement specification, Unified Modelling Language (UML) diagrams and source codes can be tracked with the help of Natural Language Processing (NLP) by creating a structured format of those documents. Therefore, in this research we aim at adding an NLP support as an extension to SAT-Analyzer. Enhancing the traceability links created in the SAT-analyzer tool is another focus due to artefact inconsistencies. This paper includes the research methodology and relevant research carried out in applying NLP for improved traceability management. Tool evaluation with multiple scenarios resulted in average Precision 72.22%, Recall 88.89% and F1 measure of 78.89% suggesting high accuracy for the domain.},
  doi       = {10.1109/MERCon.2016.7480109},
  groups    = {ws, NLP use},
  keywords  = {natural language processing;program diagnostics;software engineering;Unified Modeling Language;traceability management;natural language processing;software development process;change management;software artefacts traceability analyzer;Unified Modelling Language;UML;NLP;SAT-analyzer;Software;Natural language processing;Unified modeling language;Maintenance engineering;XML;Data mining;Natural Language Processing;Artefacts;Traceability Links;Traceability Visualization;Taxonomy},
}

@InProceedings{drivalos2010-state-based-traceability,
  author    = {Drivalos-Matragkas, Nikolaos and Kolovos, Dimitrios S. and Paige, Richard F. and Fernandes, Kiran J.},
  booktitle = {Proceedings of the 6th ECMFA Traceability Workshop},
  title     = {A State-Based Approach to Traceability Maintenance},
  year      = {2010},
  address   = {New York, NY, USA},
  pages     = {23–30},
  publisher = {Association for Computing Machinery},
  series    = {ECMFA-TW ’10},
  abstract  = {Traceability of software artefacts has been recognized as an important factor for supporting various software development activities. However, establishing traceability requires a substantial investment in effort. Even when an initial set of traceability links has been established, this set is subject to gradual degradation as the associated artefacts are modified, e.g., due to the evolutionary nature of software development. To avoid this, traceability must be constantly maintained and evolved. The manual maintenance of traceability can be time consuming and error-prone. This paper focuses on reducing the manual effort incurred in performing traceability maintenance tasks. This is achieved by introducing a dedicated mechanism in the Traceability Metamodelling Language, which is used for detecting and evolving problematic trace links. A concrete example is used to demonstrate the practicality and usefulness of our approach.},
  doi       = {10.1145/1814392.1814396},
  groups    = {ws, Metamodels, Trace integrity},
  isbn      = {9781605589930},
  keywords  = {traceability, model driven engineering, evolution},
  location  = {Paris, France},
  numpages  = {8},
  url       = {https://doi.org/10.1145/1814392.1814396},
}

@InBook{seibel2012-efficient-traceability-for-MDE,
  author    = {Seibel, Andreas and Hebig, Regina and Giese, Holger},
  editor    = {Cleland-Huang, Jane and Gotel, Orlena and Zisman, Andrea},
  pages     = {215--240},
  publisher = {Springer London},
  title     = {Traceability in Model-Driven Engineering: Efficient and Scalable Traceability Maintenance},
  year      = {2012},
  address   = {London},
  isbn      = {978-1-4471-2239-5},
  abstract  = {Model-Driven Engineering (MDE) employs models and model transformations as first-class citizens throughout the whole software development life cycle. Support for automated traceability is necessary because models in MDE usually have inherent dependencies between each other, which must be visible. Furthermore, software evolves which implies to also maintain traceability. In this chapter, we present an efficient and scalable traceability maintenance approach. It uses formal rules to specify conditions for maintaining traceability links. We also show the constitution of our rules and how we improved them, in comparison to a previous approach. Based on this formalism, we present two maintenance strategies. We show an initial (batch) strategy that is applied in case that no change information is available. The second strategy is incremental and therefore scalable. The incremental strategy is applied when change information is available. We explain our approach and evaluate the efficiency and scalability of our approach by means of the mobile phone product line case study presented in this book.},
  booktitle = {Software and Systems Traceability},
  doi       = {10.1007/978-1-4471-2239-5_10},
  groups    = {mde},
  url       = {https://doi.org/10.1007/978-1-4471-2239-5_10},
}

@InProceedings{gotel1994,
  author    = {O. C. Z. {Gotel} and C. W. {Finkelstein}},
  booktitle = {Proceedings of IEEE International Conference on Requirements Engineering},
  title     = {An analysis of the requirements traceability problem},
  year      = {1994},
  month     = {April},
  pages     = {94-101},
  abstract  = {Investigates and discusses the underlying nature of the requirements traceability problem. Our work is based on empirical studies, involving over 100 practitioners, and an evaluation of current support. We introduce the distinction between pre-requirements specification (pre-RS) traceability and post-requirements specification (post-RS) traceability to demonstrate why an all-encompassing solution to the problem is unlikely, and to provide a framework through which to understand its multifaceted nature. We report how the majority of the problems attributed to poor requirements traceability are due to inadequate pre-RS traceability and show the fundamental need for improvements. We present an analysis of the main barriers confronting such improvements in practice, identify relevant areas in which advances have been (or can be) made, and make recommendations for research.<>},
  doi       = {10.1109/ICRE.1994.292398},
  groups    = {Metastudies, identification},
  keywords  = {systems analysis;requirements traceability problem analysis;pre-requirements specification traceability;post-requirements specification traceability;requirements engineering practice;requirements traceability tools;Educational institutions;Guidelines;Project management;Research and development},
}

@Article{wohlrab2020-traceability-organization-process-culture,
  author   = {Wohlrab, Rebekka and Knauss, Eric and Steghöfer, Jan-Philipp and Maro, Salome and Anjorin, Anthony and Pelliccione, Patrizio},
  journal  = {Requirements Engineering},
  title    = {Collaborative traceability management: a multiple case study from the perspectives of organization, process, and culture},
  year     = {2020},
  issn     = {1432-010X},
  number   = {1},
  pages    = {21--45},
  volume   = {25},
  abstract = {Traceability is crucial for many activities in software and systems engineering including monitoring the development progress, and proving compliance with standards. In practice, the use and maintenance of trace links are challenging as artifacts undergo constant change, and development takes place in distributed scenarios with multiple collaborating stakeholders. Although traceability management in general has been addressed in previous studies, there is a need for empirical insights into the collaborative aspects of traceability management and how it is situated in existing development contexts. The study reported in this paper aims to close this gap by investigating the relation of collaboration and traceability management, based on an understanding of characteristics of the development effort. In our multiple exploratory case study, we conducted semi-structured interviews with 24 individuals from 15 industrial projects. We explored which challenges arise, how traceability management can support collaboration, how collaboration relates to traceability management approaches, and what characteristics of the development effort influence traceability management and collaboration. We found that practitioners struggle with the following challenges: (1) collaboration across team and tool boundaries, (2) conveying the benefits of traceability, and (3) traceability maintenance. If these challenges are addressed, we found that traceability can facilitate communication and knowledge management in distributed contexts. Moreover, there exist multiple approaches to traceability management with diverse collaboration approaches, i.e., requirements-centered, developer-driven, and mixed approaches. While traceability can be leveraged in software development with both agile and plan-driven paradigms, a certain level of rigor is needed to realize its benefits and overcome challenges. To support practitioners, we provide principles of collaborative traceability management. The main contribution of this paper is empirical evidence of how culture, processes, and organization impact traceability management and collaboration, and principles to support practitioners with collaborative traceability management. We show that collaboration and traceability management have the potential to be mutually beneficial--when investing in one, also the other one is positively affected.},
  groups   = {Metastudies},
  refid    = {Wohlrab2020},
  url      = {https://doi.org/10.1007/s00766-018-0306-1},
}

@InCollection{meinicke2017-feature-traceability,
  author    = {Jens Meinicke and Thomas Th\"{u}m and Reimar Schr\"{o}ter and Fabian Benduhn and Thomas Leich and Gunter Saake},
  booktitle = {Mastering Software Variability with {FeatureIDE}},
  publisher = {Springer International Publishing},
  title     = {Feature Traceability for Feature-Oriented Programming},
  year      = {2017},
  pages     = {173--181},
  abstract  = {Feature traceability refers to the ability to locate features in software artifacts. Traceability helps developers to identify relevant artifacts during development and maintenance. Feature-oriented programming already establishes a one-to-one mapping between features and artifacts, whereas conditional compilation comes with a many-to-many mapping. While all artifacts belonging to a feature are contained in a single feature module, the inherent complexity of variable software poses challenges for developers. The interaction of a feature module with other feature modules can easily lead to unwanted feature interactions. Thus, developers need support to understand which other feature modules are also relevant for their intended changes. In addition, debugging feature-oriented programs is typically challenging, as during the composition of feature modules the mapping disappears.},
  doi       = {10.1007/978-3-319-61443-4_15},
  groups    = {identification},
  url       = {https://doi.org/10.1007/978-3-319-61443-4_15},
}

@InProceedings{mader2007-tracing-unified-process,
  author    = {P. {Maeder} and I. {Philippow} and M. {Riebisch}},
  booktitle = {Eighth ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing (SNPD 2007)},
  title     = {A Traceability Link Model for the Unified Process},
  year      = {2007},
  month     = {July},
  pages     = {700-705},
  volume    = {3},
  abstract  = {Traceability links are widely accepted as efficient means to support an evolutionary software development. However, their usage in analysis and design is effort consuming and error prone due to lacking or missing methods and tools for their creation, update and verification. In this paper we analyse and classify Unified Process artefacts to establish a traceability link model for this process. This model defines all required links between the artefacts. Furthermore, it provides a basis for the (semi)-automatic establishment and the verification of links in Unified Process development projects. We also define a first set of rules as step towards an efficient management of the links. In the ongoing project the rule set is extended to establish a whole framework of methods and rules.},
  doi       = {10.1109/SNPD.2007.342},
  groups    = {Metamodels, Trace integrity},
  keywords  = {formal verification;software process improvement;traceability link model;evolutionary software development;link verification;unified process development projects;Design methodology;Programming;Software engineering;Artificial intelligence;Distributed computing;Error correction;Software systems;Standards development;Design engineering;Performance analysis},
}

@Misc{sotovalero2020tracebased,
  author        = {César Soto-Valero and Thomas Durieux and Nicolas Harrand and Benoit Baudry},
  title         = {Trace-based Debloat for Java Bytecode},
  year          = {2020},
  abstract      = {Software bloat is code that is packaged in an application but is actually not used and not necessary to run the application. The presence of bloat is an issue for software security, for performance, and for maintenance. In recent years, several works have proposed techniques to detect and remove software bloat. In this paper, we introduce a novel technique to debloat Java bytecode through dynamic analysis, which we call trace-based debloat. We have developed JDBL, a tool that automates the collection of accurate execution traces and the debloating process. Given a Java project and a workload, JDBL generates a debloated version of the project that is syntactically correct and preserves the original behavior, modulo the workload. We evaluate the feasibility and the effectiveness of trace-based debloat with 395 open-source Java libraries for a total 10M+ lines of code. We demonstrate that our approach significantly reduces the size of these libraries while preserving the functionalities needed by their clients.},
  archiveprefix = {arXiv},
  eprint        = {2008.08401},
  groups        = {Concrete applications},
  primaryclass  = {cs.SE},
}

@InCollection{ziegenhagen2020-expanding-tracea-with-dynamic-tracing-data,
  author    = {Dennis Ziegenhagen and Andreas Speck and Elke Pulvermueller},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer International Publishing},
  title     = {Expanding Tracing Capabilities Using Dynamic Tracing Data},
  year      = {2020},
  pages     = {319--340},
  abstract  = {Software traceability enables gaining insight into artifact relationships and dependencies throughout software development. This information can be used to support project maintenance and to reduce costs, e.g. by estimating the impact of artifact changes. Many traceability applications require manual effort for creating and managing the necessary data. Current approaches aim at reducing this effort by automating various involved tasks. To support this, we propose an enrichment of tracing data by capturing interactions that influence the artifacts’ life-cycle, which we refer to as dynamic tracing data. Its purpose is to expand capabilities of traceability applications and to enable assistance in development tasks. In this paper, we present our research methodology and current results, most importantly a flexible and modular framework for capturing and using dynamic tracing data, as well as an example scenario to demonstrate a possible implementation and usage of the framework.},
  doi       = {10.1007/978-3-030-40223-5_16},
  groups    = {Trace integrity},
  url       = {https://doi.org/10.1007/978-3-030-40223-5_16},
}

@Conference{ziegenhagen2019-developer-tool-interaction,
  author       = {Dennis Ziegenhagen. and Andreas Speck. and Elke Pulvermüller.},
  booktitle    = {Proceedings of the 14th International Conference on Evaluation of Novel Approaches to Software Engineering - Volume 1: ENASE,},
  title        = {Using Developer-tool-Interactions to Expand Tracing Capabilities},
  year         = {2019},
  organization = {INSTICC},
  pages        = {518-525},
  publisher    = {SciTePress},
  abstract     = {Expanding current software traceability methodologies offers opportunities to significantly support development activities. State-of-the-art traceability frameworks use tracing data at specific points in time. This data includes information about development artefacts and their relations, which may be used for analysis, visualisation and similar purposes. In between those points in time, developers create, modify or delete requirements, diagrams, source code and other relevant artefacts. We propose to capture such artefact interactions in order to enrich the tracing data. By applying existing approaches in the field of developer-tool interaction analysis to the enriched data, we aim at supporting the developer’s work. In this paper, we present the overall approach, along with our development of a modular framework which may be used to capture the desired data from various tools, manage it and finally enable the execution of developer-interaction analyses.},
  doi          = {10.5220/0007762905180525},
  isbn         = {978-989-758-375-9},
}

@InProceedings{ko2008-whyline-debugging,
  author    = {Ko, Andrew J. and Myers, Brad A.},
  booktitle = {Proceedings of the 30th International Conference on Software Engineering},
  title     = {Debugging Reinvented: Asking and Answering Why and Why Not Questions about Program Behavior},
  year      = {2008},
  address   = {New York, NY, USA},
  pages     = {301–310},
  publisher = {Association for Computing Machinery},
  series    = {ICSE '08},
  abstract  = {When software developers want to understand the reason for a program's behavior, they must translate their questions about the behavior into a series of questions about code, speculating about the causes in the process. The Whyline is a new kind of debugging tool that avoids such speculation by instead enabling developers to select a question about program output from a set of why did and why didn't questions derived from the program's code and execution. The tool then finds one or more possible explanations for the output in question, using a combination of static and dynamic slicing, precise call graphs, and new algorithms for determining potential sources of values and explanations for why a line of code was not reached. Evaluations of the tool on one task showed that novice programmers with the Whyline were twice as fast as expert programmers without it. The tool has the potential to simplify debugging in many software development contexts.},
  doi       = {10.1145/1368088.1368130},
  groups    = {Concrete applications},
  isbn      = {9781605580791},
  keywords  = {whyline},
  location  = {Leipzig, Germany},
  numpages  = {10},
  url       = {https://doi.org/10.1145/1368088.1368130},
}

@InProceedings{Bouzidi_2020,
  author    = {Aljia Bouzidi and Nahla Haddar and Mounira Ben-Abdallah and Kais Haddar},
  booktitle = {Proceedings of the 15th International Conference on Evaluation of Novel Approaches to Software Engineering},
  title     = {From {BPMN} to Sequence Diagrams: Transformation and Traceability},
  year      = {2020},
  publisher = {{SCITEPRESS} - Science and Technology Publications},
  abstract  = {A business cannot be competitive unless its business process is aligned with its information system. Indeed, a perfect alignment is key to a coherent management and success of the business. Therefore, it is important to bring closer business process- and IS modeling activities. The current paper presents an approach to derive a dynamic software model from a business process model, including the trace links between source and target elements. Our approach is based on a set of rules that transform a BPMN business process model into a UML sequence diagram structured according to the model view controller design pattern, and a trace model. To show the feasibility of approach in the practice, we developed a tool that implements the transformation rules.},
  doi       = {10.5220/0009418104380445},
  groups    = {MT},
  url       = {https://doi.org/10.5220%2F0009418104380445},
}

@Article{Wang_2020,
  author    = {Fei Wang and Zhi-Bin Yang and Zhi-Qiu Huang and Cheng-Wei Liu and Yong Zhou and Jean-Paul Bodeveix and Mamoun Filali},
  journal   = {{IEEE Trans. Rel.} Transactions on Reliability},
  title     = {An Approach to Generate the Traceability Between Restricted Natural Language Requirements and {AADL} Models},
  year      = {2020},
  month     = {mar},
  number    = {1},
  pages     = {154--173},
  volume    = {69},
  abstract  = {Requirements traceability is broadly recognized as a critical element of any rigorous software development process, especially for building safety-critical software (SCS) systems. Model-driven development (MDD) is increasingly used to develop SCS in many domains, such as automotive and aerospace. MDD provides new opportunities for establishing traceability links through modeling and model transformations. Architecture Analysis and Design Language (AADL) is a standardized architecture description language for embedded systems, which is widely used in avionics and aerospace industries to model safety-critical applications. However, there is a big challenge to automatically establish the traceability links between requirements and AADL models in the context of MDD, because requirements are mostly written as free natural language texts, which are often ambiguous and difficult to be processed automatically. To bridge the gap between natural language requirements (NLRs) and AADL models, we propose an approach to generate the traceability links between NLRs and AADL models. First, we propose a requirement modeling method based on the restricted natural language, which is named as RM-RNL. The RM-RNL can eliminate the ambiguity of NLRs and barely change engineers' habits of requirement specification. Second, we present a method to automatically generate the initial AADL models from the RM-RNLs and to automatically establish traceability links between the elements of the RM-RNL and the generated AADL models. Third, we refine the initial AADL models through patterns to achieve the change of requirements and traceability links. Finally, we demonstrate the effectiveness of our approach with industrial case studies and evaluation experiments.},
  doi       = {10.1109/tr.2019.2936072},
  groups    = {Concrete applications, Metamodels, mde, NLP use},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {https://doi.org/10.1109%2Ftr.2019.2936072},
}

@InProceedings{Gonzalez_2019,
  author    = {Daniel Gonzalez and Libertad Tansini},
  booktitle = {2019 {XLV} Latin American Computing Conference ({CLEI})},
  title     = {Modelling Traceability in Recommender Systems},
  year      = {2019},
  month     = {sep},
  publisher = {{IEEE}},
  abstract  = {Recommender  Systems are  valuable  tools  which suggestmeaningful  and  useful  items  to  users.In  a  previous research   project,   a   real   recommender   system   which   offers personalized  recommendations  of itemsto  health  professionals and  medical  specialists  in  the  context  of  Continuing  Medical Education (CME)was designed and developed.Traceability helps recommender systems to generate justifications about the criteria used forselectingthe suggestions of itemsto the active user. This paper  presents  a  novel  approach  for  modelling  traceability  inrecommender   systems   in   the   given   context. The   proposed approach   shows  how   to   use   different   levels   of   relationships between  users  to  trace  the  origin  of  the  recommendations. An important  contribution  of  this  research is  to  explain how  to generalize  the  proposed  model  of  traceability  in  recommender systems. In    addition,    an    automated    approach    towards communicating the origin of the recommendations to the users is proposed.},
  doi       = {10.1109/clei47609.2019.235091},
  url       = {https://doi.org/10.1109%2Fclei47609.2019.235091},
}

@InProceedings{Arcelli_2019,
  author    = {Davide Arcelli and Vittorio Cortellessa and Daniele Di Pompeo and Romina Eramo and Michele Tucci},
  booktitle = {2019 {IEEE} International Conference on Software Architecture ({ICSA})},
  title     = {Exploiting Architecture/Runtime Model-Driven Traceability for Performance Improvement},
  year      = {2019},
  month     = {mar},
  publisher = {{IEEE}},
  abstract  = {Model-Driven Engineering techniques may achieve a major support to the software development when they allow to manage relationships between a running system and its architectural model. These relationships can be exploited for different goals, such as the software evolution due to new functional requirements. In this paper, we define and use relationships that work as support to the performance improvement of a running system. In particular, we combine: (i) a bidirectional model transformation framework tailored to define relationships between performance monitoring data and an architectural model, with (ii) a technique for detecting performance antipatterns and for suggesting architectural changes, aimed at removing performance problems identified on the basis of runtime information. The result is an integrated approach that exploits traceability relationships between the monitoring data and the architectural model to derive recommended refactoring solutions for the system performance improvement. The approach has been applied to an e-commerce application based on microservices that has been designed by means of UML software models profiled with MARTE.},
  doi       = {10.1109/icsa.2019.00017},
  groups    = {identification},
  url       = {https://doi.org/10.1109%2Ficsa.2019.00017},
}

@InProceedings{Markovic_2019,
  author    = {Milan Markovic and Daniel Garijo and Peter Edwards and Wamberto Vasconcelos},
  booktitle = {2019 Sixth International Conference on Internet of Things: Systems, Management and Security ({IOTSMS})},
  title     = {Semantic Modelling of Plans and Execution Traces for Enhancing Transparency of {IoT} Systems},
  year      = {2019},
  month     = {oct},
  publisher = {{IEEE}},
  abstract  = {Transparency of IoT systems is an essential requirement for enhancing user's trust towards such systems. Provenance mechanisms documenting the execution of IoT systems are often cited as an enabler of such transparency. However, provenance records often lack detailed descriptions of a system's expected behaviour. Plan specifications describe the steps needed to achieve a certain goal by a human or an automated system. Once plans reach a certain level of complexity, they are typically decomposed in different levels of abstraction. However, this decomposition makes it difficult to relate high level abstract plans to their granular execution traces. This paper introduces EP-Plan, a vocabulary for linking the different levels of granularity of a plan with their respective provenance traces. EP-Plan also provides the means to describe plan metadata such as constraints, policies, rationales, and expected participating agents associated with a plan.},
  doi       = {10.1109/iotsms48152.2019.8939260},
  groups    = {Metamodels},
  url       = {https://doi.org/10.1109%2Fiotsms48152.2019.8939260},
}

@Article{Guana_2017,
  author    = {Victor Guana and Eleni Stroulia},
  journal   = {{Softw Syst Model} Systems Modeling},
  title     = {End-to-end model-transformation comprehension through fine-grained traceability information},
  year      = {2017},
  month     = {jun},
  number    = {2},
  pages     = {1305--1344},
  volume    = {18},
  abstract  = {The construction and maintenance of model-to-model and model-to-text transformations pose numerous challenges to novice and expert developers. A key challenge involves tracing dependency relationships between artifacts of a transformation ecosystem. This is required to assess the impact of metamodel evolution, to determine metamodel coverage, and to debug complex transformation expressions. This paper presents an empirical study that investigates the performance of developers reflecting on the execution semantics of model-to-model and model-to-text transformations. We measured the accuracy and efficiency of 25 developers completing a variety of traceability-driven tasks in two model-based code generators. We compared the performance of developers using ChainTracker, a traceability analysis environment developed by our team, and that of developers using Eclipse Modeling. We present statistically significant evidence that ChainTracker improves the performance of developers reflecting on the execution semantics of transformation ecosystems. We discuss how developers supported by off-the-shelf development environments are unable to effectively identify dependency relationships in nontrivial model-transformation chains.},
  doi       = {10.1007/s10270-017-0602-0},
  groups    = {MT, mde, identification},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs10270-017-0602-0},
}

@Article{Haidrar_2018,
  author    = {Saida Haidrar and and Adil Anwar and Jean-Michel Bruel and Ounsa Roudies},
  journal   = {JSW},
  title     = {A Domain-Specific Language to manage Requirements Traceability},
  year      = {2018},
  month     = {sep},
  number    = {9},
  pages     = {460--480},
  volume    = {13},
  abstract  = {Tracing requirements  back  to  stakeholders  and  initial  documents  on  one  hand,  and  forward  to their  corresponding  designed  system  artifacts,  on  the  other  hand,  are  crucial  activities.  Requirements  are often expressed independently from those artifacts and can take several forms: texts or models. This makes hard and  tedious  the  inference  of  trace  links  between  requirements  and  artifacts.  This  paper  introduces ReqDL,  a  domain-specific  language  for  describing  requirements  and,  at  the  same  time,  capturing  bi-directional  traceability  data,  which  concerns  more  precisely  system  modeling  elements.  The  paper  also introduces  a  generation  algorithm basedon  ReqDL  specifications  in  order  to  automatically  generate independent  trace  models.  Indeed,  we  present  ReqDL  concrete  and  abstract  syntax  in  terms  of  grammar and   metamodel. Using   ReqDL   expressions,   we   aim   at   assisting   the   traceability informalizing   easily understandable  requirements  and  establishing  an  initial  relationship  between  requirements  and  other system artifacts. The main resultis the generation of requirements traces modelswhich incorporate explicit and  implicit  trace  links  between  requirements  and  design  elements.  Moreover,  we  provide  a  working example through which we demonstrate ReqDL practicality and usefulness.},
  doi       = {10.17706/jsw.13.9.460-480},
  groups    = {Metamodels},
  publisher = {International Academy Publishing ({IAP})},
  url       = {https://doi.org/10.17706%2Fjsw.13.9.460-480},
}

@InCollection{Diskin_2017,
  author    = {Zinovy Diskin and Abel G{\'{o}}mez and Jordi Cabot},
  booktitle = {Fundamental Approaches to Software Engineering},
  publisher = {Springer Berlin Heidelberg},
  title     = {Traceability Mappings as a Fundamental Instrument in Model Transformations},
  year      = {2017},
  pages     = {247--263},
  abstract  = {Technological importance of traceability mappings for model transformations is well-known, but they have often been considered as an auxiliary element generated during the transformation execution and providing accessory information. This paper argues that traceability mappings should instead be regarded as a core aspect of the transformation definition, and a key instrument in the transformation management.

We will show how a transformation can be represented as the result of execution of a metamodel mapping, which acts as a special encoding of the transformation definition. Since mappings enjoy Boolean operations (as sets of links) and sequential composition (as sets of directed links), encoding transformations by mappings makes it possible to define these operations for transformations as well, which can be useful for model transformation reuse, compositional design, and chaining.},
  comment   = {Technological importance of traceability mappings for model transformations is well-known, but they have often been considered as an auxiliary element generated during the transformation execution and providing accessory information. This paper argues that traceability mappings should instead be regarded as a core aspect of the transformation definition, and a key instrument in the transformation management.

We will show how a transformation can be represented as the result of execution of a metamodel mapping, which acts as a special encoding of the transformation definition. Since mappings enjoy Boolean operations (as sets of links) and sequential composition (as sets of directed links), encoding transformations by mappings makes it possible to define these operations for transformations as well, which can be useful for model transformation reuse, compositional design, and chaining.},
  doi       = {10.1007/978-3-662-54494-5_14},
  groups    = {MT, mde, Metastudies},
  url       = {https://doi.org/10.1007%2F978-3-662-54494-5_14},
}

@InCollection{Filax_2017,
  author    = {Marco Filax and Tim Gonschorek and Frank Ortmeier},
  booktitle = {Model-Based Safety and Assessment},
  publisher = {Springer International Publishing},
  title     = {Building Models We Can Rely On: Requirements Traceability for Model-Based Verification Techniques},
  year      = {2017},
  pages     = {3--18},
  abstract  = {Proving the safety of a critical system is a complex and complicated task. Model-based formal verification techniques can help to verify a System Requirement Specification (SRS) with respect to normative and safety requirements. Due to an early application of these methods, it is possible to reduce the risk of high costs caused by unexpected, late system adjustments. Nevertheless, they are still rarely used. One reason among others is the lack of an applicable integration method in an existing development process.

In this paper, we propose a process to integrate formal model-based verification techniques into the development life-cycle of a safety critical system. The core idea is to systematically refine informal specifications by (1) categorization, (2) structural refinement, (3) expected behavioral refinement, and finally, (4) operational semantics. To support modeling, traceability is upheld through all refinement steps and a number of consistency checks are introduced.

The proposed process has been jointly developed with the German Railroad Authority (EBA) and an accredited safety assessor. We implemented an Eclipse-based IDE with connections to requirement and systems engineering tools as well as various verification engines. The applicability of our approach is demonstrated via an industrial-sized case study in the context of the European Train Control System with ETCS Level 1 Full Supervision.},
  doi       = {10.1007/978-3-319-64119-5_1},
  groups    = {Concrete applications, mde, certification},
  url       = {https://doi.org/10.1007%2F978-3-319-64119-5_1},
}

@InProceedings{Bunder_2017_query-for-quality,
  author    = {Hendrik Bünder and Christoph Rieger and Herbert Kuchen},
  booktitle = {Proceedings of the 5th International Conference on Model-Driven Engineering and Software Development},
  title     = {A Domain-specific Language for Configurable Traceability Analysis},
  year      = {2017},
  publisher = {{SCITEPRESS} - Science and Technology Publications},
  abstract  = {In safety-critical industries such as the aviation industry or the medical industry traceability is required by law and specific regulations. In addition, process models such as CMMI require traceability information for documentation purposes. Although creating and maintaing so-called traceability information models (TIM) takes a lot of effort, its potential for reporting development progress, supporting project management, and measuring software quality often remains untapped. The domain-specific language presented in this paper builds on an existing traceability solution and allows to define queries, metrics, and rules for company- or project-specific usage. The basis for such an analysis is a query expression to retrieve information from a TIM. Customizable metrics are then defined to compute aggregated values, which are evaluated against company- or project-specific thresholds using the rules part of the domain-specific language. The focus of this paper is to show how the combination of query, metric, and rule expressions is used to define and compute customizable analyses based on individual requirements.},
  doi       = {10.5220/0006138503740381},
  groups    = {Metamodels, Trace analysis, Trace integrity, identification},
  url       = {https://doi.org/10.5220%2F0006138503740381},
}

@Article{Buchmann_2015,
  author    = {Robert Andrei Buchmann and Dimitris Karagiannis},
  journal   = {Requirements Eng},
  title     = {Modelling mobile app requirements for semantic traceability},
  year      = {2015},
  month     = {jul},
  number    = {1},
  pages     = {41--75},
  volume    = {22},
  abstract  = {The paper presents a modelling method aimed to support the definition and elicitation of requirements for mobile apps through an approach that enables semantic traceability for the requirements representation. Business process-centricity is employed in order to capture requirements in a knowledge structure that retains procedural knowledge from stakeholders and can be traversed by semantic queries in order to trace domain-specific contextual information for the modelled requirements. Consequently, instead of having requirements represented as natural language items that are documented by diagrammatic models, the communication channels are switched: semantically interlinked conceptual models become the requirements representation, while free text can be used for requirements annotations/metadata. Thus, the method establishes a knowledge externalization channel between business stakeholders and app developers, also tackling the Twin Peaks bridging challenge (between requirements and early designs). The method is presented using its modelling procedure as a guiding thread, with each step illustrated by case-based samples of the modelling language and auxiliary functionality. The design work is encompassed by an existing metamodelling framework and introduces a taxonomy for modelling relations, since the metamodel is the key enabler for the goal of semantic traceability. The research was driven by the ComVantage EU research project, concerned with mobile app support for collaborative business process execution. Therefore, the project provides context for the illustrating examples; however, generalization possibilities beyond the project scope will also be discussed, with respect to both motivation and outcome.},
  doi       = {10.1007/s00766-015-0235-1},
  groups    = {Metamodels},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs00766-015-0235-1},
}

@InCollection{la_Fosse_2018,
  author    = {Thibault B{\'{e}}ziers la Fosse and Massimo Tisi and Jean-Marie Mottu},
  booktitle = {Software Technologies: Applications and Foundations},
  publisher = {Springer International Publishing},
  title     = {Injecting Execution Traces into a Model-Driven Framework for Program Analysis},
  year      = {2018},
  pages     = {3--13},
  abstract  = {Model-Driven Engineering (MDE) has been successfully used in static program analysis. Frameworks like MoDisco inject the program structure into a model, available for further processing by query and transformation tools, e.g., for program understanding, reverse-engineering, modernization. In this paper we present our first steps towards extending MoDisco with capabilities for dynamic program analysis.

We build an injector for program execution traces, one of the basic blocks of dynamic analysis. Our injector automatically instruments the code, executes it and captures a model of the execution behavior of the program, coupled with the model of the program structure. We use the trace injection mechanism for model-driven impact analysis on test sets. We identify some scalability issues that remain to be solved, providing a case study for future efforts in improving performance of model-management tools.},
  doi       = {10.1007/978-3-319-74730-9_1},
  groups    = {mde, identification},
  url       = {https://doi.org/10.1007%2F978-3-319-74730-9_1},
}

@InProceedings{Kr_mer_2016,
  author    = {Jan-Peter Krämer and Joel Brandt and Jan Borchers},
  booktitle = {Proceedings of the 2016 {CHI} Conference on Human Factors in Computing Systems},
  title     = {Using Runtime Traces to Improve Documentation and Unit Test Authoring for Dynamic Languages},
  year      = {2016},
  month     = {may},
  publisher = {{ACM}},
  abstract  = {Documentation and unit tests increase software maintainability, but real world software projects rarely have adequate coverage. We hypothesize that, in part, this is because existing authoring tools require developers to adjust their workflows significantly. To study whether improved interaction design could affect unit testing and documentation practice, we created an authoring support tool called Vesta. The main insight guiding Vesta's interaction design is that developers frequently manually test the software they are building. We propose leveraging runtime information from these manual executions. Because developers naturally exercise the part of the code on which they are currently working, this information will be highly relevant to appropriate documentation and testing tasks. In a complex coding task, nearly all documentation created using Vesta was accurate, compared to only 60% of documentation created without Vesta, and Vesta was able to generate significant portions of all tests, even those written manually by developers without Vesta.},
  doi       = {10.1145/2858036.2858311},
  url       = {https://doi.org/10.1145%2F2858036.2858311},
}

@InProceedings{Haidrar_2016,
  author    = {Saida Haidrar and Adil Anwar and Ounsa Roudies},
  booktitle = {2016 4th {IEEE} International Colloquium on Information Science and Technology ({CiSt})},
  title     = {Towards a generic framework for requirements traceability management for {SysML} language},
  year      = {2016},
  month     = {oct},
  publisher = {{IEEE}},
  abstract  = {Requirements traceability provides support to check that the final system meets stakeholders' requirements. Although the important role of requirements traceability is widely recognized, the application of traceability methods remains limited and varies from one development team to another. In this work, we aim at providing a common approach for requirements traceability in case of complex system development. A generic framework has been devised to manage requirement traceability along system development process. We propose a metamodel in order to define trace models and give a representation for all system artifacts and trace links. We have then included a Trace generation activity based on an algorithm to automate the trace models extraction. We use a Temperature Control System in order to apply our traceability framework.},
  doi       = {10.1109/cist.2016.7805044},
  groups    = {Metamodels},
  url       = {https://doi.org/10.1109%2Fcist.2016.7805044},
}

@Article{Cazzola_2016,
  author    = {Walter Cazzola and Paola Giannini and Albert Shaqiri},
  journal   = {Electronic Notes in Theoretical Computer Science},
  title     = {Formal Attributes Traceability in Modular Language Development Frameworks},
  year      = {2016},
  month     = {apr},
  pages     = {119--134},
  volume    = {322},
  abstract  = {Modularization and component reuse are concepts that can speed up the design and implementation of domain specific languages. Several modular development frameworks have been developed that rely on attributes to share information among components. Unfortunately, modularization also fosters development in isolation and attributes could be undefined or used inconsistently due to a lack of coordination. This work presents 1) a type system that permits to trace attributes and statically validate the composition against attributes lack or misuse and 2) a correct and complete type inference algorithm for this type system. The type system and inference are based on the Neverlang development framework but it is also discussed how it can be used with different frameworks.},
  doi       = {10.1016/j.entcs.2016.03.009},
  groups    = {Concrete applications},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016%2Fj.entcs.2016.03.009},
}

@InProceedings{Faddegon_2016,
  author    = {Maarten Faddegon and Olaf Chitil},
  booktitle = {Proceedings of the 37th {ACM} {SIGPLAN} Conference on Programming Language Design and Implementation - {PLDI} 2016},
  title     = {Lightweight computation tree tracing for lazy functional languages},
  year      = {2016},
  publisher = {{ACM} Press},
  abstract  = {A computation tree of a program execution describes computations of functions and their dependencies. A computation tree describes how a program works and is at the heart of algorithmic debugging. To generate a computation tree, existing algorithmic debuggers either use a complex implementation or yield a less informative approximation. We present a method for lazy functional languages that requires only a simple tracing library to generate a detailed computation tree. With our algorithmic debugger a programmer can debug any Haskell program by only importing our library and annotating suspected functions.},
  comment   = {debug},
  doi       = {10.1145/2908080.2908104},
  url       = {https://doi.org/10.1145%2F2908080.2908104},
}

@InProceedings{Mani_2016,
  author    = {Nariman Mani and Dorina Petriu and Murray Woodside},
  booktitle = {Proceedings of the 28th International Conference on Software Engineering and Knowledge Engineering},
  title     = {Cross-Model Traceability for Coupled Transformation of Software and Performance Models},
  year      = {2016},
  month     = {jul},
  publisher = {{KSI} Research Inc. and Knowledge Systems Institute Graduate School},
  abstract  = {In Model Driven Engineering, the relationship between a source and target model can be maintained, when the source model undergoes changes, by a coupled transformation, whereby changes applied to the source model are incrementally propagated to the target model. Cross-model traceability links are key to applying the correct changes to the target model. The coupled transformation considered in this paper propagates changes to a Layered Queueing Network (LQN) performance model (originally derived from a UML design model of a SOA system) as an effect of applying design patterns to the SOA model. A special problem arises because of differences in the level of abstraction between UML and LQN (i.e. a performance model element may represent a set of many design model elements). This paper bridges the abstraction gap between models by proposing traceability links that use new collection types (not defined in the source metamodel) to represent complex source model elements,},
  doi       = {10.18293/seke2016-142},
  groups    = {Coevolution, mde},
  url       = {https://doi.org/10.18293%2Fseke2016-142},
}

@Article{Lee_2016,
  author    = {Jihyun Lee and Sunmyung Hwang},
  journal   = {Wireless Pers Commun},
  title     = {Variability Change Management Using the Orthogonal Variability Model-Based Traceability},
  year      = {2016},
  month     = {jan},
  number    = {3},
  pages     = {729--745},
  volume    = {89},
  abstract  = {Variability is the ability of a software system or artifacts to be changed, customized, or configured for reuse in the product members of a software product line. As the amount of variability increases in software product lines the complexity of managing changes and evolutions of such variability becomes a main concern these days. In this context a high-degree of traceability can support the complexity of variability change management. However, in software product line establishing appropriate traceability is often difficult due to many-to-many relations in different levels of abstraction and across development given two separated and closely related development life cycles called domain and application. This paper proposes an approach tracing variability based on explicit variation points defined in orthogonal variability model and domain artifacts. And we validate the proposed approach through the Calculator product line. As the results of validation we found that our approach supports the defined variability change scenarios well, but has a disadvantage that many derived variation points are additionally defined and managed.},
  doi       = {10.1007/s11277-016-3195-y},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs11277-016-3195-y},
}

@InCollection{Di_Francescomarino_2015,
  author    = {Chiara Di Francescomarino and Chiara Ghidini and Sergio Tessaris and Itzel V{\'{a}}zquez Sandoval},
  booktitle = {Advanced Information Systems Engineering},
  publisher = {Springer International Publishing},
  title     = {Completing Workflow Traces Using Action Languages},
  year      = {2015},
  pages     = {314--330},
  abstract  = {The capability to monitor process and service executions, which has gone to notably increase in the last decades due to the growing adoption of IT-systems, has brought to the diffusion of several reasoning-based tools for the analysis of process executions. Nevertheless, in many real cases, the different degrees of abstraction of models and IT-data, the lack of IT-support on all the steps of the model, as well as information hiding, result in process execution data conveying only incomplete information concerning the process-level activities. This may hamper the capability to analyse and reason about process executions. This paper presents a novel approach to recover missing information about process executions, relying on a reformulation in terms of a planning problem.},
  doi       = {10.1007/978-3-319-19069-3_20},
  groups    = {identification},
  url       = {https://doi.org/10.1007%2F978-3-319-19069-3_20},
}

@InProceedings{Pape_2015,
  author    = {Tobias Pape and Tim Felgentreff and Robert Hirschfeld and Anton Gulenko and Carl Friedrich Bolz},
  booktitle = {Proceedings of the 11th Symposium on Dynamic Languages - {DLS} 2015},
  title     = {Language-independent storage strategies for tracing-{JIT}-based virtual machines},
  year      = {2015},
  publisher = {{ACM} Press},
  abstract  = {Storage strategies have been proposed as a run-time optimization for the PyPy Python implementation and have shown promising results for optimizing execution speed and memory requirements. However, it remained unclear whether the approach works equally well in other dynamic languages. Furthermore, while PyPy is based on RPython, a language to write VMs with reusable components such as a tracing just-in-time compiler and garbage collection, the strategies design itself was not generalized to be reusable across languages implemented using that same toolchain. In this paper, we present a general design and implementation for storage strategies and show how they can be reused across different RPython-based languages. We evaluate the performance of our implementation for RSqueak, an RPython-based VM for Squeak/Smalltalk and show that storage strategies may indeed offer performance benefits for certain workloads in other dynamic programming languages.We furthermore evaluate the generality of our implementation by applying it to Topaz, a Ruby VM, and Pycket, a Racket implementation.},
  doi       = {10.1145/2816707.2816716},
  groups    = {Concrete applications},
  url       = {https://doi.org/10.1145%2F2816707.2816716},
}

@InCollection{Ogunyomi_2015,
  author    = {Babajide Ogunyomi and Louis M. Rose and Dimitrios S. Kolovos},
  booktitle = {Modelling Foundations and Applications},
  publisher = {Springer International Publishing},
  title     = {Property Access Traces for Source Incremental Model-to-Text Transformation},
  year      = {2015},
  pages     = {187--202},
  abstract  = {Automatic generation of textual artefacts (including code, documentation, configuration files, build scripts, etc.) from models in a software development process through the application of model-to-text (M2T) transformation is a common MDE activity. Despite the importance of M2T transformation, contemporary M2T languages lack support for developing transformations that scale with the size of the input model. As MDE is applied to systems of increasing size and complexity, a lack of scalability in M2T (and other) transformation languages hinders industrial adoption. In this paper, we propose a form of runtime analysis that can be used to identify the impact of source model changes on generated textual artefacts. The structures produced by this runtime analysis, property access traces, can be used to perform efficient source-incremental transformation: our experiments show an average reduction of 60% in transformation execution time compared to non-incremental (batch) transformation.},
  doi       = {10.1007/978-3-319-21151-0_13},
  groups    = {MT, mde, identification},
  url       = {https://doi.org/10.1007%2F978-3-319-21151-0_13},
}

@InProceedings{Bauman_2015,
  author    = {Spenser Bauman and Carl Friedrich Bolz and Robert Hirschfeld and Vasily Kirilichev and Tobias Pape and Jeremy G. Siek and Sam Tobin-Hochstadt},
  booktitle = {Proceedings of the 20th {ACM} {SIGPLAN} International Conference on Functional Programming - {ICFP} 2015},
  title     = {Pycket: a tracing {JIT} for a functional language},
  year      = {2015},
  publisher = {{ACM} Press},
  abstract  = {We present Pycket, a high-performance tracing JIT compiler for Racket. Pycket supports a wide variety of the sophisticated features in Racket such as contracts, continuations, classes, structures, dynamic binding, and more. On average, over a standard suite of benchmarks, Pycket outperforms existing compilers, both Racket's JIT and other highly-optimizing Scheme compilers. Further, Pycket provides much better performance for Racket proxies than existing systems, dramatically reducing the overhead of contracts and gradual typing. We validate this claim with performance evaluation on multiple existing benchmark suites. The Pycket implementation is of independent interest as an application of the RPython meta-tracing framework (originally created for PyPy), which automatically generates tracing JIT compilers from interpreters. Prior work on meta-tracing focuses on bytecode interpreters, whereas Pycket is a high-level interpreter based on the CEK abstract machine and operates directly on abstract syntax trees. Pycket supports proper tail calls and first-class continuations. In the setting of a functional language, where recursion and higher-order functions are more prevalent than explicit loops, the most significant performance challenge for a tracing JIT is identifying which control flows constitute a loop---we discuss two strategies for identifying loops and measure their impact.},
  doi       = {10.1145/2784731.2784740},
  groups    = {Concrete applications, identification},
  url       = {https://doi.org/10.1145%2F2784731.2784740},
}

@InCollection{Pace_2014,
  author    = {Gordon J. Pace and Michael Rosner},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer International Publishing},
  title     = {Explaining Violation Traces with Finite State Natural Language Generation Models},
  year      = {2014},
  pages     = {179--189},
  abstract  = {An essential element of any verification technique is that of identifying and communicating to the user, system behaviour which leads to a deviation from the expected behaviour. Such behaviours are typically made available as long traces of system actions which would benefit from a natural language explanation of the trace and especially in the context of business logic level specifications. In this paper we present a natural language generation model which can be used to explain such traces. A key idea is that the explanation language is a CNL that is, formally speaking, regular language susceptible transformations that can be expressed with finite state machinery. At the same time it admits various forms of abstraction and simplification which contribute to the naturalness of explanations that are communicated to the user.},
  doi       = {10.1007/978-3-319-10223-8_17},
  groups    = {Visualization, Trace analysis, identification},
  url       = {https://doi.org/10.1007%2F978-3-319-10223-8_17},
}

@Article{Mat__2014,
  author    = {Alejandro Mat{\'{e}} and Juan Trujillo},
  journal   = {{Computer Standards & Interfaces} Interfaces},
  title     = {Tracing conceptual models{\textquotesingle} evolution in data warehouses by using the model driven architecture},
  year      = {2014},
  month     = {sep},
  number    = {5},
  pages     = {831--843},
  volume    = {36},
  abstract  = {Developing a data warehouse is an ongoing task where new requirements are constantly being added. A widely accepted approach for developing data warehouses is the hybrid approach, where requirements and data sources must be accommodated to a reconciliated data warehouse model. During this process, relationships between conceptual elements specified by user requirements and those supplied by the data sources are lost, since no traceability mechanisms are included. As a result, the designer wastes additional time and effort to update the data warehouse whenever user requirements or data sources change. In this paper, we propose an approach to preserve traceability at conceptual level for data warehouses. Our approach includes a set of traces and their formalization, in order to relate the multidimensional elements specified by user requirements with the concepts extracted from data sources. Therefore, we can easily identify how changes should be incorporated into the data warehouse, and derive it according to the new configuration. In order to minimize the effort required, we define a set of general Query/View/Transformation rules to automate the derivation of traces along with data warehouse elements. Finally, we describe a CASE tool that supports our approach and provide a detailed case study to show the applicability of the proposal.},
  doi       = {10.1016/j.csi.2014.01.004},
  groups    = {identification, Coevolution},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016%2Fj.csi.2014.01.004},
}

@InCollection{Pfeiffer_2014,
  author    = {Rolf-Helge Pfeiffer and Jan Reimann and Andrzej W{\k{a}}sowski},
  booktitle = {Modelling Foundations and Applications},
  publisher = {Springer International Publishing},
  title     = {Language-Independent Traceability with Lässig},
  year      = {2014},
  pages     = {148--163},
  abstract  = {Typical programming languages, including model transformation languages, do not support traceability. Applications requiring inter-object traceability implement traceability support repeatedly for different domains. In this paper we introduce a solution for generic traceability which enables the generation of trace models for all programming languages compiling to Virtual Machine (VM) bytecode by leveraging automatically generated observer aspects.

We implement our solution in a tool called Lässig adding traceability support to all programming languages compiling to the Java Virtual Machine (JVM). We evaluate and discuss general feasibility, correctness, and the performance overhead of our solution by applying it to three model-to-model transformations.

Our generic traceability solution is capable of automatically establishing complete sets of trace links for transformation programs in various languages and at a minimum cost. Lässig is available as an open-source project for integration into modeling frameworks},
  doi       = {10.1007/978-3-319-09195-2_10},
  url       = {https://doi.org/10.1007%2F978-3-319-09195-2_10},
}

@InCollection{Inostroza_2014,
  author    = {Pablo Inostroza and Tijs van der Storm and Sebastian Erdweg},
  booktitle = {Theory and Practice of Model Transformations},
  publisher = {Springer International Publishing},
  title     = {Tracing Program Transformations with String Origins},
  year      = {2014},
  pages     = {154--169},
  abstract  = {Program transformations play an important role in domain-specific languages and model-driven development. Tracing the execution of such transformations has well-known benefits for debugging, visualization and error reporting. In this paper, we introduce string origins, a lightweight, generic and portable technique to establish a tracing relation between the textual fragments in the input and output of a program transformation. We discuss the semantics and the implementation of string origins using the Rascal meta programming language as an example. We illustrate the utility of string origins by presenting data structures and operations for tracing generated code, implementing protected regions, performing name resolution and fixing inadvertent name capture in generated code.},
  doi       = {10.1007/978-3-319-08789-4_12},
  groups    = {NLP use},
  url       = {https://doi.org/10.1007%2F978-3-319-08789-4_12},
}

@InProceedings{Boulanger_2014,
  author    = {Frederic Boulanger and Christophe Jacquet and Cecile Hardebolle and Iuliana Prodan},
  booktitle = {2014 Twelfth {ACM}/{IEEE} Conference on Formal Methods and Models for Codesign ({MEMOCODE})},
  title     = {{TESL}: A language for reconciling heterogeneous execution traces},
  year      = {2014},
  month     = {oct},
  publisher = {{IEEE}},
  abstract  = {Various formalisms deal with time, and each of them has its own notion of time. When designing a system, it is often desirable to combine several of these formalisms to model different parts. Therefore one has to reconcile execution traces that may use different kinds of time (discrete, continuous, periodic) and different time scales (e.g. minutes, microseconds or even angles in degrees). In this article, we present a deterministic model of time which allows the specification of the coincidence of events that occur on different time scales, as well as instantaneous causality between events. This model supports both event-driven and time-driven specifications.},
  doi       = {10.1109/memcod.2014.6961849},
  url       = {https://doi.org/10.1109%2Fmemcod.2014.6961849},
}

@InProceedings{Laghouaouta_2014,
  author    = {Youness Laghouaouta and Mahmoud Nassar and Adil Anwar and Jean-Michel Bruel},
  booktitle = {2014 {IEEE} Eighth International Conference on Research Challenges in Information Science ({RCIS})},
  title     = {On the use of graph transformations for model composition traceability},
  year      = {2014},
  month     = {may},
  publisher = {{IEEE}},
  abstract  = {The model composition provides support to build systems based on a set of less complex sub-models. This operation allows managing complexity while supporting the modularity and reusability tasks. Due to the increase number of the involving models, their composition becomes a tedious task. For that, the need for maintaining traceability information is raised to help managing the composition operation. We propose in this work a graph-based model transformations approach, which aims to keep track of the model composition operation. Our objective is to capture traces in an automatic and reusable manner. Finally, a composition scenario is given to demonstrate the feasibility of our proposal.},
  doi       = {10.1109/rcis.2014.6861075},
  groups    = {mde},
  url       = {https://doi.org/10.1109%2Frcis.2014.6861075},
}

@InProceedings{Saada_2013,
  author    = {Hajer Saada and Marianne Huchard and Clementine Nebut and Houari Sahraoui},
  booktitle = {2013 28th {IEEE}/{ACM} International Conference on Automated Software Engineering ({ASE})},
  title     = {Recovering model transformation traces using multi-objective optimization},
  year      = {2013},
  month     = {nov},
  publisher = {{IEEE}},
  abstract  = {Model Driven Engineering (MDE) is based on a large set of models that are used and manipulated throughout the development cycle. These models are manually or automatically produced and/or exploited using model transformations. To allow engineers to maintain the models and track their changes, recovering transformation traces is essential. In this paper, we propose an automated approach, based on multi-objective optimization, to recover transformation traces between models. Our approach takes as input a source model in the form of a set of fragments (fragments are defined using the source meta-model cardinalities and OCL constraints), and a target model. The recovered transformation traces take the form of many-to-many mappings between the constructs of the two models},
  doi       = {10.1109/ase.2013.6693134},
  groups    = {MT, mde, identification},
  url       = {https://doi.org/10.1109%2Fase.2013.6693134},
}

@InProceedings{Szabo_2013,
  author    = {Claudia Szabo and Yufei Chen},
  booktitle = {2013 22nd Australian Software Engineering Conference},
  title     = {A Model-Driven Approach for Ensuring Change Traceability and Multi-model Consistency},
  year      = {2013},
  month     = {jun},
  publisher = {{IEEE}},
  abstract  = {In model driven engineering, high-level models of an application are constructed to enable reasoning about functional and non-functional requirements independently of implementation issues and concerns. This allows for reduced maintenance, shortens development time, and permits automated model updates, system model executions, and impact assessment. Part of model driven engineering, multi-modeling integrates models that abstract various aspects of the system, such as I/O, behavioral, and functional among others, at different levels of granularity and using various domain specific modeling languages. An important challenge is to understand the relationship between these models towards preserving multi-model consistency as changes in one model affect other models in the multi-model. This paper presents a multi-modeling architecture that captures model relationships at syntactic and semantic levels. We define a taxonomy of change effects that relies on a relationship correspondence meta-model to highlight and trace the impact of changes across various modeling environments. Following the correspondence meta-model and associated change effects, our prototype implementation ensures that multi-model consistency is met and notifies stakeholders of significant changes. Our case study of a submarine tracking system checks multi model consistency and highlights the impact of changes across system modeling tools that capture its functional and behavioral aspects among others. Our experiments show the feasibility of our approach while highlighting important challenges.},
  doi       = {10.1109/aswec.2013.24},
  groups    = {Metamodels, mde},
  url       = {https://doi.org/10.1109%2Faswec.2013.24},
}

@InCollection{Santiago_2013,
  author    = {Iv{\'{a}}n Santiago and Juan M. Vara and Valeria de Castro and Esperanza Marcos},
  booktitle = {Communications in Computer and Information Science},
  publisher = {Springer Berlin Heidelberg},
  title     = {Measuring the Effect of Enabling Traces Generation in {ATL} Model Transformations},
  year      = {2013},
  pages     = {229--240},
  abstract  = {The benefits that proper management of traceability information can bring to any given (software development) project are beyond any doubt. These benefits become even more appealing when dealing with traceability does not imply additional efforts. This is the case of Model-Driven Engineering (MDE). As a matter of fact, since model transformations are the wheel that drives MDE proposals forward, traceability data can be automatically available in MDE projects. To that end, the implicit traceability relationships contained in any model transformation have to be made explicit by enriching the model transformation with traces generation capabilities. However, this refinement process implies a cost in terms of quality: enriched transformations are intuitively more complex. To back such intuition, this work presents an empirical study to assess the impact over the quality of the automatic enrichment of model transformations},
  doi       = {10.1007/978-3-642-54092-9_17},
  groups    = {mde},
  url       = {https://doi.org/10.1007%2F978-3-642-54092-9_17},
}

@Article{Rosenkranz_2013,
  author    = {Christoph Rosenkranz and Marianne Corvera Charaf and Roland Holten},
  journal   = {Journal of Information Technology},
  title     = {Language Quality in Requirements Development: Tracing Communication in the Process of Information Systems Development},
  year      = {2013},
  month     = {sep},
  number    = {3},
  pages     = {198--223},
  volume    = {28},
  abstract  = {Knowledge transfer, communication, and shared understanding between project stakeholders are important factors in requirements development and in the information systems development process. Nevertheless, the impact and analysis of language and linguistic communication during requirements development is still an open issue. In our research, we claim that requirements development depends on the ability to deal with language and communication issues in practice and reach shared understanding of requirements. We propose the concept of language quality as a suitable means for analyzing the emergence of coherent and meaningful requirements. By applying the thereby developed dimensions of language quality to a real information systems development project, we are able to obtain practice-grounded propositions to further evaluate the consequences of different actions on the interaction and communication process of stakeholders in requirements development.},
  doi       = {10.1057/jit.2012.33},
  publisher = {{SAGE} Publications},
  url       = {https://doi.org/10.1057%2Fjit.2012.33},
}

@InCollection{Alhaj_2013,
  author    = {Mohammad Alhaj and Dorina C. Petriu},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  title     = {Traceability Links in Model Transformations between Software and Performance Models},
  year      = {2013},
  pages     = {203--221},
  abstract  = {In Model Driven Engineering, traceability is used to establish relationships between various software artifacts during the software life cycle. Traceability can be also used to define dependencies between related elements in different models, to propagate and verify properties from one model to another and to analyze the impact of changes. In this paper we describe how to define typed trace-links between different kinds of models in our model transformation chain PUMA4SOA, which generates Layered Queuing performance models from UML software models of service-oriented applications. The goal of PUMA4SOA is to help evaluate the performance of SOA systems in the early development phases. In our approach, the traceability links are stored externally in a new model, which maintain traces separately from the source and target models they refer to. We illustrate how traceability links can be used to propagate the results of the performance model back to the original software model.},
  doi       = {10.1007/978-3-642-38911-5_12},
  groups    = {MT, mde},
  url       = {https://doi.org/10.1007%2F978-3-642-38911-5_12},
}

@Article{George_2012,
  author    = {Mathew George and Klaus-Peter Fischer-Hellmann and Martin Knahl and Udo Bleimann and Shirley Atkinson},
  journal   = {Future Internet},
  title     = {Traceability in Model-Based Testing},
  year      = {2012},
  month     = {nov},
  number    = {4},
  pages     = {1026--1036},
  volume    = {4},
  abstract  = {The growing complexities of software and the demand for shorter time to market are two important challenges that face today’s IT industry. These challenges demand the increase of both productivity and quality of software. Model-based testing is a promising technique for meeting these challenges. Traceability modeling is a key issue and challenge in model-based testing. Relationships between the different models will help to navigate from one model to another, and trace back to the respective requirements and the design model when the test fails. In this paper, we present an approach for bridging the gaps between the different models in model-based testing. We propose relation definition markup language (RDML) for defining the relationships between models.},
  doi       = {10.3390/fi4041026},
  groups    = {mde},
  publisher = {{MDPI} {AG}},
  url       = {https://doi.org/10.3390%2Ffi4041026},
}

@InCollection{van_Amstel_2012,
  author    = {Marcel F. van Amstel and Mark G. J. van den Brand and Alexander Serebrenik},
  booktitle = {Theory and Practice of Model Transformations},
  publisher = {Springer Berlin Heidelberg},
  title     = {Traceability Visualization in Model Transformations with {TraceVis}},
  year      = {2012},
  pages     = {152--159},
  abstract  = {Model transformations are commonly used to transform models suited for one purpose (e.g., describing a solution in a particular domain) to models suited for a related but different purpose (e.g., simulation or execution). The disadvantage of a transformational approach, however, is that feedback acquired from analyzing transformed models is not reported on the level of the problem domain but on the level of the transformed model. Expressing the feedback on the level of the problem domain requires improving traceability in model transformations.

We propose to visualize traceability links in (chains of) model transformations, thus making traceability amenable for analysis.},
  doi       = {10.1007/978-3-642-30476-7_10},
  groups    = {MT, mde, Visualization, Trace analysis},
  url       = {https://doi.org/10.1007%2F978-3-642-30476-7_10},
}

@InCollection{Jim_nez_2013,
  author    = {{\'{A}}lvaro Jim{\'{e}}nez and Juan M. Vara and Ver{\'{o}}nica A. Bollati and Esperanza Marcos},
  booktitle = {Building Sustainable Information Systems},
  publisher = {Springer {US}},
  title     = {Model-Driven Development of Model Transformations Supporting Traces Generation},
  year      = {2013},
  pages     = {233--245},
  abstract  = {This work introduces a framework for model-driven development of model transformations that support traces generation. The proposal starts from a high-level specification of the relationships that must hold between the elements of source and target metamodels. Such specification is subsequently refined into lower-level transformation models until they can be serialized into the source code that implements the transformation. Running such transformation produces not only the corresponding source models but also a trace model between the elements of source and target models.},
  doi       = {10.1007/978-1-4614-7540-8_18},
  groups    = {MT, mde},
  url       = {https://doi.org/10.1007%2F978-1-4614-7540-8_18},
}

@InProceedings{2012,
  author    = {Francisca Rosique, Pedro Sánchez, Diego Alonso and Manuel Jiménez},
  booktitle = {Proceedings of the 7th International Conference on Software Paradigm Trends},
  title     = {Traceability Support for {MDE} Development of Home Automation Systems},
  year      = {2012},
  publisher = {{SciTePress} - Science and and Technology Publications},
  abstract  = {Traceability is a technique to ease determining the impact of changes in the design of software, to support their integration, to preserve knowledge, and to assure the quality and accuracy of the overall system. In this paper, an approach that considers traceability in the context of model-driven development of Home Automation (HA) systems is presented. This combination enables the development of tools with techniques for improving the quality both of the process and of the models obtained. To obtain these advantages we have developed a tool that provides users with traceability reports after applying model transformations. These reports enable developers to study whether all requirements have been considered, the impact of changes, and how they are considered both in architectural decisions and code implementations.},
  doi       = {10.5220/0004081302240229},
  groups    = {mde},
  url       = {https://doi.org/10.5220%2F0004081302240229},
}

@InProceedings{Sannier_2012,
  author    = {Nicolas Sannier and Benoit Baudry},
  booktitle = {2012 Second {IEEE} International Workshop on Model-Driven Requirements Engineering ({MoDRE})},
  title     = {Toward multilevel textual requirements traceability using model-driven engineering and information retrieval},
  year      = {2012},
  month     = {sep},
  publisher = {{IEEE}},
  abstract  = {In complex industrial projects, textual information remains the main vector of information at the project level. Consequently, requirements are scattered throughout multiple documents expressing different levels of requirements and different kinds of requirements. Formalizing this information and tracing different relationships among documents and organizing this environment present a challenging question. Domain-specific modeling and traceability modeling are Model-Driven Engineering (MDE) techniques that could address various aspects of requirements formalization. Text-based high level requirements can be formalized as document concepts can be gathered and represented. Still, relationships cannot always be determined using sole MDE approaches and, as a consequence, relationships and traceability issue remains. Information retrieval (IR) approaches have already proved to work in an efficient way on large text corpora for requirements traceability analysis but do only consider similarity aspects of flatten documents, losing their organization and hierarchy. This paper aims to introduce how a combined use of both MDE and IR can lead to improved requirements organization and traceability while handling textual ambiguous requirements documents.},
  doi       = {10.1109/modre.2012.6360072},
  groups    = {Metamodels, mde, identification},
  url       = {https://doi.org/10.1109%2Fmodre.2012.6360072},
}

@InCollection{Graf_2012,
  author    = {Andreas Graf and Nirmal Sasidharan and Ömer Gürsoy},
  booktitle = {Complex Systems Design {\&} Management},
  publisher = {Springer Berlin Heidelberg},
  title     = {Requirements, Traceability and {DSLs} in Eclipse with the Requirements Interchange Format ({ReqIF})},
  year      = {2012},
  pages     = {187--199},
  abstract  = {Requirements engineering (RE) is a crucial aspect in systems development and is the area of ongoing research and process improvement.However, unlike in modeling, there has been no established standard that activities could converge on. In recent years, the emerging Requirements Interchange Format (RIF/ReqIF) gained more and more visibility in the industry, and research projects started to investigate these standards. To avoid redundant efforts in implementing the standard, the VERDE and Deploy projects cooperate to provide a stable common basis for ReqIF implementation that could be leveraged by other research projects as well. In this paper, we present an Eclipse-based extensible implementation of a RIF/ReqIFbased requirements editing platform. In addition, we also investigate two related aspects of RE that take advantage of the common platform. Firstly, how can the quality of requirements be improved by replacing or complementing natural language requirements with formal approaches such as domain specific languages or models. Secondly, how can we establish a robust traceability mechanism that links different artifacts of a development process like requirements, design etc.},
  doi       = {10.1007/978-3-642-25203-7_13},
  groups    = {mde},
  url       = {https://doi.org/10.1007%2F978-3-642-25203-7_13},
}

@InProceedings{Garces_2011,
  author    = {Kelly Garces and Julien Deantoni and Frederic Mallet},
  booktitle = {2011 37th {EUROMICRO} Conference on Software Engineering and Advanced Applications},
  title     = {A Model-Based Approach for Reconciliation of Polychronous Execution Traces},
  year      = {2011},
  month     = {aug},
  publisher = {{IEEE}},
  abstract  = {Embedded systems are very difficult to design and debug because of the limited access to the device itself. Therefore, debugging usually requires to instrument the code so as to produce execution traces that are then monitored from a base station. Such an intrusive method has a direct impact on performances. In case of multiple interacting embedded targets the problem is even more severe and is not limited to computations but also spreads to communications. To reduce the communication overhead, we propose an approach in which unsynchronized traces from several targets are reconciled a posteriori. Since each target has its own time base without a built-in clock synchronization protocol, our approach requires a multi-clock reconciliation specification. This paper describes our model-based proposal developed during the ANR project RT-Simex. The different steps of the reconciliation are illustrated on a simple case-study used in the project, a terrestrial robot controlled in position.},
  doi       = {10.1109/seaa.2011.47},
  url       = {https://doi.org/10.1109%2Fseaa.2011.47},
}

@Article{Sanchez_2011,
  author    = {Pedro Sanchez and Diego Alonso and Francisca Rosique and Barbara Alvarez and Juan A. Pastor},
  journal   = {{IEEE Trans. Comput.} Transactions on Computers},
  title     = {Introducing Safety Requirements Traceability Support in Model-Driven Development of Robotic Applications},
  year      = {2011},
  month     = {aug},
  number    = {8},
  pages     = {1059--1071},
  volume    = {60},
  abstract  = {Requirements traceability is a technique intended to help determine the impact of changes in software design, support their integration, preserve knowledge, and assure the quality and correctness of the overall system. This paper presents an approach that considers traceability of safety requirements in the context of model-driven development of teleoperated services robots. The combination of the model-driven approach with safety requirements traceability makes it possible to construct systems using techniques for automatically identifying, managing, and mitigating risks so that these systems are safe enough to work in a particular environment. To secure the advantages of these mechanisms, we have developed a tool that provides users with traceability reports after applying model transformations. These reports enable developers to determine whether or not all safety requirements have been considered, the impact of changing a safety requirement, and how they are considered both in architectural decisions and code implementations.},
  doi       = {10.1109/tc.2010.149},
  groups    = {Metamodels, mde, certification, identification},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {https://doi.org/10.1109%2Ftc.2010.149},
}

@Article{Grosch_2011,
  author    = {Vanessa Grosch},
  journal   = {International Journal of Embedded and Real-Time Communication Systems},
  title     = {Requirements Traceability within Model-Based Testing},
  year      = {2011},
  month     = {apr},
  number    = {2},
  pages     = {1--21},
  volume    = {2},
  abstract  = {Requirements traceability enables the linkage between all development artifacts during the development process. Within model-based testing, requirements traceability links the original requirements with test model elements and generated test cases. Current approaches are either not practical or lack the necessary formal foundation for generating requirements-based test cases using model-checking techniques involving the requirements trace. This paper describes a practical and formal approach to ensure requirements traceability. The descriptions of the requirements are defined on path fragments of timed automata or timed state charts. The graphical representation of these paths is called a computation sequence chart (CSC). CSCs are automatically transformed into temporal logic formulae. A model-checking algorithm considers these formulae when generating test cases.},
  doi       = {10.4018/jertcs.2011040101},
  groups    = {Visualization},
  publisher = {{IGI} Global},
  url       = {https://doi.org/10.4018%2Fjertcs.2011040101},
}

@InCollection{Ono_2010,
  author    = {Kouichi Ono and Manabu Toyota and Ryo Kawahara and Yoshifumi Sakamoto and Takeo Nakada and Naoaki Fukuoka},
  booktitle = {Modelling Foundations and Applications},
  publisher = {Springer Berlin Heidelberg},
  title     = {A Model-Based Method for Evaluating Embedded System Performance by Abstraction of Execution Traces},
  year      = {2010},
  pages     = {233--244},
  abstract  = {his paper describes a model-based method to evaluate performance of embedded systems. The core technology of this modeling method is reverse modeling based on dynamic analysis of the existing systems. A case study of real MFPs (multifunction peripherals/printers) is presented in this paper to evaluate the modeling method.},
  doi       = {10.1007/978-3-642-13595-8_19},
  url       = {https://doi.org/10.1007%2F978-3-642-13595-8_19},
}

@InProceedings{Yrj_nen_2010,
  author    = {Anton Yrjönen and Janne Merilinna},
  booktitle = {Proceedings of the 6th {ECMFA} Traceability Workshop on - {ECMFA}-{TW} {\textquotesingle}10},
  title     = {Tooling for the full traceability of non-functional requirements within model-driven development},
  year      = {2010},
  publisher = {{ACM} Press},
  abstract  = {There is an ever-increasing need to rapidly deliver products, whilst, at the same time, also delivering products of high quality. To improve the quality of products and increase productivity within software development processes, all phases of the development process must fit together well. While defining requirements for the system, it must be ensured that the correct requirements are defined as well as ensure that they can be translated into a design fulfilling the requirements. The earlier the correct requirements are found, the easier and cheaper it will be to design good products. Finally, the design must be verified against the correct requirements. To realize this, requirements traceability is of extreme importance for development processes. The non-functional requirements (NFR) are particularly important and difficult. In this paper, we will report on an integrated tooling solution for a Domain-Specific Modelling approach that enables and guides towards defining accurate and non-conflicting requirements. Additionally, the solution enables a full bidirectional traceability from the requirements to models to the implementation, and offers an up-to-date overall view of the state of the requirements within the product.},
  doi       = {10.1145/1814392.1814395},
  groups    = {Metamodels, mde, certification},
  url       = {https://doi.org/10.1145%2F1814392.1814395},
}

@InProceedings{Levendovszky_2010,
  author    = {Tihamer Levendovszky and Daniel Balasubramanian and Kevin Smyth and Feng Shi and Gabor Karsai},
  booktitle = {Proceedings of the 6th {ECMFA} Traceability Workshop on - {ECMFA}-{TW} {\textquotesingle}10},
  title     = {A transformation instance-based approach to traceability},
  year      = {2010},
  publisher = {{ACM} Press},
  abstract  = {Although traceability is often a suggested requirement for general software development, there are areas such as airborne systems, where traceability is a compulsory part of the development process. This paper describes a tool chain that is able to generate and to follow traceability links across model-to-model and model-to-code transformations, and capable of providing navigability support along these traceability links. We elaborate on the conceptual design of our tool chain and provide details on its realization in a DSML environment underpinned by graph rewriting-based model transformation.},
  doi       = {10.1145/1814392.1814400},
  groups    = {Metamodels, mde},
  url       = {https://doi.org/10.1145%2F1814392.1814400},
}

@InProceedings{Pfeiffer_2010,
  author    = {Rolf-Helge Pfeiffer and Andrzej W{\k{a}}sowski},
  booktitle = {Proceedings of the 6th {ECMFA} Traceability Workshop on - {ECMFA}-{TW} {\textquotesingle}10},
  title     = {An aspect-based traceability mechanism for domain specific languages},
  year      = {2010},
  publisher = {{ACM} Press},
  abstract  = {Development environments for domain specific modeling usually represent elements of visual models as objects when in memory and as XML elements when persisted. Visual models are editable using different kinds of editors, and both the in-memory representations and the serialization syntax can be manipulated by automatic tools. We present Tengja, a toolkit, that automatically collects the traces between model elements in abstract, visual, and serialization syntax. Once the trace model is established by Tengja it can be used by other applications to synchronize representations involved, or to navigate across models. We demonstrate the toolkit by implementing a simple navigation support on top of it.},
  doi       = {10.1145/1814392.1814399},
  groups    = {Metamodels},
  url       = {https://doi.org/10.1145%2F1814392.1814399},
}

@InProceedings{bin_Abid_2010,
  author    = {Saad bin Abid},
  booktitle = {Proceedings of the 6th {ECMFA} Traceability Workshop on - {ECMFA}-{TW} {\textquotesingle}10},
  title     = {Resolving feature dependency implementations inconsistencies during product derivation},
  year      = {2010},
  publisher = {{ACM} Press},
  abstract  = {Features implementing the functionality in a software product line (SPL) often interact and depend on each other. It is hard to maintain the consistency between feature dependencies on the model level and the actual implementation over time, resulting in inconsistency during product derivation. We describe our initial results when working with feature dependency implementations and the related inconsistencies in actual code. Our aim is to improve consistency checking during product derivation. We have provided tool support for maintaining consistency between feature dependency implementations on both model and code levels in a product line. The tool chain supports the consistency checking on both the domain engineering and the application levels between actual code and models. We report our experience of managing feature dependency consistency in the context of an existing scientific calculator product line.},
  doi       = {10.1145/1814392.1814397},
  url       = {https://doi.org/10.1145%2F1814392.1814397},
}

@InProceedings{Goknil_2010,
  author    = {Arda Goknil and Ivan Kurtev and Klaas van den Berg},
  booktitle = {Proceedings of the 6th {ECMFA} Traceability Workshop on - {ECMFA}-{TW} {\textquotesingle}10},
  title     = {Tool support for generation and validation of traces between requirements and architecture},
  year      = {2010},
  publisher = {{ACM} Press},
  abstract  = {Traceability is considered crucial for establishing and maintaining consistency between software development artifacts. Although considerable research has been devoted to relating requirements and design artifacts with source code, less attention has been paid to relating requirements with architecture by using well-defined semantics of traces. We present a tool that provides trace establishment by using semantics of traces between R&A (Requirements and Architecture). The tool provides the following: (1) generation/validation of traces by using requirements relations and/or verification of architecture, (2) generation/validation of requirements relations by using traces. The tool uses the semantics of traces together with requirements relations and verification results for generating and validating traces. It is based on model transformations in ATL and term-rewriting logic in Maude.},
  doi       = {10.1145/1814392.1814398},
  url       = {https://doi.org/10.1145%2F1814392.1814398},
}

@InProceedings{Dubois_2010,
  author    = {Hubert Dubois and Marie-Agnes Peraldi-Frati and Fadoi Lakhal},
  booktitle = {2010 15th {IEEE} International Conference on Engineering of Complex Computer Systems},
  title     = {A Model for Requirements Traceability in a Heterogeneous Model-Based Design Process: Application to Automotive Embedded Systems},
  year      = {2010},
  month     = {mar},
  publisher = {{IEEE}},
  abstract  = {Requirements traceability modeling is a key issue in real-time embedded design process. In such systems, requirements are of different nature (software-related, system-related, functional or non functional) and must be traced through a multilevel design flow which integrates multiple tools and heterogeneous models. Validation and Verification (V&V) activities must be performed on models and on the final product to check whether they match the initial requirements. Results of design and V&V activities must be able to impact traceability information. We thus propose DARWIN4REQ, a metamodel for requirement traceability, based on three independent flows (requirement model, solution model and V&V model). The new metamodel establishes a link between these flows and affords full traceability of requirements, including those set for heterogeneous models. This paper presents the DARWIN4REQ metamodel and its use in the context of heterogeneous models for requirements modeling, design and V&V. An automotive application illustrates the proposed approach based on UML-profiles such that SYSML, EAST-ADL2 and MARTE for design and on SIMULINK, SyNDEx and TIMESQUARE for V&V activities.},
  doi       = {10.1109/iceccs.2010.2},
  groups    = {Metamodels},
  url       = {https://doi.org/10.1109%2Ficeccs.2010.2},
}

@InProceedings{Naslavsky_2010,
  author    = {Leila Naslavsky and Hadar Ziv and Debra J. Richardson},
  booktitle = {2010 Third International Conference on Software Testing, Verification and Validation},
  title     = {{MbSRT}2: Model-Based Selective Regression Testing with Traceability},
  year      = {2010},
  publisher = {{IEEE}},
  abstract  = {Widespread adoption of model-centric development has created opportunities for software testing, with Model-Based Testing (MBT). MBT supports the generation of test cases from models and the demonstration of model and source-code compliance. Models evolve, much like source code. Thus, an important activity of MBT is selective regression testing, which selects test cases for retest based on model modifications, rather than source-code modifications. This activity explores relationships between model elements and test cases that traverse those elements to locate retest able test cases. We contribute an approach and prototype to model-based selective regression testing, whereby fine-grain traceability relationships among entities in models and test cases are persisted into a traceability infrastructure throughout the test generation process: the relationships represent reasons for test case creation and are used to select test cases for re-run. The approach builds upon existing regression test selection techniques and adopts scenarios as behavioral modeling perspective. We analyze precision, efficiency and safety of the approach through case studies and through theoretical and intuitive reasoning.},
  doi       = {10.1109/icst.2010.61},
  groups    = {Metamodels},
  url       = {https://doi.org/10.1109%2Ficst.2010.61},
}

@Article{Her_2010,
  author    = {Jin Sun Her and Hao Yuan and Soo Dong Kim},
  journal   = {Information and Software Technology},
  title     = {Traceability-centric model-driven object-oriented engineering},
  year      = {2010},
  month     = {aug},
  number    = {8},
  pages     = {845--870},
  volume    = {52},
  abstract  = {Context: Object-oriented (OO) development method is a popular paradigm in developing target systems. However, the current practices of OO analysis and design (OOAD) and implementation largely rely on human developers' experience and expertise, making it possible less efficient and more error-prone. Hence, there is room for improving the development efficiency while preserving high quality of programs. Objective: Model-driven development (MDD) is a promising approach to developing programs by machine-assisted model transformation, saving human efforts and reducing the possibility of introducing program faults. Hence, it is appealing to apply key disciplines of MDD in developing OO programs. Method: In this paper, we propose a comprehensive framework for applying MDD on OO program engineering in a rigorous and formal fashion. The framework consists of: (1) a hybrid engineering model of human and machine, (2) meta-models of OOAD artifacts, (3) traceability map with trace links, and (4) transformation rules. Results: We identified five platform independent models and two platform specific models, and defined formal representations for them. We identified 16 traceability links and accordingly 16 transformation rules among the eight artifacts. Through the case study, we showed that our work is feasible and applicable. We assessed our work and concluded that our work is sound, complete, and extendable. Our work established the foundation toward automatic generation of OO programs based on the traceability framework. Conclusion: It is concluded that it is essential to identify the OOAD artifacts, traceability links, and transformation rules for automatic generation of OO programs. It is also important to understand the human involvement nature in MDD and to explicitly treat them in the model transformation.},
  doi       = {10.1016/j.infsof.2010.03.012},
  groups    = {Concrete applications, Metamodels, mde, identification},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016%2Fj.infsof.2010.03.012},
}

@InProceedings{Morgan_2010,
  author    = {Bo Morgan},
  booktitle = {2010 Fourth {IEEE} International Conference on Self-Adaptive and Self-Organizing Systems Workshop},
  title     = {Funk2: A Distributed Processing Language for Reflective Tracing of a Large Critic-Selector Cognitive Architecture},
  year      = {2010},
  month     = {sep},
  publisher = {{IEEE}},
  abstract  = {We see the field of metareasoning to be the answer to many large organizational problems encountered when putting together an understandable cognitive architecture, capable of commonsense reasoning. In this paper we review the EM1 implementation of the Emotion Machine critic-selector architecture, as well as explain the current progress we have made in redesigning this first version implementation. For this purpose of redesign and large-scale implementation, we have written a novel programming language, Funk2, that focuses on efficient metareasoning and procedural reflection, the keystones of the critic-selector architecture. We present an argument for why the Funk2 programming language lends itself to easing the burden on programmers that prefer to not be restricted to strictly declarative programming paradigms by allowing the learning of critic and selector activation strengths by credit assignment through arbitrary procedural code.},
  doi       = {10.1109/sasow.2010.56},
  groups    = {Metamodels},
  url       = {https://doi.org/10.1109%2Fsasow.2010.56},
}

@Article{Grave_2010,
  author    = {Andrejs Grave},
  journal   = {Scientific Journal of Riga Technical University. Computer Sciences},
  title     = {Testing and Traceability Aspects in the Context of the Model Driven Architecture ({MDA})},
  year      = {2010},
  month     = {jan},
  number    = {1},
  pages     = {52--59},
  volume    = {41},
  abstract  = {With the growth of complexity of the software systems it becomes more complicated to ensure and evaluate quality of the software being built. This paper discusses quality of the software in the context of the Model Driven Architecture. Paper analyses factors that affect quality of the software in the software development projects that are developed using MDA. As one of the important factor that affects quality of the software, is traceability. This paper provides description of the traceability property and importance of it within development of the software. Within context of this paper traceability is considered as a property of a system description technique that allows changes in one of the system descriptions to be traced to the corresponding portions of the other descriptions. This paper is focused on such aspects of the software development as testing and traceability in the context of MDA. Paper contains in review of traceability, MDA and traceability within MDA. Also paper contains description of the method for formal definition of the problem domain – called Topological functioning modeling for model driven architecture (TFMfMDA). This paper introduces method of the application of the TFM as the traceability tool. TFM as the traceability tool can be used to analyze impact of the changes and select most important tests.},
  doi       = {10.2478/v10143-010-0024-8},
  groups    = {mde},
  publisher = {Walter de Gruyter {GmbH}},
  url       = {https://doi.org/10.2478%2Fv10143-010-0024-8},
}

@InProceedings{Hegedus_2010,
  author    = {Abel Hegedus and Gabor Bergmann and Istvan Rath and Daniel Varro},
  booktitle = {2010 8th {IEEE} International Conference on Software Engineering and Formal Methods},
  title     = {Back-annotation of Simulation Traces with Change-Driven Model Transformations},
  year      = {2010},
  month     = {sep},
  publisher = {{IEEE}},
  abstract  = {Model-driven analysis aims at detecting design flaws early in high-level design models by automatically deriving mathematical models. These analysis models are subsequently investigated by formal verification and validation (V&V) tools, which may retrieve traces violating a certain requirement. Back-annotation aims at mapping back the results of V&V tools to the design model in order to highlight the real source of the fault, to ease making necessary amendments. Here we propose a technique for the back-annotation of simulation traces based on change-driven model transformations. Simulation traces of analysis models will be persisted as a change model with high-level change commands representing macro steps of a trace. This trace is back-annotated to the design model using change-driven transformation rules, which bridge the conceptual differences between macro steps in the analysis and design traces. Our concepts will be demonstrated on the back-annotation problem for analyzing BPEL processes using a Petri net simulator.},
  doi       = {10.1109/sefm.2010.28},
  groups    = {Concrete applications, Trace analysis, Trace integrity, identification},
  url       = {https://doi.org/10.1109%2Fsefm.2010.28},
}

@InProceedings{Dickerson_2010,
  author    = {Charles Dickerson and Ricardo Valerdi},
  booktitle = {2010 5th International Conference on System of Systems Engineering},
  title     = {Using relational model transformations to reduce complexity in {SoS} requirements traceability: Preliminary investigation},
  year      = {2010},
  month     = {jun},
  publisher = {{IEEE}},
  abstract  = {The principles and methods of Model Driven Architecture are applied to the problem of requirements traceability for a System of Systems (SoS). Model transformations of operational threads are used to reduce the complexity of modeling mission requirements and their flow into the architecture of the SoS. The allocation of requirements to operational mission threads (OMTs) rather than to individual systems reduces the complexity of the requirements tracing. Relational transformations provide a mathematically based formalism for model transformations that permit precise computation of the transformation of operational threads into threads of systems allocated from the SoS. Connectivity requirements for the SoS are also exposed in this way and the number of permissible system threads are seen to correspond directly to the number of permissible transformations. The principles and methods are illustrated by an elementary case study for sensor fusion.},
  comment   = {Req eng.},
  doi       = {10.1109/sysose.2010.5544064},
  url       = {https://doi.org/10.1109%2Fsysose.2010.5544064},
}

@Article{Maoz_2009,
  author    = {Shahar Maoz},
  journal   = {Computer},
  title     = {Using Model-Based Traces as Runtime Models},
  year      = {2009},
  month     = {oct},
  number    = {10},
  pages     = {28--36},
  volume    = {42},
  abstract  = {Software engineers typically use code-level tracing to capture a running system's behavior. An alternative is to generate and analyze model-based traces, which contain rich semantic information about the system's runs at the abstraction level that its design models define. A set of metrics and operators can aid such trace analysis.},
  doi       = {10.1109/mc.2009.336},
  groups    = {Concrete applications},
  publisher = {Institute of Electrical and Electronics Engineers ({IEEE})},
  url       = {https://doi.org/10.1109%2Fmc.2009.336},
}

@InProceedings{Clauzel_2009,
  author    = {Damien Clauzel and Karim Sehaba and Yannick Pri{\'{e}}},
  booktitle = {2009 International Conference on Intelligent Networking and Collaborative Systems},
  title     = {Modelling and Visualising Traces for Reflexivity in Synchronous Collaborative Systems},
  year      = {2009},
  month     = {nov},
  publisher = {{IEEE}},
  abstract  = {This article addresses issues related to traces modelling and visualization in synchronous collaborative learning. The objective is to propose models and tools for representing, transforming, sharing and visualizing traces of users' experiences. The traces here represent the users' activities in their interactions with the learning platform. Our proposition is based on reflexive learning defined as the ability to interact with the situation, in order to meet one's own limitations. This work takes place in the ITHACA project which aims at developing an online learning platform that uses interaction traces as knowledge sources on, and for, the learners' learning as individuals or groups. In this paper, we propose a general framework for trace management and sharing, a generic model of synchronous collaborative activity based on the notion of interaction modes, which we specialized for whiteboard sharing and text chatting. We modelled an IRC client and developed a first implementation.},
  doi       = {10.1109/incos.2009.55},
  groups    = {Tracing processes},
  url       = {https://doi.org/10.1109%2Fincos.2009.55},
}

@Article{Valderas_2009,
  author    = {Pedro Valderas and Vicente Pelechano},
  journal   = {Information and Software Technology},
  title     = {Introducing requirements traceability support in model-driven development of web applications},
  year      = {2009},
  month     = {apr},
  number    = {4},
  pages     = {749--768},
  volume    = {51},
  abstract  = {Requirements traceability is a technique intended to help determine the impact of changes in software design, support their integration, preserve knowledge, and assure the quality and correctness of the overall system. This paper presents an approach that considers traceability of safety requirements in the context of model-driven development of teleoperated services robots. The combination of the model-driven approach with safety requirements traceability makes it possible to construct systems using techniques for automatically identifying, managing, and mitigating risks so that these systems are safe enough to work in a particular environment. To secure the advantages of these mechanisms, we have developed a tool that provides users with traceability reports after applying model transformations. These reports enable developers to determine whether or not all safety requirements have been considered, the impact of changing a safety requirement, and how they are considered both in architectural decisions and code implementations.},
  doi       = {10.1016/j.infsof.2008.09.008},
  groups    = {mde, certification, identification},
  publisher = {Elsevier {BV}},
  url       = {https://doi.org/10.1016%2Fj.infsof.2008.09.008},
}

@InProceedings{Kerstan_2008,
  author    = {C. Kerstan and N. Bannow and W. Rosenstiel},
  booktitle = {2008 Forum on Specification, Verification and Design Languages},
  title     = {Enabling automated code transformation and variable tracing},
  year      = {2008},
  month     = {sep},
  publisher = {{IEEE}},
  abstract  = {To solve the challenge of hardware/software partitioning and the reuse of legacy system models (Bannow et al., 2004) introduced a module adapter (MA) based approach which is considered in section 2. The described transformation/mapping of functional code into a SystemC model still needs heavy code modifications. Besides the parser that has to be nearly as powerful as a C++ compiler the readability suffers from the necessary changes. This paper introduces an approach which reduces the code modifications to a minimum. The primary objective is to provide a solution to enable an automated application. In this novel approach, code readability and transformation effort are improved significantly by using the powerful operator overloading mechanism of C++. The presented implementation can be used to either realize transparent communication over module barriers, trace simulation data or only for debugging purposes. Some examples demonstrate the applicability and give some incitements for expedient use cases. The presented C++ code can be easily extended by inheritance for custom needs.},
  doi       = {10.1109/fdl.2008.4641447},
  groups    = {Concrete applications},
  url       = {https://doi.org/10.1109%2Ffdl.2008.4641447},
}

@InProceedings{Boskovic_2007,
  author    = {Marko Boskovic},
  booktitle = {14th Annual {IEEE} International Conference and Workshops on the Engineering of Computer-Based Systems ({ECBS}{\textquotesingle}07)},
  title     = {Model-Based Empirical Performance Evaluation Based on Relational Traces},
  year      = {2007},
  month     = {mar},
  publisher = {{IEEE}},
  abstract  = {Empirical performance evaluation is the process of measuring and calculating performance metrics of deployed software systems. It is a part of performance validation during testing of a software system. The topic of this thesis is an approach for the empirical performance evaluation in the context of model-driven engineering. The hypothesis which will be examined is whether concepts of the temporal databases theory can be used as a general way for empirical performance evaluation of model-driven developed software},
  doi       = {10.1109/ecbs.2007.52},
  url       = {https://doi.org/10.1109%2Fecbs.2007.52},
}

@InCollection{Olsen,
  author    = {G{\o}ran K. Olsen and Jon Oldevik},
  booktitle = {Model Driven Architecture- Foundations and Applications},
  publisher = {Springer Berlin Heidelberg},
  title     = {Scenarios of Traceability in Model to Text Transformations},
  year      = {2007},
  pages     = {144--156},
  abstract  = {The challenges of managing change in model-driven development are addressed by traceability mechanisms for model to text transformations. A traceability model, tailored for representing trace information between models and generated code, provides the basis for visualisation and analysis of the relationships between models and code. Usage scenarios for traceability are discussed and illustrated by our traceability implementation.},
  doi       = {10.1007/978-3-540-72901-3_11},
  groups    = {MT, Metamodels, mde},
  url       = {https://doi.org/10.1007%2F978-3-540-72901-3_11},
}

@Article{Almeida_2007,
  author    = {Jo{\~{a}}o Paulo A. Almeida and Maria-Eugenia Iacob and Pascal van Eck},
  journal   = {Inf Syst Front},
  title     = {Requirements traceability in model-driven development: Applying model and transformation conformance},
  year      = {2007},
  month     = {aug},
  number    = {4},
  pages     = {327--342},
  volume    = {9},
  doi       = {10.1007/s10796-007-9038-3},
  groups    = {Coevolution, mde},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fs10796-007-9038-3},
}

@Article{Triebsees_2007,
  author    = {Thomas Triebsees},
  journal   = {JSW},
  title     = {Constraint-based Model Transformation: Tracing the Preservation of Semantic Properties},
  year      = {2007},
  month     = {sep},
  number    = {3},
  volume    = {2},
  abstract  = {We present and evaluate a novel constraint based model transformation approach that implements a preservation-centric view. The proposed framework comprises formal preservation constraints that can be used to specify the preservation of invariants that are possibly implemented differently in the source and target model. These invariants are enclosed in concepts, which at the same time serve as grouping mechanism for their different implementations. In that, our framework abstracts from the concrete implementation languages by pre-supposing only a basic set of modeling constructs. To this end, we present two case studies where we apply our approach for the preservation of non-trivial properties and provide some performance analysis where we show that tracking the preservation of a relevant class of complex properties can be done in linear time.},
  doi       = {10.4304/jsw.2.3.19-29},
  groups    = {Metamodels, mde},
  publisher = {International Academy Publishing ({IAP})},
  url       = {https://doi.org/10.4304%2Fjsw.2.3.19-29},
}

@InProceedings{Almeida_2006,
  author    = {Joao Paulo Almeida and Pascal van Eck and Maria-eugenia Iacob},
  booktitle = {2006 10th {IEEE} International Enterprise Distributed Object Computing Conference ({EDOC}{\textquotesingle}06)},
  title     = {Requirements Traceability and Transformation Conformance in Model-Driven Development},
  year      = {2006},
  month     = {oct},
  publisher = {{IEEE}},
  abstract  = {The variety of design artefacts (models) produced in a model-driven design process results in an intricate relationship between requirements and the various models. This paper proposes a methodological framework that simplifies management of this relationship. This framework is a basis for tracing requirements, assessing the quality of model transformation specifications, metamodels, models and realizations. We propose a notion of conformance between application models which reduces the effort needed for assessment activities. We discuss how this notion of conformance can be integrated with model transformations},
  doi       = {10.1109/edoc.2006.45},
  groups    = {Coevolution, MT, mde, certification},
  url       = {https://doi.org/10.1109%2Fedoc.2006.45},
}

@InCollection{Brassel_2006,
  author    = {Bernd Brassel and Sebastian Fischer and Frank Huch},
  booktitle = {Logic-Based Program Synthesis and Transformation},
  publisher = {Springer Berlin Heidelberg},
  title     = {A Program Transformation for Tracing Functional Logic Computations},
  year      = {2006},
  pages     = {160--176},
  abstract  = {Tracing program executions is a promising technique to find bugs in lazy functional logic programs. In previous work we developed an extension of a heap based semantics for functional logic languages which generates a trace reflecting the computation of the program. This extension was also prototypically implemented by instrumenting an interpreter for functional logic programs. Since this interpreter is too restricted for real world applications, we developed a program transformation which efficiently computes the trace by means of side effects during the computation. This paper presents our program transformation.},
  doi       = {10.1007/978-3-540-71410-1_12},
  groups    = {MT},
  url       = {https://doi.org/10.1007%2F978-3-540-71410-1_12},
}

@InProceedings{Peischl_2005,
  author    = {Bernhard Peischl and Franz Wotawa},
  booktitle = {Proceedings of the Sixth sixth international symposium on Automated analysis-driven debugging - {AADEBUG}{\textquotesingle}05},
  title     = {Error traces in model-based debugging of hardware description languages},
  year      = {2005},
  publisher = {{ACM} Press},
  abstract  = {In this article we address the fault localization problem in HDLs, particularly in VHDL designs. Our approach relies on the model-based diagnosis paradigm and, unlike to other approaches that rely on the design's gate-level representation, we accurately represent the program's syntax and semantics in a debugging model. This detailed modeling approach, however, may cause scalability problems for larger designs, thus reducing the model's complexity and size is a crucial issue. Creating a debugging model specifically for a given test case in terms of its execution trace is, although tractable in terms of the model's size, uneligible for source level debugging. We illustrate this result by a simple example and relate it to similar findings in the area of program slicing. Moreover, we present a solution to this problem and discuss implications on software debugging by means of our recent empirical results.},
  doi       = {10.1145/1085130.1085136},
  groups    = {Concrete applications},
  url       = {https://doi.org/10.1145%2F1085130.1085136},
}

@InCollection{Belkadi_2006,
  author    = {Farouk Belkadi and Eric Bonjour and Maryvonne Dulmet},
  booktitle = {Lecture Notes in Computer Science},
  publisher = {Springer Berlin Heidelberg},
  title     = {Modelling Framework of a Traceability System to Improve Knowledge Sharing and Collaborative Design},
  year      = {2006},
  pages     = {355--364},
  abstract  = {In collaborative design, the results of each activity imply modifications of different objects of the situation and are likely to affect the achievement of other activities. The use of collaborative tools enhances the capitalization process, especially at the stage of information collecting. Conversely, capitalized knowledge can also promote cooperation between actors regarding their situation in common. This paper develops a new modelling framework of a traceability system, based on the concept of work situation, to improve knowledge sharing and collaborative design. It aims at giving designers a collaborative tool to capture information of their work and, simultaneously, a view of the progress of their activity and of other inter-related activities.},
  doi       = {10.1007/11686699_36},
  groups    = {Metamodels},
  url       = {https://doi.org/10.1007%2F11686699_36},
}

@InProceedings{Mason,
  author    = {P. Mason and A. Saeed and P. Arkely and S. Riddle},
  booktitle = {10th {IEEE} International Conference and Workshop on the Engineering of Computer-Based Systems, 2003. Proceedings.},
  title     = {Meta-modelling approach to traceability for avionics: a framework for managing the engineering of computer based aerospace systems},
  year      = {2003},
  publisher = {{IEEE} Comput. Soc},
  abstract  = {Traceability is the common term for mechanisms to record and navigate relationships between artifacts produced by development and assessment processes. Effective management of these relationships is crucial to projects involving the development of complex, safety critical computer based aerospace systems. Practitioners use a range of notations to model such systems. Most have tool support, though a lack of well defined approaches to integration limits traceability between their respective data sets. This paper proposes a framework known as MATrA (Meta-modelling Approach to Traceability for Avionics) that enables traceability links to be established and consistency maintained across data from potentially disjoint tools.},
  doi       = {10.1109/ecbs.2003.1194804},
  groups    = {Metamodels},
  url       = {https://doi.org/10.1109%2Fecbs.2003.1194804},
}

@InProceedings{Nilsson_1999,
  author    = {Henrik Nilsson},
  booktitle = {Proceedings of the fourth {ACM} {SIGPLAN} international conference on Functional programming - {ICFP} {\textquotesingle}99},
  title     = {Tracing piece by piece},
  year      = {1999},
  publisher = {{ACM} Press},
  abstract  = {The advantage of lazy functional languages is that programs may be written declaratively without specifying the exact evaluation order. The ensuing order of evaluation can however be quite involved which makes it difficult to debug such programs using traditional, operational techniques. A solution is to trace the computation in a way which focuses on the declarative aspects and hides irrelevant operational details. The main problem with this approach is the immense cost in time and space of tracing large computations. Dealing with these performance issues is thus the key to practical, general purpose debuggers for lazy functional languages. In this paper we show that computing partial traces on demand by re-executing the traced program is a viable way to overcome these difficulties. This allows any program to be traced using only a fixed amount of extra storage. Since it takes a lot of time to build a complete trace, most of which is wasted since only a fraction of a typical trace is investigated during debugging, partial tracing and repeated re-execution is also attractive from a time perspective. Performance figures are presented to substantiate our claims.},
  doi       = {10.1145/317636.317782},
  groups    = {Trace analysis},
  url       = {https://doi.org/10.1145%2F317636.317782},
}

@Article{Corbett_1995,
  author    = {Albert T. Corbett and John R. Anderson},
  journal   = {User Model User-Adap Inter},
  title     = {Knowledge tracing: Modeling the acquisition of procedural knowledge},
  year      = {1995},
  number    = {4},
  pages     = {253--278},
  volume    = {4},
  abstract  = {This paper describes an effort to model students' changing knowledge state during skill acquisition. Students in this research are learning to write short programs with the ACT Programming Tutor (APT). APT is constructed around a production rule cognitive model of programming knowledge, called theideal student model. This model allows the tutor to solve exercises along with the student and provide assistance as necessary. As the student works, the tutor also maintains an estimate of the probability that the student has learned each of the rules in the ideal model, in a process calledknowledge tracing. The tutor presents an individualized sequence of exercises to the student based on these probability estimates until the student has ‘mastered’ each rule. The programming tutor, cognitive model and learning and performance assumptions are described. A series of studies is reviewed that examine the empirical validity of knowledge tracing and has led to modifications in the process. Currently the model is quite successful in predicting test performance. Further modifications in the modeling process are discussed that may improve performance levels.},
  doi       = {10.1007/bf01099821},
  groups    = {Tracing processes},
  publisher = {Springer Science and Business Media {LLC}},
  url       = {https://doi.org/10.1007%2Fbf01099821},
}

@InProceedings{Borstler_1992,
  author    = {J. Borstler and T. Janning},
  booktitle = {[1992] Proceedings. The Sixteenth Annual International Computer Software and Applications Conference},
  title     = {Traceability between requirements and design: a transformational approach},
  year      = {1992},
  publisher = {{IEEE} Comput. Soc. Press},
  abstract  = {Modern computer-aided software engineering (CASE) tools raise the need for traceability, i.e. the ability to control the consistency between software documents produced at different stages of the software life-cycle. The authors describe the transformation between an integrated requirements engineering language based on structured analysis and the entity relationship model, and a modern design language. The transformation works incrementally and is sensitive to changes to already transformed parts. The authors outline the transformation algorithm and compare the approach to those found in the literature. A tool which implements the proposed algorithm and supports the proposed traceability is described. The potential and the limits of this approach are highlighted.},
  doi       = {10.1109/cmpsac.1992.217578},
  url       = {https://doi.org/10.1109%2Fcmpsac.1992.217578},
}

@InCollection{paige2017-changing-mde,
  author    = {Richard F. Paige and Athanasios Zolotas and Dimitris Kolovos},
  booktitle = {Present and Ulterior Software Engineering},
  publisher = {Springer International Publishing},
  title     = {The Changing Face of Model-Driven Engineering},
  year      = {2017},
  pages     = {103--118},
  abstract  = {Model-Driven Engineering has been studied and applied for many years, and it has evolved to a state where it has been used successfully in a variety of substantial projects. It is now at a state of maturity where there are potentially significant challenges to future adoption. In this chapter, we outline the state of practice in Model-Driven Engineering and point to two important future research directions: support for more flexible approaches to modelling and support for legacy models and modelling technologies.},
  doi       = {10.1007/978-3-319-67425-4_7},
  url       = {https://doi.org/10.1007/978-3-319-67425-4_7},
}

@Misc{dblp,
  howpublished = {dblp computer science bibliography.},
  month        = jul,
  note         = {https://dblp.org/xml/release/dblp-2020-0701.xml.gz},
  title        = {The dblp team: Monthly snapshot release of July 2020},
  year         = {2020},
  url          = {https://dblp.org/xml/release/dblp-2020-0701.xml.gz},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:Metamodels\;0\;0\;0xccffffff\;\;\;;
1 StaticGroup:Metastudies\;0\;0\;0xffffffff\;\;\;;
1 StaticGroup:NLP use\;0\;0\;0x6680e6ff\;\;\;;
1 StaticGroup:Concrete applications\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:Tracing processes\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Visualization\;0\;0\;0xb3e6b3ff\;\;\;;
1 StaticGroup:mde\;0\;1\;0x00ffffff\;\;\;;
2 StaticGroup:MT\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Coevolution\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:certification\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Trace analysis\;0\;1\;0xff0000ff\;\;\;;
2 StaticGroup:Trace integrity\;0\;1\;0xe64d4dff\;\;\;;
1 StaticGroup:identification\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:categorization\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:type\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:meta\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:mm\;0\;1\;0x8a8a8aff\;\;\;;
3 StaticGroup:cs\;0\;1\;0x8a8a8aff\;\;\;;
}
